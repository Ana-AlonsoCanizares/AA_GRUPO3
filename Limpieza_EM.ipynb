{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ana-AlonsoCanizares/AA_GRUPO3/blob/main/Limpieza_EM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Limpieza Empleo"
      ],
      "metadata": {
        "id": "ozKandqXfND7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dvMsJCefc1QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unidecode import unidecode\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "a9L0wTJmfQeW",
        "outputId": "c0697566-cfa0-4c5b-e4f9-f777abf6dc45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegúrarse de cambiar la ruta por el nombre real de la carpeta en Google Drive\n",
        "folder_path = '/content/drive/My Drive/PFG_FASPAS/EM'\n",
        "docs_xlsx = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
        "print(docs_xlsx)"
      ],
      "metadata": {
        "id": "_OgIZHrMc234"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic_dataframes = {}\n",
        "\n",
        "for doc in docs_xlsx:\n",
        "    entire_path = os.path.join(folder_path, doc)\n",
        "    df = pd.read_excel(entire_path)\n",
        "    # Uso el nombre del archivo como clave\n",
        "    dic_dataframes[doc] = df"
      ],
      "metadata": {
        "id": "gchdPZaZdMlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # CÓDIGO SOLO PARA EL CURRO (PQ NO PUEDO ACCEDER AL DRIVE)\n",
        "# CU_EM = pd.read_excel('/content/CU_EM.xlsx')\n",
        "# TO_EM = pd.read_excel('/content/TO_EM.xlsx')\n",
        "# AB_EM = pd.read_excel('/content/AB_EM.xlsx')\n",
        "# # CR_EM = pd.read_excel('/content/CR_EM.xlsx')"
      ],
      "metadata": {
        "id": "KtwvaREwfV7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la función que realiza las transformaciones\n",
        "def transform_df(df):\n",
        "    col_excluded = ['FECHA NACIMIENTO', 'FECHA DE NACIMIENTO', 'FECHA NACIM.']\n",
        "\n",
        "    # Convertir todas las columnas de tipo object a mayúsculas, excepto las especificadas\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype == 'object' and column not in col_excluded:\n",
        "            df[column] = df[column].apply(lambda x: unidecode(x.upper()) if isinstance(x, str) else x)\n",
        "\n",
        "    # Ahora, aplicamos unidecode a los nombres de las columnas\n",
        "    df.columns = [unidecode(col.upper()) for col in df.columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "def mapping_names(df):\n",
        "    # Diccionario con los mapeos deseados\n",
        "    columns_map = {\n",
        "        'C. POSTAL': 'CP',\n",
        "        'COD. POSTAL': 'CP',\n",
        "        'TIPO PROTESIS ': 'PROTESIS',\n",
        "        'TIPO DE PROTESIS': 'PROTESIS',\n",
        "        'FECHA NACIM.': 'FECHA NACIMIENTO',\n",
        "        'FECHA NAC.': 'FECHA NACIMIENTO',\n",
        "        'GRADO DISCAP.': 'GRADO DISCAPACIDAD',\n",
        "        '%DISCAP.': 'GRADO DISCAPACIDAD',\n",
        "        '%PERDIDA': 'GRADO PERDIDA',\n",
        "        'SIST. COMUNIC.': 'SISTEMA COMUNICACION',\n",
        "        'G. DEPENDENCIA': 'GRADO DEPENDENCIA',\n",
        "        'GRADO DE PERDIDA': 'GRADO PERDIDA',\n",
        "        'FECHA INSERCCION': 'FECHA ATENCION',\n",
        "        'ANO DE AT.': 'YEAR ATENCION',\n",
        "    }\n",
        "\n",
        "    # Crear un nuevo diccionario para los nombres de columnas\n",
        "    rename_columns = {}\n",
        "\n",
        "    # Iterar sobre las columnas y aplicar el mapeo\n",
        "    for col in df.columns:\n",
        "        norm_col = columns_map.get(col, col)\n",
        "        rename_columns[col] = norm_col\n",
        "\n",
        "    # Renombrar las columnas del DataFrame\n",
        "    df.rename(columns=rename_columns, inplace=True)\n",
        "    return df\n",
        "\n",
        "def CP_year(df):\n",
        "    if 'FECHA NACIMIENTO' in df.columns:\n",
        "      df['FECHA NACIMIENTO'] = pd.to_datetime(df['FECHA NACIMIENTO'], errors='coerce')\n",
        "\n",
        "      df['FECHA NACIMIENTO'] = df['FECHA NACIMIENTO'].apply(lambda x: np.nan if str(x).isdigit() or x == '(ADULTO)' else x)\n",
        "      df['YEAR NACIMIENTO'] = df['FECHA NACIMIENTO'].dt.year\n",
        "\n",
        "      # Convertir a numérico, dejando como NaN los valores que no sean convertibles\n",
        "      df['CP'] = pd.to_numeric(df['CP'], errors='coerce').astype('Int64')\n",
        "\n",
        "      df = df.dropna(subset=['CP', 'LOCALIDAD'], how='all')\n",
        "      CP_loc_filter = df['CP'].isnull() & df['LOCALIDAD'].isnull()\n",
        "      df = df[~CP_loc_filter]\n",
        "    return df\n",
        "\n",
        "def other_columns(df):\n",
        "  if 'PROTESIS' in df.columns:\n",
        "    df['AUD O PROTESIS'] = df['PROTESIS'].apply(lambda x: 'NO' if x in [np.nan, '-','NINGUNA', 'NO'] else 'SI')\n",
        "    df.drop('PROTESIS', axis=1, inplace=True)\n",
        "\n",
        "  if 'SISTEMA COMUNICACION' in df.columns:\n",
        "    df['SISTEMA COMUNICACION'] = df['SISTEMA COMUNICACION'].apply(lambda x: 'ORAL' if x in ['ORAL', 'ORAL/LSE', 'LSE/ORAL', 'COM. ORAL', 'COM.ORAL'] else x)\n",
        "    df['SISTEMA COMUNICACION'] = df['SISTEMA COMUNICACION'].apply(lambda x: 'LSE' if x in ['L.S.E', 'L.S.E.', 'LS', 'LSE'] else x)\n",
        "\n",
        "  if 'GRADO DISCAPACIDAD' in df.columns:\n",
        "    df['GRADO DISCAPACIDAD'] = df['GRADO DISCAPACIDAD'].apply(lambda x: x / 100 if x > 1 else x)\n",
        "    df['GRADO DISCAPACIDAD'] = df['GRADO DISCAPACIDAD'].fillna(0)\n",
        "\n",
        "  if 'LOCALIDAD' in df.columns:\n",
        "    # Limpiar los datos eliminando contenido entre paréntesis\n",
        "    df['LOCALIDAD'] = df['LOCALIDAD'].str.replace(r'\\s*\\([^)]*\\)', '', regex=True)\n",
        "\n",
        "  if 'GENERO' in df.columns:\n",
        "    df['GENERO'] = df['GENERO'].apply(lambda x: 'MUJER' if x in ['M', 'MUJER', 'FEMENINO'] else x)\n",
        "    df['GENERO'] = df['GENERO'].apply(lambda x: 'HOMBRE' if x in ['H', 'HOMBRE', 'MASCULINO'] else x)\n",
        "\n",
        "  if 'FECHA ATENCION' in df.columns:\n",
        "    df['FECHA ATENCION'] = pd.to_datetime(df['FECHA ATENCION'], errors='coerce')\n",
        "    df['YEAR ATENCION'] = df['FECHA ATENCION'].dt.year\n",
        "    df.drop('FECHA ATENCION', axis=1, inplace=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "def delete_not_important_columns(df):\n",
        "  # Añado 'AÑO ATENCIÓN' para SAAF\n",
        "  needed_columns = ['FECHA NACIMIENTO', 'LOCALIDAD', 'CP', 'YEAR NACIMIENTO']\n",
        "\n",
        "  # Creación de la lista de columnas consideradas para posible eliminación\n",
        "  social_columns = [col for col in df.columns if col not in needed_columns]\n",
        "\n",
        "  # Porcentaje máximo de valores nulos permitido\n",
        "  max_percentage = 1/3\n",
        "\n",
        "  # Identifico columnas para eliminar\n",
        "  del_columns = []\n",
        "  for col in social_columns:\n",
        "      if df[col].isnull().sum() / len(df) >= max_percentage:\n",
        "          del_columns.append(col)\n",
        "\n",
        "  # Eliminar las columnas identificadas\n",
        "  df.drop(columns=del_columns, inplace=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "vUFPCcqTi_-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suponiendo que 'dict_of_dfs' es tu diccionario de DataFrames\n",
        "for df_key, df in dic_dataframes.items():\n",
        "    dic_dataframes[df_key] = transform_df(df)\n",
        "    dic_dataframes[df_key] = mapping_names(df)\n",
        "    dic_dataframes[df_key] = CP_year(df)\n",
        "    dic_dataframes[df_key] = other_columns(df)\n",
        "    dic_dataframes[df_key] = delete_not_important_columns(df)"
      ],
      "metadata": {
        "id": "WWWNT7d5dYl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # CÓDIGO DE USO PARA EL CURRO\n",
        "# CU_EM = transform_df(CU_EM)\n",
        "# CU_EM = mapping_names(CU_EM)\n",
        "# CU_EM = CP_year(CU_EM)\n",
        "# CU_EM = other_columns(CU_EM)\n",
        "# CU_EM = delete_not_important_columns(CU_EM)\n",
        "\n",
        "# TO_EM = transform_df(TO_EM)\n",
        "# TO_EM = mapping_names(TO_EM)\n",
        "# TO_EM = CP_year(TO_EM)\n",
        "# TO_EM = other_columns(TO_EM)\n",
        "# TO_EM = delete_not_important_columns(TO_EM)\n",
        "\n",
        "# AB_EM = transform_df(AB_EM)\n",
        "# AB_EM = mapping_names(AB_EM)\n",
        "# AB_EM = CP_year(AB_EM)\n",
        "# AB_EM = other_columns(AB_EM)\n",
        "# AB_EM = delete_not_important_columns(AB_EM)"
      ],
      "metadata": {
        "id": "FRe8GIVu4sd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AB_EM = dic_dataframes.get(\"AB_EM.xlsx\")\n",
        "CR_EM = dic_dataframes.get(\"CR_EM.xlsx\")\n",
        "CU_EM = dic_dataframes.get(\"CU_EM.xlsx\")\n",
        "TO_EM = dic_dataframes.get(\"TO_EM.xlsx\")"
      ],
      "metadata": {
        "id": "FyHkX-NkCbLu",
        "outputId": "241baa24-9b4e-430c-8c23-de8b4d1e2025",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31 entries, 0 to 30\n",
            "Data columns (total 9 columns):\n",
            " #   Column                Non-Null Count  Dtype         \n",
            "---  ------                --------------  -----         \n",
            " 0   YEAR ATENCION         31 non-null     int64         \n",
            " 1   FECHA NACIMIENTO      30 non-null     datetime64[ns]\n",
            " 2   GENERO                31 non-null     object        \n",
            " 3   LOCALIDAD             31 non-null     object        \n",
            " 4   CP                    31 non-null     Int64         \n",
            " 5   GRADO DISCAPACIDAD    31 non-null     float64       \n",
            " 6   SISTEMA COMUNICACION  31 non-null     object        \n",
            " 7   YEAR NACIMIENTO       30 non-null     float64       \n",
            " 8   AUD O PROTESIS        31 non-null     object        \n",
            "dtypes: Int64(1), datetime64[ns](1), float64(2), int64(1), object(4)\n",
            "memory usage: 2.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLM_EM = pd.concat([AB_EM, CR_EM, CU_EM, TO_EM])"
      ],
      "metadata": {
        "id": "h8A491G7-58h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of DataFrames\n",
        "dfs = [AB_EM, CR_EM, CU_EM, TO_EM, CLM_EM]\n",
        "\n",
        "# Corresponding folder paths on Google Drive\n",
        "folder_paths = [\n",
        "    '/content/drive/My Drive/PFG_FASPAS/AB',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CR',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CU',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/TO',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CLM'\n",
        "]\n",
        "\n",
        "# Corresponding file names\n",
        "file_names = ['AB_EM_limpio.xlsx', 'CR_EM_limpio.xlsx', 'CU_EM_limpio.xlsx', 'TO_EM_limpio.xlsx', 'CLM_EM_limpio.xlsx']"
      ],
      "metadata": {
        "id": "iWrouYeiBgZG",
        "outputId": "544dc478-4509-46cc-a214-4ea827de6f87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 116 entries, 0 to 69\n",
            "Data columns (total 11 columns):\n",
            " #   Column                   Non-Null Count  Dtype         \n",
            "---  ------                   --------------  -----         \n",
            " 0   YEAR ATENCION            46 non-null     float64       \n",
            " 1   FECHA NACIMIENTO         112 non-null    datetime64[ns]\n",
            " 2   GENERO                   116 non-null    object        \n",
            " 3   LOCALIDAD                116 non-null    object        \n",
            " 4   CP                       116 non-null    Int64         \n",
            " 5   GRADO DISCAPACIDAD       116 non-null    float64       \n",
            " 6   SISTEMA COMUNICACION     101 non-null    object        \n",
            " 7   YEAR NACIMIENTO          112 non-null    float64       \n",
            " 8   AUD O PROTESIS           116 non-null    object        \n",
            " 9   SISTEMA DE COMUNICACION  15 non-null     object        \n",
            " 10  GRADO PERDIDA            15 non-null     object        \n",
            "dtypes: Int64(1), datetime64[ns](1), float64(3), object(6)\n",
            "memory usage: 11.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the DataFrames, folder paths, and file names\n",
        "for df, folder_path, file_name in zip(dfs, folder_paths, file_names):\n",
        "    # Define the complete file path\n",
        "    file_path = f\"{folder_path}/{file_name}\"\n",
        "\n",
        "    # Save the DataFrame as an Excel file\n",
        "    df.to_excel(file_path, index=False)\n",
        "\n",
        "print(\"All DataFrames have been exported successfully.\")"
      ],
      "metadata": {
        "id": "TxsojhdReUyv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}