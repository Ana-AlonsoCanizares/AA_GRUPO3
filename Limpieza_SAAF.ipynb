{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ana-AlonsoCanizares/AA_GRUPO3/blob/main/Limpieza_SAAF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Informe Provincial Cuenca\n",
        "##Descarga y limpeza de datos"
      ],
      "metadata": {
        "id": "cncOKnCG9KT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzamos cargando los datos de la carpeta de Google Drive en la que estén guardados (será necesario cambiar esta ruta en función de la ruta del ordenador).\n",
        "\n",
        "Es necesario aceptar la conexión con la cuenta de Google Drive.\n",
        "\n",
        "Importante y esencial, antes de tirar el código es necesario que la carpeta de Drive a la que se va a llamar tenga los archivos en formato xlsx así nombrados: 'CU_SAAF.xlsx', 'CU_AT.xlsx', 'CU_EMPLEO.xlsx', 'CU_LOG.xlsx' para que no haya errores a la hora de ejecutar este código.\n",
        "\n",
        "**¡OJO! Primeros archivo con extensión xlsx y los de las zonas a clasificar, con extensión csv, en teoría, los csv no deberían modificarse (a menos que las normativas cambien y con ello las zonas de impacto se modifiquen).**\n",
        "\n",
        "**Y todos las columnas deben tener los nombres definidos en el documento \"Resumen de datos por servicio FASPAS\" y en mayúsculas antes de ser subidos al programa.**"
      ],
      "metadata": {
        "id": "SHATfRyI9VF6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mhwbvGlQ9JVW"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importan las librerías necesarias para la parte de carga de datos y su limpieza."
      ],
      "metadata": {
        "id": "T6gtnbKM-e5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cdv4QrHLrle",
        "outputId": "4142a4a7-6a2d-4c6a-9b7a-cd9fd553c1c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unidecode import unidecode\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "e4n3PNFZ-oIq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Asegúrarse de cambiar la ruta por el nombre real de la carpeta en Google Drive\n",
        "# folder_path = '/content/drive/My Drive/PFG_FASPAS/SAAF'\n",
        "# docs_xlsx = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
        "# print(docs_xlsx)\n",
        "\n",
        "# # Asegúrarse de cambiar la ruta por el nombre real de la carpeta en Google Drive\n",
        "# folder_path_csv = '/content/drive/My Drive/PFG_FASPAS/Zonas_Prioritarias'\n",
        "# docs_csv = [f for f in os.listdir(folder_path_csv) if f.endswith('.csv')]\n",
        "# print(docs_csv)"
      ],
      "metadata": {
        "id": "yMug4vBB9ozZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creación de un diccionario que almacene los dataframes (.xlsx) contenidos en la carpeta de Cuenca.\n",
        "\n",
        "Se irán cargando todos los archivos en un dataframe que se añade al diccionario con el nombre de dicho archivo como clave."
      ],
      "metadata": {
        "id": "hxl_Z9P1-wXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic_dataframes = {}\n",
        "dic_zonas = {}\n",
        "\n",
        "for doc in docs_xlsx:\n",
        "    entire_path = os.path.join(folder_path, doc)\n",
        "    df = pd.read_excel(entire_path)\n",
        "    # Uso el nombre del archivo como clave\n",
        "    dic_dataframes[doc] = df\n",
        "\n",
        "for doc in docs_csv:\n",
        "  entire_path = os.path.join(folder_path_csv, doc)\n",
        "  df = pd.read_csv(entire_path)\n",
        "  # Uso el nombre del archivo como clave\n",
        "  dic_zonas[doc] = df"
      ],
      "metadata": {
        "id": "wpsYAD2X-c4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se debe observar que el dataframe cuente con al menos las columnas: 'AÑOS ATENCIÓN', 'FECHA NACIMIENTO' **en formato fecha**, 'LOCALIDAD', 'GÉNERO' y 'CP'"
      ],
      "metadata": {
        "id": "swAIR8SeSRpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que sabemos cuáles son las claves, guardamos cada dataframe por separado para trabajar con todos ellos de manera individual, por el momento."
      ],
      "metadata": {
        "id": "j7NG1ZuiB2pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Imprimir todas las claves\n",
        "# for clave in dic_dataframes.keys():\n",
        "#     print(clave)"
      ],
      "metadata": {
        "id": "-bSrp6NdAwQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CU_SAAF = dic_dataframes.get(\"CU_SAAF.xlsx\")\n",
        "# CU_AT = dic_dataframes.get(\"CU_AT.xlsx\")\n",
        "# CU_EMPLEO = dic_dataframes.get(\"CU_EMPLEO.xlsx\")\n",
        "# CU_LOG = dic_dataframes.get(\"CU_LOG.xlsx\")\n",
        "# # CU_SOCIOS = dic_dataframes.get(\"CU_SOCIOS.xlsx\")"
      ],
      "metadata": {
        "id": "tgagsBVtCDkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a limpiar cada uno de los dataframes en función de los datos que tenemos y vamos a normalizarlos para cuando los crucemos entre ellos.\n",
        "\n",
        "Comenzamos con los datos de Servicio de Atención y Apoyo a Familias (SAAF)."
      ],
      "metadata": {
        "id": "51k6fU9qClCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sacamos la información del dataset y observamos que de 77 entradas, el campo de 'GRADO DEPENDENCIA' tan solo tiene 1 registro, por lo que se procede a eliminarla. El 'GRADO DISCAPACIDAD' de momento lo dejamos ya que para el impacto territorial no lo vamos a usar."
      ],
      "metadata": {
        "id": "TmNPUhvqDIUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO SOLO PARA EL CURRO (PQ NO PUEDO ACCEDER AL DRIVE)\n",
        "CU_SAAF = pd.read_excel('/content/CU_SAAF.xlsx')\n",
        "TO_SAAF = pd.read_excel('/content/TO_SAAF.xlsx')\n",
        "AB_SAAF = pd.read_excel('/content/AB_SAAF.xlsx')\n",
        "GU_SAAF = pd.read_excel('/content/GU_SAAF.xlsx')\n",
        "CR_SAAF = pd.read_excel('/content/CR_SAAF.xlsx')\n",
        "\n",
        "# CU_AT = pd.read_excel('/content/CU_AT.xlsx')\n",
        "# CU_EMPLEO = pd.read_excel('/content/CU_EMPLEO.xlsx')\n",
        "# CU_LOG = pd.read_excel('/content/CU_LOG.xlsx')\n",
        "# CU_SOCIOS = pd.read_excel('/content/CU_SOCIOS.xlsx')\n",
        "# mun_pri_clm = pd.read_csv('/content/municipios_prioritarios_clm.csv')"
      ],
      "metadata": {
        "id": "FzS8Balj4ozG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TO_SAAF.info()"
      ],
      "metadata": {
        "id": "Ah7zBMd0Tenq",
        "outputId": "396d67fa-21ec-4ef2-ec6b-b71a5c251d7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 112 entries, 0 to 111\n",
            "Data columns (total 20 columns):\n",
            " #   Column                               Non-Null Count  Dtype         \n",
            "---  ------                               --------------  -----         \n",
            " 0   FECHA ALTA                           112 non-null    datetime64[ns]\n",
            " 1   EDAD ALTA                            112 non-null    object        \n",
            " 2   TIPO USUARIO                         56 non-null     object        \n",
            " 3   DIAGNÓSTICO RECIENTE                 112 non-null    object        \n",
            " 4   GÉNEO                                112 non-null    object        \n",
            " 5   FECHA NACIMIENTO                     112 non-null    datetime64[ns]\n",
            " 6   TIPO SORDERA                         112 non-null    object        \n",
            " 7   TIPO SORDERA AMPLIACIÓN              13 non-null     object        \n",
            " 8   EDAD DIAGNÓSTICO                     112 non-null    int64         \n",
            " 9   AUD O PRÓTESIS                       112 non-null    object        \n",
            " 10  ¿Lleva I.C.?                         112 non-null    object        \n",
            " 11  ¿Lleva implante de tronco cerebral?  112 non-null    object        \n",
            " 12  ¿Lleva implante osteointegrado?      112 non-null    object        \n",
            " 13  ¿Lleva implante de oído medio?       112 non-null    object        \n",
            " 14  Localidad                            95 non-null     object        \n",
            " 15  CP                                   94 non-null     float64       \n",
            " 16  Provincia                            100 non-null    object        \n",
            " 17  Modalidad comunicativa en casa       49 non-null     object        \n",
            " 18  Grado de discapacidad                9 non-null      float64       \n",
            " 19  Ámbito                               56 non-null     object        \n",
            "dtypes: datetime64[ns](2), float64(2), int64(1), object(15)\n",
            "memory usage: 17.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se ponen todos los nombres de las columnas y todos los valores de los registros en mayúsculas y se eliminan todas las tildes contenidas (tanto en los registros de tipo texto como en las columnas), para uniformar el dataset."
      ],
      "metadata": {
        "id": "V0sIxMvj5RAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la función que realiza las transformaciones\n",
        "def transform_df(df):\n",
        "    col_excluded = ['FECHA NACIMIENTO', 'FECHA DE NACIMIENTO', 'FECHA NAC']\n",
        "\n",
        "    # Convertir todas las columnas de tipo object a mayúsculas, excepto las especificadas\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype == 'object' and column not in col_excluded:\n",
        "            df[column] = df[column].apply(lambda x: unidecode(x.upper()) if isinstance(x, str) else x)\n",
        "\n",
        "    # Ahora, aplicamos unidecode a los nombres de las columnas\n",
        "    df.columns = [unidecode(col.upper()) for col in df.columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "# Asegurarse de que todas las columnas necesarias existan en todos los dataframes, creándolas si es necesario (OJO: COLUMNAS NECESARIAS PARA TODOS LOS SERVICIOS)\n",
        "# Limpieza de todas aquellas columnas no pedidas\n",
        "def kept_columns(df):\n",
        "  # Lista de columnas necesarias para hacer el impacto territorial en todos los dataframes\n",
        "  all_needed_columns = ['FECHA NACIMIENTO', 'LOCALIDAD', 'GENERO', 'CP']\n",
        "  for col in all_needed_columns:\n",
        "    if col not in df.columns:\n",
        "      df[col] = np.nan\n",
        "\n",
        "  columns_to_keep = ['FECHA ALTA','FECHA DE ALTA', 'FECHA NACIMIENTO','FECHA DE NACIMIENTO','FECHA NAC' ,'LOCALIDAD', 'GENERO', 'CP', 'TIPO SORDERA', 'MOMENTO APARICION', 'MOMENTO DE APARICION DE LA SORDERA', '?LLEVA AUDIFONO?', '?LLEVA I.C.?', '?LLEVA IMPLANTE DE TRONCO CEREBRAL?', '?LLEVA IMPLANTE OSTEOINTEGRADO?', '?LLEVA IMPLANTE DE OIDO MEDIO?', 'MODALIDAD COMUNICATIVA', 'MODALIDAD COMUNICATIVA EN CASA','MOD COM','GRADO DISCAPACIDAD', 'TIPO PROTESIS', 'TIPO DE PROTESIS','TIPO DE PROTESIS AUDITIVA', 'GRADO PERDIDA', 'GRADO DE PERDIDA']\n",
        "  df = df[df.columns.intersection(columns_to_keep)]\n",
        "  return df\n",
        "\n",
        "def mapping_names(df):\n",
        "    # Diccionario con los mapeos deseados\n",
        "    columns_map = {\n",
        "        'FECHA DE ALTA': 'FECHA ALTA',\n",
        "        'FECHA NAC': 'FECHA NACIMIENTO',\n",
        "        'FECHA DE NACIMIENTO': 'FECHA NACIMIENTO',\n",
        "        'MOMENTO DE APARICION DE LA SORDERA': 'MOMENTO APARICION',\n",
        "        'TIPO DE PROTESIS AUDITIVA': 'TIPO PROTESIS',\n",
        "        'TIPO DE PROTESIS': 'TIPO PROTESIS',\n",
        "        'MOD COM': 'MODALIDAD COMUNICATIVA',\n",
        "        'MODALIDAD COMUNICATIVA EN CASA': 'MODALIDAD COMUNICATIVA',\n",
        "        'GRADO DE PERDIDA': 'GRADO PERDIDA'\n",
        "    }\n",
        "\n",
        "    # Crear un nuevo diccionario para los nombres de columnas\n",
        "    rename_columns = {}\n",
        "\n",
        "    # Iterar sobre las columnas y aplicar el mapeo\n",
        "    for col in df.columns:\n",
        "        norm_col = columns_map.get(col, col)\n",
        "        rename_columns[col] = norm_col\n",
        "\n",
        "    # Renombrar las columnas del DataFrame\n",
        "    df.rename(columns=rename_columns, inplace=True)\n",
        "    return df\n",
        "\n",
        "def CP_year(df):\n",
        "\n",
        "  df['FECHA NACIMIENTO'] = df['FECHA NACIMIENTO'].apply(lambda x: np.nan if str(x).isdigit() or x == '(ADULTO)' else x)\n",
        "  # df['FECHA NACIMIENTO'] = pd.to_datetime(df['FECHA NACIMIENTO'], errors='coerce')\n",
        "\n",
        "  df['CP'] =df['CP'].astype('Int64')\n",
        "\n",
        "  df['YEAR NACIMIENTO'] = df['FECHA NACIMIENTO'].dt.year\n",
        "\n",
        "  df = df.dropna(subset=['CP', 'LOCALIDAD'], how='all')\n",
        "\n",
        "  CP_loc_filter = df['CP'].isnull() & df['LOCALIDAD'].isnull()\n",
        "\n",
        "  df = df[~CP_loc_filter]\n",
        "  return df"
      ],
      "metadata": {
        "id": "1IJU09ZlVrml"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OJOOOOOOOO HAY QUE VER CÓMO PROCEDER PARA AQUELLOS REGISTROS CON DATOS NULOS EN LOS CAMPOS DE CP Y LOCALIDAD**\n",
        "\n",
        "¿¿SI HAY UNO DE LOS DOS DEJAMOS EL REGISTRO, PERO SI NO HAY NADA EN AMBOS CAMPOS LOS ELIMINAMOS?? está justo arriba"
      ],
      "metadata": {
        "id": "rIr8fpZ38qbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a comenzar a limpiar los datos del Servicio de Asistencia y Apoyo a Familias (sAAF)."
      ],
      "metadata": {
        "id": "p64AZybRx3kt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo primero que hacemos es eliminar aquellas columnas cuyos datos NO se hayan pedido, ya que aunque no se hayan podido recopilar todos los datos pedidos de todas las provincias, queremos que los datasets sean lo más homogéneos posibles."
      ],
      "metadata": {
        "id": "0Ly23V5wG1nt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por otra parte, la columna 'FECHA NACIMIENTO' nos quedamos solo con la fecha (OJOOOO ¿O SOLO EL AÑO???? O AMBAS OPCIONES), eliminando la hora. Por defecto, Excel pone el CP como float, asi que lo pasamos a entero.\n",
        "\n",
        "**YO NO QUITARÍA LA FECHA DE NACIMIENTO CONCRETA POR SI HAY QUE CONTEMPLAR QUE LOS DATOS DE ENTRADA TENGAN USUARIOS REPETIDOS, PERO PARA HACER ESTUDIO DE EDAD, USARÍA LA COLUMNA DE 'AÑO NACIMIENTO'. CONSULTAAAAAAAAAAAAAAAR.**"
      ],
      "metadata": {
        "id": "1mM-6P2bFsHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si existe en el dataframe, como en este caso, aquellos que no tienen registro de 'TIPO PRÓTESIS' hay que examinar el motivo. Vamos a ver aquellos registros distintos que tienen todas las columnas. Vemos que en la columna 'TIPO PRÓTESIS' no hay ninguna salida que sea \"NO TIENE\" y preguntamos a FASPAS, tras su aprobación, procedemos a sustituir los valores nulos por 'NO TIENE'."
      ],
      "metadata": {
        "id": "Qo75GIDwHlyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se observa que la 'MODALIDAD COMUNICATIVA' no da ninguna información, pues todos los registros son \"ORAL\", sim embargo, la dejamos por si acaso en un futuro los registros cambiaran."
      ],
      "metadata": {
        "id": "4-jR--TTKzM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se disminuye la complejidad de los datos de manera que solo nos quedamos con la categoría de 'AUD O PRÓTESIS' que indica si lleva o no alguno de los dispotivos posibles (¿Lleva implante de tronco cerebral/osteointegrado/de oído medio?) con independencia de cuál de estos sea."
      ],
      "metadata": {
        "id": "f0bDOcSLVe57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación de columna 'AUD O PRÓTESIS' en función del dataset de entrada\n",
        "def determinar_si_o_no(row):\n",
        "    # Lista de las columnas a verificar\n",
        "    columns_to_meet = ['?LLEVA AUDIFONO?' ,'?LLEVA I.C.?', '?LLEVA IMPLANTE DE TRONCO CEREBRAL?', '?LLEVA IMPLANTE OSTEOINTEGRADO?', '?LLEVA IMPLANTE DE OIDO MEDIO?']\n",
        "    # Itera sobre cada columna especificada\n",
        "    for col in columns_to_meet:\n",
        "        # Verifica si el valor es NaN, \"No\" o \"no tiene\"\n",
        "        if pd.isna(row[col]) or row[col] == 'NO' or row[col] == 'NO TIENE':\n",
        "            return 'NO'\n",
        "    # Si ninguna columna cumple la condición anterior, devuelve 'Sí'\n",
        "    return 'SI'\n",
        "\n",
        "def other_columns(df):\n",
        "  if 'TIPO PROTESIS' in df.columns:\n",
        "    df['TIPO PROTESIS'] = df['TIPO PROTESIS'].fillna('NO TIENE')\n",
        "    df['AUD O PROTESIS'] = np.where(df['TIPO PROTESIS'] == 'NO TIENE', 'NO', 'SI')\n",
        "    df.drop('TIPO PROTESIS', axis=1, inplace=True)\n",
        "\n",
        "  # elif ('¿LLEVA AUDIFONO?' and '¿LLEVA I.C.?' and '¿LLEVA IMPLANTE DE TRONCO CEREBRAL?' and '¿LLEVA IMPLANTE OSTEOINTEGRADO?' and '¿LLEVA IMPLANTE DE OIDO MEDIO?') in df.columns:\n",
        "  elif '?LLEVA AUDIFONO?' in df.columns:\n",
        "    for row in df:\n",
        "      df['AUD O PROTESIS'] = df.apply(determinar_si_o_no, axis=1)\n",
        "\n",
        "  # if '¿LLEVA AUDIFONO?' in df.columns:\n",
        "  #   si = ['SI', 'YES', 'S']\n",
        "  #   for s in si:\n",
        "  #     df['¿LLEVA AUDIFONO?'] = np.where(df['¿LLEVA AUDIFONO?'] == s, 'SI', 'NO')\n",
        "  #     df['¿LLEVA I.C.?'] = np.where(df['¿LLEVA I.C.?'] == s, 'SI', 'NO')\n",
        "  #     df['¿LLEVA IMPLANTE DE TRONCO CEREBRAL?'] = np.where(df['¿LLEVA IMPLANTE DE TRONCO CEREBRAL?'] == s, 'SI', 'NO')\n",
        "  #     df['¿LLEVA IMPLANTE OSTEOINTEGRADO?'] = np.where(df['¿LLEVA IMPLANTE OSTEOINTEGRADO?'] == s, 'SI', 'NO')\n",
        "  #     df['¿LLEVA IMPLANTE DE OIDO MEDIO?'] = np.where(df['¿LLEVA IMPLANTE DE OIDO?'] == s, 'SI', 'NO')\n",
        "\n",
        "  #   # Creación de columna 'AUD O PRÓTESIS' y elimino las demás\n",
        "  #   df['AUD O PROTESIS'] = df[['¿LLEVA AUDIFONO?' ,'¿LLEVA I.C.?', '¿LLEVA IMPLANTE DE TRONCO CEREBRAL?', '¿LLEVA IMPLANTE OSTEOINTEGRADO?', '¿LLEVA IMPLANTE DE OIDO MEDIO?']].apply(lambda x: x == 'SI').any(axis=1)\n",
        "    df.drop(columns=['?LLEVA AUDIFONO?' ,'?LLEVA I.C.?', '?LLEVA IMPLANTE DE TRONCO CEREBRAL?', '?LLEVA IMPLANTE OSTEOINTEGRADO?', '?LLEVA IMPLANTE DE OIDO MEDIO?'], inplace=True)\n",
        "\n",
        "  if 'GENERO' in df.columns:\n",
        "    # OJO: contemplar tb las diferentes formas de escribir TODAS LAS COLUMNAS 'MOMENTO APARICIÓN', HAY QUE NORMALIZAR TODO\n",
        "    mujer = ['MUJER', 'HEMBRA', 'FEMENINO', 'FEM', 'F']\n",
        "    hombre = ['HOMBRE', 'MACHO', 'MASCULINO', 'MASC', 'MAS']\n",
        "\n",
        "    for m in mujer:\n",
        "      df['GENERO'] = df['GENERO'].replace(m, 'M')\n",
        "\n",
        "    for h in hombre:\n",
        "      df['GENERO'] = df['GENERO'].replace(h, 'H')\n",
        "  return df"
      ],
      "metadata": {
        "id": "iFVuG1LXH-Fp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para contemplar que otros datos que se ingresen sean distintos, vamos a jugar con eliminar aquellas columnas que no sean esenciales para el estudio territorial, sino que nos den información más sociológica y sirvan para un estudio social; siempre y cuando el porcentaje de valores nulos sea mayor o igual que 1/3 del total de registros."
      ],
      "metadata": {
        "id": "oiLN3k37MBz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_not_important_columns(df):\n",
        "  # Añado 'AÑO ATENCIÓN' para SAAF\n",
        "  needed_columns = ['AÑO ATENCION', 'FECHA NACIMIENTO', 'LOCALIDAD', 'CP', 'YEAR NACIMIENTO']\n",
        "\n",
        "  # Creación de la lista de columnas consideradas para posible eliminación\n",
        "  social_columns = [col for col in df.columns if col not in needed_columns]\n",
        "\n",
        "  # Porcentaje máximo de valores nulos permitido\n",
        "  max_percentage = 1/3\n",
        "\n",
        "  # Identifico columnas para eliminar\n",
        "  del_columns = []\n",
        "  for col in social_columns:\n",
        "      if df[col].isnull().sum() / len(df) >= max_percentage:\n",
        "          del_columns.append(col)\n",
        "\n",
        "  # Eliminar las columnas identificadas\n",
        "  df.drop(columns=del_columns, inplace=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "eGbzUeKaMtVx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además, pondremos todos los registros de MUJER como M y HOMBRE como H. Esto lo realizaremos con todos los dataframes. Contemplamos que los registros que llegan pueden tener otros nombres en este campo."
      ],
      "metadata": {
        "id": "acwjNFXXIUOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def left_columns_norm(df):\n",
        "  if 'TIPO SORDERA' in df.columns:\n",
        "    # Lista con las posibles salidas permitidas\n",
        "    strings_to_keep = ['NEUROSENSORIAL', 'CONDUCTIVA', 'MIXTA', 'TEL']\n",
        "\n",
        "    # Sustituyo los registros distintos por la palabra 'NO REGISTRADO' (VER SI SE CAMBIA ESTO)\n",
        "    df.loc[~df['TIPO SORDERA'].isin(strings_to_keep), 'TIPO SORDERA'] = 'NO REGISTRADO'\n",
        "\n",
        "  if 'MOMENTO APARICION' in df.columns:\n",
        "    strings_to_keep = ['PERILOCUTIVA', 'POSTLOCUTIVA', 'PRELOCUTIVA']\n",
        "\n",
        "    # Sustituyo los registros distintos por la palabra 'NO REGISTRADO' (VER SI SE CAMBIA ESTO)\n",
        "    df.loc[~df['MOMENTO APARICION'].isin(strings_to_keep), 'MOMENTO APARICION'] = 'NO REGISTRADO'\n",
        "\n",
        "  if 'MODALIDAD COMUNICATIVA' in df.columns:\n",
        "    strings_to_keep = ['SIGNO', 'LSE','SIGNOS', 'ORAL', 'BIMODAL', 'L.S.E.', 'L.S.E', 'SIGNOS NATURALES', 'ORAL,SIGNOS NATURALES', 'ORAL, SIGNOS NATURALES']\n",
        "\n",
        "    # Sustituyo los registros distintos por la palabra 'NO REGISTRADO' (VER SI SE CAMBIA ESTO)\n",
        "    df.loc[~df['MODALIDAD COMUNICATIVA'].isin(strings_to_keep), 'MODALIDAD COMUNICATIVA'] = 'NO REGISTRADO'\n",
        "\n",
        "    # Normalizo todas las formas de llamar a las distintas modalidades comunicativas\n",
        "    ORAL = ['ORAL', 'ORAL,SIGNOS NATURALES', 'ORAL, SIGNOS NATURALES']\n",
        "    LSE = ['LSE', 'L.S.E.','L.S.E']\n",
        "    SIGNOS = ['SIGNO', 'SIGNOS', 'SIGNOS NATURALES']\n",
        "\n",
        "    for o in ORAL:\n",
        "      df['MODALIDAD COMUNICATIVA'] = df['MODALIDAD COMUNICATIVA'].replace(o, 'ORAL')\n",
        "\n",
        "    for l in LSE:\n",
        "      df['MODALIDAD COMUNICATIVA'] = df['MODALIDAD COMUNICATIVA'].replace(l, 'LSE')\n",
        "\n",
        "    for s in SIGNOS:\n",
        "      df['MODALIDAD COMUNICATIVA'] = df['MODALIDAD COMUNICATIVA'].replace(s, 'SIGNOS')\n",
        "\n",
        "  if 'GRADO PERDIDA' in df.columns:\n",
        "    df['GRADO PERDIDA'] = df['GRADO PERDIDA'].astype(str)\n",
        "\n",
        "    # Selecciono solo las 3 primeras letras (quitando la parte de DB si la tuviera)\n",
        "    df['GRADO PERDIDA'] = df['GRADO PERDIDA'].str.slice(0, 3)\n",
        "\n",
        "    strings_to_keep = ['DAP', 'DAM', 'DAS', 'DAL']\n",
        "\n",
        "    df.loc[~df['GRADO PERDIDA'].isin(strings_to_keep), 'GRADO PERDIDA'] = 'NO REGISTRADO'\n",
        "\n",
        "  if 'GRADO DISCAPACIDAD' in df.columns:\n",
        "    df['GRADO DISCAPACIDAD'] = df['GRADO DISCAPACIDAD'].apply(lambda x: x / 100 if x > 1 else x)\n",
        "    # OJOOOOOOOOOOOOOOO PREGUNTAR A OLGA SI LE PARECE BIEN O MEJOR PONERLO A CERO LAS QUE NO TENGAN REGISTRO!?!?\n",
        "    df['GRADO DISCAPACIDAD'] = df['GRADO DISCAPACIDAD'].fillna(0)\n",
        "    # df['GRADO DISCAPACIDAD'] = df['GRADO DISCAPACIDAD'].fillna(df['GRADO DISCAPACIDAD'].mean())\n",
        "  return df"
      ],
      "metadata": {
        "id": "5F-V0DwZaopA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí podemos ver la información del df, cuáles son las columnas que se tendrán en cuenta para este caso concreto y los diferentes datos que pueden tomar. Observamos que los únicos datos que pueden tener valores nulos son CP y LOCALIDAD, pero serán en registros distintos."
      ],
      "metadata": {
        "id": "BoAn1uH0T7Hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crea un filtro booleano que coge aquellos registros con ambos campos nulos y se lo aplicamos al dataframe. Ya que aquellos registros sin geolocalización no nos sirven para el objetivo principal que es saber el impacto que se tiene en las diferentes zonas para desarrollar un plan de ampliación territorial estratégico basado en el estudio estadístico."
      ],
      "metadata": {
        "id": "I52DZXN9QMN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suponiendo que 'dict_of_dfs' es tu diccionario de DataFrames\n",
        "for df_key, df in dic_dataframes.items():\n",
        "    dic_dataframes[df_key] = transform_df(df)\n",
        "    dic_dataframes[df_key] = mapping_names(df)\n",
        "    dic_dataframes[df_key] = kept_columns(df)\n",
        "    dic_dataframes[df_key] = CP_year(df)\n",
        "    dic_dataframes[df_key] = other_columns(df)\n",
        "    dic_dataframes[df_key] = delete_not_important_columns(df)\n",
        "    dic_dataframes[df_key] = left_columns_norm(df)"
      ],
      "metadata": {
        "id": "zPGQTBgp9hiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO DE USO PARA EL CURRO\n",
        "CU_SAAF = transform_df(CU_SAAF)\n",
        "CU_SAAF = mapping_names(CU_SAAF)\n",
        "CU_SAAF = kept_columns(CU_SAAF)\n",
        "CU_SAAF = CP_year(CU_SAAF)\n",
        "CU_SAAF = other_columns(CU_SAAF)\n",
        "CU_SAAF = delete_not_important_columns(CU_SAAF)\n",
        "CU_SAAF = left_columns_norm(CU_SAAF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_ZQ7fPK-AL2",
        "outputId": "c52b5b83-c993-4333-9d4f-6fa77d1dbc7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-1db86cc03e61>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['FECHA NACIMIENTO'] = df['FECHA NACIMIENTO'].apply(lambda x: np.nan if str(x).isdigit() or x == '(ADULTO)' else x)\n",
            "<ipython-input-11-1db86cc03e61>:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['CP'] =df['CP'].astype('Int64')\n",
            "<ipython-input-11-1db86cc03e61>:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['YEAR NACIMIENTO'] = df['FECHA NACIMIENTO'].dt.year\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO DE USO PARA EL CURRO\n",
        "GU_SAAF = transform_df(GU_SAAF)\n",
        "GU_SAAF = mapping_names(GU_SAAF)\n",
        "GU_SAAF = kept_columns(GU_SAAF)\n",
        "GU_SAAF = CP_year(GU_SAAF)\n",
        "GU_SAAF = other_columns(GU_SAAF)\n",
        "GU_SAAF = delete_not_important_columns(GU_SAAF)\n",
        "GU_SAAF = left_columns_norm(GU_SAAF)"
      ],
      "metadata": {
        "id": "KpcNdfft05D-",
        "outputId": "6d423d83-8183-4128-ca52-8248e5402d23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-1db86cc03e61>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['FECHA NACIMIENTO'] = df['FECHA NACIMIENTO'].apply(lambda x: np.nan if str(x).isdigit() or x == '(ADULTO)' else x)\n",
            "<ipython-input-11-1db86cc03e61>:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['CP'] =df['CP'].astype('Int64')\n",
            "<ipython-input-11-1db86cc03e61>:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['YEAR NACIMIENTO'] = df['FECHA NACIMIENTO'].dt.year\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO DE USO PARA EL CURRO\n",
        "TO_SAAF = transform_df(TO_SAAF)\n",
        "TO_SAAF = mapping_names(TO_SAAF)\n",
        "TO_SAAF = kept_columns(TO_SAAF)\n",
        "TO_SAAF = CP_year(TO_SAAF)\n",
        "TO_SAAF = other_columns(TO_SAAF)\n",
        "TO_SAAF = delete_not_important_columns(TO_SAAF)\n",
        "TO_SAAF = left_columns_norm(TO_SAAF)"
      ],
      "metadata": {
        "id": "I0XNnELq1Cos",
        "outputId": "16172259-f0df-40a4-8145-9f955e8ae472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-1db86cc03e61>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['FECHA NACIMIENTO'] = df['FECHA NACIMIENTO'].apply(lambda x: np.nan if str(x).isdigit() or x == '(ADULTO)' else x)\n",
            "<ipython-input-11-1db86cc03e61>:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['CP'] =df['CP'].astype('Int64')\n",
            "<ipython-input-11-1db86cc03e61>:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['YEAR NACIMIENTO'] = df['FECHA NACIMIENTO'].dt.year\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO DE USO PARA EL CURRO\n",
        "AB_SAAF = transform_df(AB_SAAF)\n",
        "AB_SAAF = mapping_names(AB_SAAF)\n",
        "AB_SAAF = kept_columns(AB_SAAF)\n",
        "AB_SAAF = CP_year(AB_SAAF)\n",
        "AB_SAAF = other_columns(AB_SAAF)\n",
        "AB_SAAF = delete_not_important_columns(AB_SAAF)\n",
        "AB_SAAF = left_columns_norm(AB_SAAF)"
      ],
      "metadata": {
        "id": "YsLvgEbK1KYm",
        "outputId": "6e93aa07-a837-48f1-8613-5af1db104998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-1db86cc03e61>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['FECHA NACIMIENTO'] = df['FECHA NACIMIENTO'].apply(lambda x: np.nan if str(x).isdigit() or x == '(ADULTO)' else x)\n",
            "<ipython-input-11-1db86cc03e61>:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['CP'] =df['CP'].astype('Int64')\n",
            "<ipython-input-11-1db86cc03e61>:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['YEAR NACIMIENTO'] = df['FECHA NACIMIENTO'].dt.year\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#OJO EN CR NO HAY NI CP NI LOCALIDAD, NO PUEDO CRUZAR LOS DATOS CON NADA."
      ],
      "metadata": {
        "id": "N6OIYgaF2OLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO DE USO PARA EL CURRO\n",
        "CR_SAAF = transform_df(CR_SAAF)\n",
        "CR_SAAF = mapping_names(CR_SAAF)\n",
        "CR_SAAF = kept_columns(CR_SAAF)\n",
        "CR_SAAF = CP_year(CR_SAAF)\n",
        "CR_SAAF = other_columns(CR_SAAF)\n",
        "CR_SAAF = delete_not_important_columns(CR_SAAF)\n",
        "CR_SAAF = left_columns_norm(CR_SAAF)"
      ],
      "metadata": {
        "id": "OSMAV73e1NBN",
        "outputId": "016f2682-0a0b-495e-c8ff-fd45d2535d21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-1db86cc03e61>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['FECHA NACIMIENTO'] = df['FECHA NACIMIENTO'].apply(lambda x: np.nan if str(x).isdigit() or x == '(ADULTO)' else x)\n",
            "<ipython-input-11-1db86cc03e61>:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['CP'] =df['CP'].astype('Int64')\n",
            "<ipython-input-11-1db86cc03e61>:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['YEAR NACIMIENTO'] = df['FECHA NACIMIENTO'].dt.year\n",
            "<ipython-input-13-33e17827c768>:14: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  if df[col].isnull().sum() / len(df) >= max_percentage:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO DE USO PARA EL CURRO\n",
        "CU_SAAF.info()\n",
        "column_names = CU_SAAF.columns.tolist()\n",
        "\n",
        "for column in column_names:\n",
        "  unique_val = CU_SAAF[column].unique()\n",
        "  print(unique_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QItI6b9_phA",
        "outputId": "8245c36b-309e-40f9-fdc1-26f635983b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 212 entries, 0 to 211\n",
            "Data columns (total 11 columns):\n",
            " #   Column                                 Non-Null Count  Dtype         \n",
            "---  ------                                 --------------  -----         \n",
            " 0   FECHA DE ALTA                          212 non-null    datetime64[ns]\n",
            " 1   FECHA NACIMIENTO                       212 non-null    datetime64[ns]\n",
            " 2   TIPO DE SORDERA                        204 non-null    object        \n",
            " 3   EDAD AL RECIBIR EL DIAGNOSTICO - ANOS  212 non-null    int64         \n",
            " 4   LOCALIDAD                              160 non-null    object        \n",
            " 5   CP                                     130 non-null    float64       \n",
            " 6   PROVINCIA                              167 non-null    object        \n",
            " 7   GRADO DE DISCAPACIDAD                  124 non-null    object        \n",
            " 8   MOMENTO DE APARICION DE LA SORDERA     135 non-null    object        \n",
            " 9   GRADO DE PERDIDA                       125 non-null    object        \n",
            " 10  AUD O PROTESIS                         212 non-null    object        \n",
            "dtypes: datetime64[ns](2), float64(1), int64(1), object(7)\n",
            "memory usage: 18.3+ KB\n",
            "<DatetimeArray>\n",
            "['2024-01-25 00:00:00', '2023-10-19 00:00:00', '2023-05-12 00:00:00',\n",
            " '2022-06-24 00:00:00', '2022-05-04 00:00:00', '2022-04-28 00:00:00',\n",
            " '2022-03-08 00:00:00', '2022-03-07 00:00:00', '2022-03-04 00:00:00',\n",
            " '2022-01-20 00:00:00',\n",
            " ...\n",
            " '2001-09-20 00:00:00', '2001-09-19 00:00:00', '2001-05-23 00:00:00',\n",
            " '2001-05-21 00:00:00', '2001-05-17 00:00:00', '2001-05-01 00:00:00',\n",
            " '2001-04-11 00:00:00', '2001-02-07 00:00:00', '2001-01-09 00:00:00',\n",
            " '1997-10-20 00:00:00']\n",
            "Length: 203, dtype: datetime64[ns]\n",
            "<DatetimeArray>\n",
            "['2024-01-08 00:00:00', '1988-08-12 00:00:00', '2021-10-26 00:00:00',\n",
            " '2013-04-08 00:00:00', '1985-09-28 00:00:00', '2019-02-17 00:00:00',\n",
            " '1985-05-04 00:00:00', '2010-01-09 00:00:00', '1955-06-21 00:00:00',\n",
            " '2016-04-28 00:00:00',\n",
            " ...\n",
            " '1991-11-07 00:00:00', '1992-01-30 00:00:00', '1993-01-27 00:00:00',\n",
            " '1971-12-20 00:00:00', '1998-05-14 00:00:00', '1995-03-06 00:00:00',\n",
            " '1991-05-30 00:00:00', '1992-09-20 00:00:00', '1969-11-03 00:00:00',\n",
            " '1995-04-29 00:00:00']\n",
            "Length: 208, dtype: datetime64[ns]\n",
            "['CONDUCTIVA' 'NEUROSENSORIAL' 'MIXTA' nan]\n",
            "[ 9  8  1  4  7  3 17  5 63  0  6  2 10 20 30 43 13 32 44 -1 48 40 14 16\n",
            " 15 -9 50 51 18 12 36 27 24]\n",
            "['ALBACETE' nan 'CASAS DE FERNANDO ALONSO' 'ALPERA' 'ALMANSA' 'LA RODA'\n",
            " 'LA RODA ' 'VIANOS' 'MADRIGUERAS' 'ALBACETE ' 'ALMANSA ' 'FUENTEALBILLA '\n",
            " 'CASASIMARRO ' 'TOBARRA' 'LEZUZA ' 'CAUDETE ' 'LA GINETA ' 'CAUDETE'\n",
            " 'LA ALBERCA DE ZANCARA ' 'TARAZONA DE LA MANCHA ' 'TOBARRA ' 'BALAZOTE'\n",
            " 'HELLIN' 'POZOCANADA ' 'BEMBIBRE' 'SISANTE' 'EL HERRUMBLAR' 'LA GINETA'\n",
            " 'SAN CLEMENTE' 'TARAZONA' 'VILLARROBLEDO' 'BELMONTE' 'BARRAX'\n",
            " 'TARAZONA DE LA MANCHA' 'NAVAS DE CAMPANA (HELLIN)' 'POZO CANADA'\n",
            " 'ELCHE DE LA SIERRA' 'VILLARTA']\n",
            "[ 2005.    nan  2003. 16610.  2690.  2640.  2006.  2004.  2630.  2315.\n",
            "  2001.  2230.  2002.  2008.  2260.  2350.  2500.  2660.  2011. 16620.\n",
            "  2320.  2400.  2510. 24300. 16700. 16290.   211.  2066. 16600.  2100.\n",
            "  2600. 16640.  2430. 16280.  2080.]\n",
            "['ALBACETE' nan 'CUENCA' 'ALBACETE ' 'CUENCA ' 'LEON ']\n",
            "[0.33 nan 'EN TRAMITES' 0.36 0.37 0.79 0.405 0.34 'NO SOLICITADO'\n",
            " 'TRAMITES' 0.65 0.41 0.35 'NO SOLICITADA' 0.38 'NO' 'NO SOLICITADO ' 0.46\n",
            " 'TRAMITES ' 'EN TRAMITES ' 0.66 '  ' 0.725 0.45 0.57 0.55 0.43 0.39 0.44\n",
            " 0.5 0.42 'ESTA EN TRAMITES' '65% (DEPENDENCIA)' 0.73 0.48\n",
            " 'ES LA DE RUMANIA' 0.58 0.4 'NO HA ENCONTRADO LOS PAPELES' 0.22 0.335\n",
            " 0.49 'ESTA EN TRAMITES ' 0.72 0.56 0.575 0.62 0.53 0.82 0.51 0.555 49.5\n",
            " 0.595 0.675 0.6 0.505 0.355 0.47 0.475]\n",
            "['POSTLOCUTIVA' nan 'PRELOCUTIVA' 'PERILOCUTIVA']\n",
            "['DAM(40-70DB)' nan 'DAS(70-90DB)' 'DAP(+90DB)' 'DAL(20-40DB)'\n",
            " 'DAS(70-90MB)']\n",
            "['NO']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = dic_dataframes['CU_SAAF.xlsx'].columns.tolist()\n",
        "\n",
        "for column in column_names:\n",
        "  unique_val = dic_dataframes['CU_SAAF.xlsx'][column].unique()\n",
        "  print(unique_val)"
      ],
      "metadata": {
        "id": "1doWoxX2Jltq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_comun = pd.merge(dic_dataframes['CU_SAAF.xlsx'], mun_pri_clm, left_on='LOCALIDAD', right_on='ZONA PRIORITARIA')\n",
        "df_comun"
      ],
      "metadata": {
        "id": "i4n9cHTXcCqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos el impacto que tiene en las zonas prioritarias."
      ],
      "metadata": {
        "id": "41R1ETSNgyxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el conteo de registros para cada categoría\n",
        "cat_count = df_comun['LOCALIDAD'].value_counts()\n",
        "\n",
        "# Crear un gráfico de barras\n",
        "cat_count.sort_index().plot(kind='bar')\n",
        "\n",
        "# Personalización adicional\n",
        "plt.title('SAAF: Impacto en Zonas por Zonas Prioritarias')\n",
        "plt.xlabel('ZONA PRIORITARIA')\n",
        "plt.ylabel('Número de Registros')\n",
        "plt.xticks(rotation=45)  # Rota las etiquetas del eje X para mejor lectura\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yA6sWBBaeR-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"En este caso concreto las localidades con impacto dentro de las que se incluyen en las zonas prioritarias son: \\n\\nLocalidad Nº Registros\")\n",
        "print(cat_count)\n",
        "# DEFINIR QUÉ SE CONSIDERA IMPACTO FUERTE/IMPACTO NORMAL/IMPACTO LEVE\n",
        "# Iterar sobre la serie y mostrar solo las localidades con un valor mayor que 10\n",
        "for localidad, valor in cat_count.items():\n",
        "    if valor > 10:\n",
        "      print(f\"La Localidad de {localidad} tiene un impacto fuerte, ya que cuenta con {valor} registros.\")\n",
        "    elif valor > 5:\n",
        "      print(f\"La Localidad de {localidad} tiene un impacto medio, ya que cuenta con {valor} registros.\")\n",
        "    else:\n",
        "      if valor > 1:\n",
        "        print(f\"La Localidad de {localidad} tiene un impacto leve, ya que cuenta con {valor} registros.\")\n",
        "      else:\n",
        "        print(f\"La Localidad de {localidad} tiene un impacto leve, ya que cuenta con {valor} registro.\")"
      ],
      "metadata": {
        "id": "_jZTIFrahZzL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}