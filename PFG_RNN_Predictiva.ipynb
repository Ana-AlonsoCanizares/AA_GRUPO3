{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ana-AlonsoCanizares/AA_GRUPO3/blob/main/PFG_RNN_Predictiva.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Red Neuronal Predictiva\n",
        "\n",
        "Creación de una red neuronal predictiva que sea capaz de clasificar nuevos usuarios con buena precisión en servicio y provincia."
      ],
      "metadata": {
        "id": "2dYYkD8OoRlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CouywWAlovYw",
        "outputId": "e9cea714-aa15-4020-bdfb-cd573ce37f03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install unidecode"
      ],
      "metadata": {
        "id": "xf__oEyxOkZI",
        "outputId": "ccbf0cd2-5bdc-41f7-c4ac-7f9a5fb4247c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unidecode import unidecode\n",
        "import matplotlib.pyplot as plt\n",
        "import unicodedata"
      ],
      "metadata": {
        "id": "0InrTb-CGMCI"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegúrarse de cambiar la ruta por el nombre real de la carpeta en Google Drive\n",
        "folder_path = '/content/drive/My Drive/PFG_FASPAS/RNN'\n",
        "docs_xlsx = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
        "print(docs_xlsx)"
      ],
      "metadata": {
        "id": "zj2viAzoGOoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic_dataframes = {}\n",
        "\n",
        "for doc in docs_xlsx:\n",
        "    entire_path = os.path.join(folder_path, doc)\n",
        "    df = pd.read_excel(entire_path)\n",
        "    # Uso el nombre del archivo como clave\n",
        "    dic_dataframes[doc] = df\n",
        "\n",
        "# Imprimir todas las claves\n",
        "for clave in dic_dataframes.keys():\n",
        "    print(clave)"
      ],
      "metadata": {
        "id": "C7_AhL9OGamp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RN_SAAF = dic_dataframes.get(\"RN_SAAF.xlsx\")\n",
        "RN_AT = dic_dataframes.get(\"RN_AT.xlsx\")\n",
        "# RN_ACT = dic_dataframes.get(\"RN_ACT.xlsx\")\n",
        "RN_EM = dic_dataframes.get(\"RN_EM.xlsx\")\n",
        "RN_SO = dic_dataframes.get(\"RN_SO.xlsx\")\n",
        "RN_LOG = dic_zonas.get(\"RN_LOG.xlsx\")\n",
        "df_8000rows = dic_mun.get(\"df_8000_rows.xlsx\")"
      ],
      "metadata": {
        "id": "jI7CuaujGm5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO SOLO PARA EL CURRO (PQ NO PUEDO ACCEDER AL DRIVE)\n",
        "RN_SAAF = pd.read_excel('/content/RN_SAAF.xlsx')\n",
        "RN_AT = pd.read_excel('/content/RN_AT.xlsx')\n",
        "# RN_ACT = pd.read_excel('/content/RN_ACT.xlsx')\n",
        "RN_EM = pd.read_excel('/content/RN_EM.xlsx')\n",
        "RN_LOG = pd.read_excel('/content/RN_LOG.xlsx')\n",
        "RN_SO = pd.read_excel('/content/RN_SO.xlsx')\n",
        "df_8000rows = pd.read_excel('/content/df_8000_rows.xlsx')\n",
        "provincia_municipio = pd.read_excel('/content/PROVINCIA_MUNICIPIO.xlsx')"
      ],
      "metadata": {
        "id": "MYSRNK9UHEcT"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all string columns to uppercase and remove accents/diacritics in combined_df\n",
        "df_8000rows = df_8000rows.applymap(lambda x: unidecode(x.upper()) if isinstance(x, str) else x)\n",
        "provincia_municipio = provincia_municipio.applymap(lambda x: unidecode(x.upper()) if isinstance(x, str) else x)"
      ],
      "metadata": {
        "id": "5vJYmkkQMvzh"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to add PROVINCIA column based on LOCALIDAD\n",
        "def add_provincia_column(df, provincia_mapping):\n",
        "    df['PROVINCIA'] = df['LOCALIDAD'].map(provincia_mapping)\n",
        "    return df\n",
        "\n",
        "# Create a dictionary mapping from LOCALIDAD to PROVINCIA\n",
        "localidad_to_provincia = provincia_municipio.set_index('MUNICIPIO')['PROVINCIA'].to_dict()\n",
        "\n",
        "# List of RN dataframes to process\n",
        "rn_dataframes = {'AT': RN_AT, 'EM': RN_EM, 'LOG': RN_LOG, 'SAAF': RN_SAAF, 'SO': RN_SO}\n",
        "\n",
        "# Add the PROVINCIA column to each RN dataframe\n",
        "rn_dfs_with_provincia = {name: add_provincia_column(df, localidad_to_provincia) for name, df in rn_dataframes.items()}\n",
        "\n",
        "# Drop rows with null values in the 'PROVINCIA' column in each RN dataframe\n",
        "rn_dfs_cleaned = {name: df.dropna(subset=['PROVINCIA']) for name, df in rn_dfs_with_provincia.items()}"
      ],
      "metadata": {
        "id": "njHewFYSS2NB"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to keep\n",
        "required_columns = ['LOCALIDAD', 'GENERO', 'YEAR NACIMIENTO', 'PROVINCIA']\n",
        "\n",
        "# Function to ensure the dataframe has all required columns\n",
        "def ensure_columns(df, columns):\n",
        "    for column in columns:\n",
        "        if column not in df.columns:\n",
        "            df[column] = np.nan  # Create column with NaN values if it does not exist\n",
        "    return df[columns]  # Return dataframe with only the required columns\n",
        "\n",
        "# Ensure all dataframes have the required columns\n",
        "rn_dfs_final = {name: ensure_columns(df, required_columns) for name, df in rn_dfs_cleaned.items()}"
      ],
      "metadata": {
        "id": "4-mAp8jrXUk6",
        "outputId": "23640bbb-3821-4f2e-e2a5-152ab5992294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-109-605fc2068a84>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column] = np.nan  # Create column with NaN values if it does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping dictionary for normalizing gender values\n",
        "gender_mapping = {\n",
        "    'FEMENINO': 'MUJER',\n",
        "    'M': 'MUJER',\n",
        "    'MASCULINO': 'HOMBRE',\n",
        "    'H': 'HOMBRE'\n",
        "}\n",
        "\n",
        "# Function to normalize the 'GENERO' column in a dataframe\n",
        "def normalize_gender_column(df):\n",
        "    df['GENERO'] = df['GENERO'].map(lambda x: gender_mapping.get(x, x))\n",
        "    return df\n",
        "\n",
        "# Apply the normalization to the 'SO' dataframe\n",
        "rn_dfs_final['SO'] = normalize_gender_column(rn_dfs_final['SO'])"
      ],
      "metadata": {
        "id": "k-1iPbJ5ZTPg",
        "outputId": "0abab4f8-e00a-4aa0-8600-d3a3016f946b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-110-333b05a14062>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['GENERO'] = df['GENERO'].map(lambda x: gender_mapping.get(x, x))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to insert random registers into a dataframe where the 'GENERO' column is empty\n",
        "def insert_random_registers(df, gender_distribution):\n",
        "    # Find the indices where 'GENERO' is empty\n",
        "    empty_indices = df[df['GENERO'].isna()].index\n",
        "\n",
        "    # Generate random genders based on the given distribution for the empty indices\n",
        "    genders = np.random.choice(\n",
        "        ['MUJER', 'HOMBRE'],\n",
        "        size=len(empty_indices),\n",
        "        p=[gender_distribution['MUJER'], gender_distribution['HOMBRE']]\n",
        "    )\n",
        "\n",
        "    # Assign these random genders to the empty 'GENERO' rows\n",
        "    df.loc[empty_indices, 'GENERO'] = genders\n",
        "    return df\n",
        "\n",
        "# Example of usage\n",
        "gender_distribution = {'MUJER': 0.44, 'HOMBRE': 0.56}\n",
        "\n",
        "# Insert random registers into a specific dataframe, e.g., 'ACT', where 'GENERO' is empty\n",
        "rn_dfs_final['SAAF'] = insert_random_registers(rn_dfs_final['SAAF'], gender_distribution)\n",
        "rn_dfs_final['SO'] = insert_random_registers(rn_dfs_final['SO'], gender_distribution)"
      ],
      "metadata": {
        "id": "QJBfgKPgbVCd"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the min and max year in the 'YEAR NACIMIENTO' column\n",
        "min_year = int(rn_dfs_final['SO']['YEAR NACIMIENTO'].min())\n",
        "max_year = int(rn_dfs_final['SO']['YEAR NACIMIENTO'].max())\n",
        "\n",
        "# Function to generate random years with the specified distribution\n",
        "def generate_random_years(size):\n",
        "    # 75% of the years under 2004\n",
        "    under_2004 = np.random.randint(min_year, 2004, size=int(size * 0.75))\n",
        "    # 25% of the years between 2004 and max_year\n",
        "    over_2004 = np.random.randint(2004, max_year + 1, size=size - int(size * 0.75))\n",
        "    return np.concatenate([under_2004, over_2004])\n",
        "\n",
        "# Function to insert random years into the 'YEAR NACIMIENTO' column where it is empty\n",
        "def insert_random_years(df):\n",
        "    # Find the indices where 'YEAR NACIMIENTO' is empty\n",
        "    empty_indices = df[df['YEAR NACIMIENTO'].isna()].index\n",
        "\n",
        "    # Generate random years based on the specified distribution\n",
        "    random_years = generate_random_years(len(empty_indices))\n",
        "    np.random.shuffle(random_years)  # Shuffle to mix the values\n",
        "\n",
        "    # Assign these random years to the empty 'YEAR NACIMIENTO' rows\n",
        "    df.loc[empty_indices, 'YEAR NACIMIENTO'] = random_years\n",
        "    return df\n",
        "\n",
        "# Apply the function to the 'SO' dataframe\n",
        "rn_dfs_final['SO'] = insert_random_years(rn_dfs_final['SO'])\n"
      ],
      "metadata": {
        "id": "qm7bSdbPbuo3"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column named 'SERVICIO' with the name of the dataframe to each dataframe in rn_dfs_final\n",
        "def add_servicio_column(dfs):\n",
        "    for name, df in dfs.items():\n",
        "        df['SERVICIO'] = name\n",
        "    return dfs\n",
        "\n",
        "# Apply the function to rn_dfs_final\n",
        "rn_dfs_final = add_servicio_column(rn_dfs_final)"
      ],
      "metadata": {
        "id": "PybnAC9reCDb",
        "outputId": "6a52c3fd-e2fa-45c5-d594-1c7b1cbb4926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-113-c5260d67a514>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SERVICIO'] = name\n",
            "<ipython-input-113-c5260d67a514>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SERVICIO'] = name\n",
            "<ipython-input-113-c5260d67a514>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SERVICIO'] = name\n",
            "<ipython-input-113-c5260d67a514>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SERVICIO'] = name\n",
            "<ipython-input-113-c5260d67a514>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SERVICIO'] = name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all dataframes into a single dataframe\n",
        "combined_df = pd.concat(rn_dfs_final.values(), ignore_index=True)\n",
        "\n",
        "# Shuffle the rows of the combined dataframe\n",
        "shuffled_combined_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "shuffled_combined_df['SERVICIO'].value_counts()"
      ],
      "metadata": {
        "id": "o_JtWWq1j-Fp",
        "outputId": "62ecfdff-a423-4b40-fc37-8573f451e5e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SERVICIO\n",
              "SO      1457\n",
              "SAAF     567\n",
              "EM       203\n",
              "LOG      182\n",
              "AT       143\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the frequency of each element in the 'SERVICIO' column\n",
        "service_frequency = df['SERVICIO'].value_counts()\n",
        "\n",
        "# Group by 'PROVINCIA' and 'SERVICIO' and count the occurrences\n",
        "service_province_freq = shuffled_combined_df.groupby(['PROVINCIA', 'SERVICIO']).size().reset_index(name='COUNT')\n",
        "\n",
        "# Function to assign services based on frequency\n",
        "def assign_service(row, freq_df):\n",
        "    province = row['PROVINCIA']\n",
        "    possible_services = freq_df[freq_df['PROVINCIA'] == province]\n",
        "    if possible_services.empty:\n",
        "        return np.nan\n",
        "    else:\n",
        "        return np.random.choice(possible_services['SERVICIO'].values, p=possible_services['COUNT'].values / possible_services['COUNT'].sum())\n",
        "\n",
        "# Apply the function to assign services\n",
        "df_8000rows['SERVICIO'] = df_8000rows.apply(assign_service, axis=1, args=(service_province_freq,))\n",
        "\n",
        "# Ensure balanced classes by sampling\n",
        "min_class_size = service_frequency.min()\n",
        "balanced_df = df_8000rows.groupby('SERVICIO').apply(lambda x: x.sample(n=min_class_size, replace=True)).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "1uB0r6aSmkZd"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df['SERVICIO'].shape"
      ],
      "metadata": {
        "id": "NriTgA3RnJXD",
        "outputId": "601d9609-34d6-4439-f5ec-4b9503f62b07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7285,)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}