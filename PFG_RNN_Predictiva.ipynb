{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ana-AlonsoCanizares/AA_GRUPO3/blob/main/PFG_RNN_Predictiva.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CouywWAlovYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017747c3-38ba-428a-be86-6fa7befcfde6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf__oEyxOkZI",
        "outputId": "af42c328-833c-421b-abbb-10a3c44e3881"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unidecode import unidecode\n",
        "import matplotlib.pyplot as plt\n",
        "import unicodedata"
      ],
      "metadata": {
        "id": "0InrTb-CGMCI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegúrarse de cambiar la ruta por el nombre real de la carpeta en Google Drive\n",
        "folder_path = '/content/drive/My Drive/PFG_FASPAS/RNN'\n",
        "docs_xlsx = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
        "print(docs_xlsx)"
      ],
      "metadata": {
        "id": "zj2viAzoGOoP",
        "outputId": "2775e845-f676-45e5-cc81-27ada4971897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['RN_LOG.xlsx', 'RN_ACT.xlsx', 'RN_EM.xlsx', 'RN_SO.xlsx', 'RN_AT.xlsx', 'RN_SAAF.xlsx', 'df_8000_rows.xlsx']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dic_dataframes = {}\n",
        "\n",
        "for doc in docs_xlsx:\n",
        "    entire_path = os.path.join(folder_path, doc)\n",
        "    df = pd.read_excel(entire_path)\n",
        "    # Uso el nombre del archivo como clave\n",
        "    dic_dataframes[doc] = df\n",
        "\n",
        "# Imprimir todas las claves\n",
        "for clave in dic_dataframes.keys():\n",
        "    print(clave)"
      ],
      "metadata": {
        "id": "C7_AhL9OGamp",
        "outputId": "04829501-dbac-4fd8-cfaa-ad27e6dffdc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RN_LOG.xlsx\n",
            "RN_ACT.xlsx\n",
            "RN_EM.xlsx\n",
            "RN_SO.xlsx\n",
            "RN_AT.xlsx\n",
            "RN_SAAF.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RN_SAAF = dic_dataframes.get(\"RN_SAAF.xlsx\")\n",
        "RN_AT = dic_dataframes.get(\"RN_AT.xlsx\")\n",
        "# RN_ACT = dic_dataframes.get(\"RN_ACT.xlsx\")\n",
        "RN_EM = dic_dataframes.get(\"RN_EM.xlsx\")\n",
        "RN_SO = dic_dataframes.get(\"RN_SO.xlsx\")\n",
        "RN_LOG = dic_dataframes.get(\"RN_LOG.xlsx\")\n",
        "df_8000rows = dic_dataframes.get(\"df_8000_rows.xlsx\")"
      ],
      "metadata": {
        "id": "jI7CuaujGm5D"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO SOLO PARA EL CURRO (PQ NO PUEDO ACCEDER AL DRIVE)\n",
        "RN_SAAF = pd.read_excel('/content/RN_SAAF.xlsx')\n",
        "RN_AT = pd.read_excel('/content/RN_AT.xlsx')\n",
        "# RN_ACT = pd.read_excel('/content/RN_ACT.xlsx')\n",
        "RN_EM = pd.read_excel('/content/RN_EM.xlsx')\n",
        "RN_LOG = pd.read_excel('/content/RN_LOG.xlsx')\n",
        "RN_SO = pd.read_excel('/content/RN_SO.xlsx')\n",
        "df_8000rows = pd.read_excel('/content/df_8000_rows.xlsx')\n",
        "provincia_municipio = pd.read_excel('/content/PROVINCIA_MUNICIPIO.xlsx')"
      ],
      "metadata": {
        "id": "MYSRNK9UHEcT"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all string columns to uppercase and remove accents/diacritics in combined_df\n",
        "df_8000rows = df_8000rows.applymap(lambda x: unidecode(x.upper()) if isinstance(x, str) else x)\n",
        "provincia_municipio = provincia_municipio.applymap(lambda x: unidecode(x.upper()) if isinstance(x, str) else x)"
      ],
      "metadata": {
        "id": "5vJYmkkQMvzh"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to add PROVINCIA column based on LOCALIDAD\n",
        "def add_provincia_column(df, provincia_mapping):\n",
        "    df['PROVINCIA'] = df['LOCALIDAD'].map(provincia_mapping)\n",
        "    return df\n",
        "\n",
        "# Create a dictionary mapping from LOCALIDAD to PROVINCIA\n",
        "localidad_to_provincia = provincia_municipio.set_index('MUNICIPIO')['PROVINCIA'].to_dict()\n",
        "\n",
        "# List of RN dataframes to process\n",
        "rn_dataframes = {'AT': RN_AT, 'EM': RN_EM, 'LOG': RN_LOG, 'SAAF': RN_SAAF, 'SO': RN_SO}\n",
        "\n",
        "# Add the PROVINCIA column to each RN dataframe\n",
        "rn_dfs_with_provincia = {name: add_provincia_column(df, localidad_to_provincia) for name, df in rn_dataframes.items()}\n",
        "\n",
        "# Drop rows with null values in the 'PROVINCIA' column in each RN dataframe\n",
        "rn_dfs_cleaned = {name: df.dropna(subset=['PROVINCIA']) for name, df in rn_dfs_with_provincia.items()}"
      ],
      "metadata": {
        "id": "njHewFYSS2NB"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to keep\n",
        "required_columns = ['LOCALIDAD', 'GENERO', 'YEAR NACIMIENTO', 'PROVINCIA']\n",
        "\n",
        "# Function to ensure the dataframe has all required columns\n",
        "def ensure_columns(df, columns):\n",
        "    for column in columns:\n",
        "        if column not in df.columns:\n",
        "            df[column] = np.nan  # Create column with NaN values if it does not exist\n",
        "    return df[columns]  # Return dataframe with only the required columns\n",
        "\n",
        "# Ensure all dataframes have the required columns\n",
        "rn_dfs_final = {name: ensure_columns(df, required_columns) for name, df in rn_dfs_cleaned.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-mAp8jrXUk6",
        "outputId": "905eae0b-766f-40ad-e5ef-593334f8b9a6"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-151-605fc2068a84>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column] = np.nan  # Create column with NaN values if it does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping dictionary for normalizing gender values\n",
        "gender_mapping = {\n",
        "    'FEMENINO': 'MUJER',\n",
        "    'M': 'MUJER',\n",
        "    'MASCULINO': 'HOMBRE',\n",
        "    'H': 'HOMBRE'\n",
        "}\n",
        "\n",
        "# Function to normalize the 'GENERO' column in a dataframe\n",
        "def normalize_gender_column(df):\n",
        "    df['GENERO'] = df['GENERO'].map(lambda x: gender_mapping.get(x, x))\n",
        "    return df\n",
        "\n",
        "# Apply the normalization to the 'SO' dataframe\n",
        "rn_dfs_final['SO'] = normalize_gender_column(rn_dfs_final['SO'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-1iPbJ5ZTPg",
        "outputId": "9f118431-a082-4eb8-a01e-dd8563e70b99"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-152-333b05a14062>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['GENERO'] = df['GENERO'].map(lambda x: gender_mapping.get(x, x))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to insert random registers into a dataframe where the 'GENERO' column is empty\n",
        "def insert_random_registers(df, gender_distribution):\n",
        "    # Find the indices where 'GENERO' is empty\n",
        "    empty_indices = df[df['GENERO'].isna()].index\n",
        "\n",
        "    # Generate random genders based on the given distribution for the empty indices\n",
        "    genders = np.random.choice(\n",
        "        ['MUJER', 'HOMBRE'],\n",
        "        size=len(empty_indices),\n",
        "        p=[gender_distribution['MUJER'], gender_distribution['HOMBRE']]\n",
        "    )\n",
        "\n",
        "    # Assign these random genders to the empty 'GENERO' rows\n",
        "    df.loc[empty_indices, 'GENERO'] = genders\n",
        "    return df\n",
        "\n",
        "# Example of usage\n",
        "gender_distribution = {'MUJER': 0.44, 'HOMBRE': 0.56}\n",
        "\n",
        "# Insert random registers into a specific dataframe, e.g., 'ACT', where 'GENERO' is empty\n",
        "rn_dfs_final['SAAF'] = insert_random_registers(rn_dfs_final['SAAF'], gender_distribution)\n",
        "rn_dfs_final['SO'] = insert_random_registers(rn_dfs_final['SO'], gender_distribution)"
      ],
      "metadata": {
        "id": "QJBfgKPgbVCd"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the min and max year in the 'YEAR NACIMIENTO' column\n",
        "min_year = int(rn_dfs_final['SO']['YEAR NACIMIENTO'].min())\n",
        "max_year = int(rn_dfs_final['SO']['YEAR NACIMIENTO'].max())\n",
        "\n",
        "# Function to generate random years with the specified distribution\n",
        "def generate_random_years(size):\n",
        "    # 75% of the years under 2004\n",
        "    under_2004 = np.random.randint(min_year, 2004, size=int(size * 0.75))\n",
        "    # 25% of the years between 2004 and max_year\n",
        "    over_2004 = np.random.randint(2004, max_year + 1, size=size - int(size * 0.75))\n",
        "    return np.concatenate([under_2004, over_2004])\n",
        "\n",
        "# Function to insert random years into the 'YEAR NACIMIENTO' column where it is empty\n",
        "def insert_random_years(df):\n",
        "    # Find the indices where 'YEAR NACIMIENTO' is empty\n",
        "    empty_indices = df[df['YEAR NACIMIENTO'].isna()].index\n",
        "\n",
        "    # Generate random years based on the specified distribution\n",
        "    random_years = generate_random_years(len(empty_indices))\n",
        "    np.random.shuffle(random_years)  # Shuffle to mix the values\n",
        "\n",
        "    # Assign these random years to the empty 'YEAR NACIMIENTO' rows\n",
        "    df.loc[empty_indices, 'YEAR NACIMIENTO'] = random_years\n",
        "    return df\n",
        "\n",
        "# Apply the function to the 'SO' dataframe\n",
        "rn_dfs_final['SO'] = insert_random_years(rn_dfs_final['SO'])"
      ],
      "metadata": {
        "id": "qm7bSdbPbuo3"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column named 'SERVICIO' with the name of the dataframe to each dataframe in rn_dfs_final\n",
        "def add_servicio_column(dfs):\n",
        "    for name, df in dfs.items():\n",
        "        df['SERVICIO'] = name\n",
        "    return dfs\n",
        "\n",
        "# Apply the function to rn_dfs_final\n",
        "rn_dfs_final = add_servicio_column(rn_dfs_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PybnAC9reCDb",
        "outputId": "5b4a1a8a-30b3-4888-bfcf-503800dd3ddc"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-155-c5260d67a514>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SERVICIO'] = name\n",
            "<ipython-input-155-c5260d67a514>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SERVICIO'] = name\n",
            "<ipython-input-155-c5260d67a514>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SERVICIO'] = name\n",
            "<ipython-input-155-c5260d67a514>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SERVICIO'] = name\n",
            "<ipython-input-155-c5260d67a514>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SERVICIO'] = name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all dataframes into a single dataframe\n",
        "combined_df = pd.concat(rn_dfs_final.values(), ignore_index=True)\n",
        "\n",
        "# Shuffle the rows of the combined dataframe\n",
        "shuffled_combined_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "shuffled_combined_df['SERVICIO'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_JtWWq1j-Fp",
        "outputId": "eeef34ea-02fa-4094-eb61-dd8fbd71cbdc"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SERVICIO\n",
              "SO      1457\n",
              "SAAF     567\n",
              "EM       203\n",
              "LOG      182\n",
              "AT       143\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una función para categorizar por grupos de edad\n",
        "def categorize_age(year):\n",
        "    if year < 1940:\n",
        "        return 'ANTES DE 1940'\n",
        "    elif year < 1960:\n",
        "        return '1940-1959'\n",
        "    elif year < 1980:\n",
        "        return '1960-1979'\n",
        "    elif year < 2000:\n",
        "        return '1980-1999'\n",
        "    elif year < 2020:\n",
        "        return '2000-2020'\n",
        "    else:\n",
        "        return '2020 EN ADELANTE'\n",
        "\n",
        "rna1 = shuffled_combined_df.copy()\n",
        "# Aplicar la función a la columna 'YEAR NACIMIENTO'\n",
        "rna1['YEAR NACIMIENTO'] = rna1['YEAR NACIMIENTO'].apply(categorize_age)\n",
        "\n",
        "# Ver el resultado\n",
        "print(rna1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpkB79Ibf3o5",
        "outputId": "2f640627-59aa-4cf5-fdf1-6eddc44bff22"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 LOCALIDAD  GENERO YEAR NACIMIENTO    PROVINCIA SERVICIO\n",
            "0              GUADALAJARA  HOMBRE       2000-2020  GUADALAJARA     SAAF\n",
            "1                 ALBACETE   MUJER       1960-1979     ALBACETE       EM\n",
            "2              GUADALAJARA   MUJER       1940-1959  GUADALAJARA       SO\n",
            "3              GUADALAJARA   MUJER       1980-1999  GUADALAJARA     SAAF\n",
            "4              GUADALAJARA  HOMBRE       2000-2020  GUADALAJARA       SO\n",
            "...                    ...     ...             ...          ...      ...\n",
            "2547            MARCHAMALO  HOMBRE       2000-2020  GUADALAJARA       SO\n",
            "2548            FUENSALIDA  HOMBRE       2000-2020       TOLEDO     SAAF\n",
            "2549         OLIAS DEL REY  HOMBRE       2000-2020       TOLEDO      LOG\n",
            "2550  CABANILLAS DEL CAMPO   MUJER       2000-2020  GUADALAJARA       SO\n",
            "2551              ALBACETE   MUJER       2000-2020     ALBACETE       SO\n",
            "\n",
            "[2552 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RNA predictiva con los datos reales\n",
        "Vamos a realizar una primera red neuronal con los registros reales."
      ],
      "metadata": {
        "id": "B-k7H7ejhjBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Preparación de los datos\n",
        "\n",
        "Convertimos las variables categóricas en variables dummy usando pd.get_dummies.\n",
        "\n",
        "Separamos las características (x) de la etiqueta (y).\n",
        "Convertimos la etiqueta en variables dummy para la clasificación multiclase."
      ],
      "metadata": {
        "id": "iCsB5tg8kIFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir las variables categóricas en variables dummy\n",
        "df = pd.get_dummies(rna1, columns=['LOCALIDAD', 'GENERO', 'PROVINCIA', 'YEAR NACIMIENTO'])\n",
        "\n",
        "# Separar las características (X) y la etiqueta (y)\n",
        "X = df.drop('SERVICIO', axis=1)\n",
        "y = df['SERVICIO']\n",
        "\n",
        "# Convertir la etiqueta en variables dummy\n",
        "y = pd.get_dummies(y)"
      ],
      "metadata": {
        "id": "BLS2lcb_hiKc"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####División de los datos\n",
        "Usaremos un 70% de los datos para entrenar y del 30% restante, un 70% para validar (21% del total) e ir ajustandio los hiperparámetros (evitando el sobreentrenamiento) y un 30% para el conjunto de test (9% del total), para evaluar el modelo y su precisión al final."
      ],
      "metadata": {
        "id": "wVrutIpJkdSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=42)\n",
        "\n",
        "# Verificar las formas de los conjuntos de datos\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", X_train.shape)\n",
        "print(\"Tamaño del conjunto de validación:\", X_val.shape)\n",
        "print(\"Tamaño del conjunto de prueba:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqQj73uDkdn0",
        "outputId": "c454036c-463e-448c-bc58-0f7df2ff2fa9"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: (1786, 228)\n",
            "Tamaño del conjunto de validación: (536, 228)\n",
            "Tamaño del conjunto de prueba: (230, 228)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VrZHc07-mVIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Definir el modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgOtWJpPmUpA",
        "outputId": "3062dc97-bf61-4930-ce1b-1148d539aa21"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "56/56 [==============================] - 2s 9ms/step - loss: 1.3029 - accuracy: 0.5274 - val_loss: 1.1578 - val_accuracy: 0.5466\n",
            "Epoch 2/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.1046 - accuracy: 0.5773 - val_loss: 1.0903 - val_accuracy: 0.5466\n",
            "Epoch 3/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.0593 - accuracy: 0.5761 - val_loss: 1.0584 - val_accuracy: 0.5466\n",
            "Epoch 4/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 1.0324 - accuracy: 0.5840 - val_loss: 1.0364 - val_accuracy: 0.5821\n",
            "Epoch 5/50\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.9947 - accuracy: 0.5952 - val_loss: 1.0035 - val_accuracy: 0.6082\n",
            "Epoch 6/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.9656 - accuracy: 0.6181 - val_loss: 0.9662 - val_accuracy: 0.6250\n",
            "Epoch 7/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.9384 - accuracy: 0.6243 - val_loss: 0.9543 - val_accuracy: 0.6250\n",
            "Epoch 8/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.9196 - accuracy: 0.6265 - val_loss: 0.9293 - val_accuracy: 0.6343\n",
            "Epoch 9/50\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.8860 - accuracy: 0.6316 - val_loss: 0.9398 - val_accuracy: 0.6530\n",
            "Epoch 10/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.8795 - accuracy: 0.6596 - val_loss: 0.9126 - val_accuracy: 0.6567\n",
            "Epoch 11/50\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.8652 - accuracy: 0.6585 - val_loss: 0.9057 - val_accuracy: 0.6455\n",
            "Epoch 12/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.8519 - accuracy: 0.6529 - val_loss: 0.9058 - val_accuracy: 0.6474\n",
            "Epoch 13/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.8355 - accuracy: 0.6579 - val_loss: 0.9183 - val_accuracy: 0.6642\n",
            "Epoch 14/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.8289 - accuracy: 0.6719 - val_loss: 0.8966 - val_accuracy: 0.6418\n",
            "Epoch 15/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.8273 - accuracy: 0.6697 - val_loss: 0.9013 - val_accuracy: 0.6586\n",
            "Epoch 16/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.8116 - accuracy: 0.6848 - val_loss: 0.8963 - val_accuracy: 0.6586\n",
            "Epoch 17/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.8075 - accuracy: 0.6753 - val_loss: 0.9077 - val_accuracy: 0.6623\n",
            "Epoch 18/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.7932 - accuracy: 0.6769 - val_loss: 0.9014 - val_accuracy: 0.6586\n",
            "Epoch 19/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.7850 - accuracy: 0.6909 - val_loss: 0.8911 - val_accuracy: 0.6586\n",
            "Epoch 20/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.7795 - accuracy: 0.6965 - val_loss: 0.9051 - val_accuracy: 0.6716\n",
            "Epoch 21/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.7832 - accuracy: 0.6797 - val_loss: 0.9065 - val_accuracy: 0.6623\n",
            "Epoch 22/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.7759 - accuracy: 0.6881 - val_loss: 0.8985 - val_accuracy: 0.6604\n",
            "Epoch 23/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.7692 - accuracy: 0.6892 - val_loss: 0.9121 - val_accuracy: 0.6418\n",
            "Epoch 24/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.7519 - accuracy: 0.6971 - val_loss: 0.9092 - val_accuracy: 0.6716\n",
            "Epoch 25/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.7439 - accuracy: 0.6993 - val_loss: 0.9101 - val_accuracy: 0.6530\n",
            "Epoch 26/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.7308 - accuracy: 0.7223 - val_loss: 0.9232 - val_accuracy: 0.6549\n",
            "Epoch 27/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.7441 - accuracy: 0.6960 - val_loss: 0.9164 - val_accuracy: 0.6567\n",
            "Epoch 28/50\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.7406 - accuracy: 0.6870 - val_loss: 0.9143 - val_accuracy: 0.6474\n",
            "Epoch 29/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.7214 - accuracy: 0.7088 - val_loss: 0.9394 - val_accuracy: 0.6530\n",
            "Epoch 30/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.7327 - accuracy: 0.7060 - val_loss: 0.9334 - val_accuracy: 0.6549\n",
            "Epoch 31/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.7211 - accuracy: 0.7004 - val_loss: 0.9310 - val_accuracy: 0.6437\n",
            "Epoch 32/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.7266 - accuracy: 0.7049 - val_loss: 0.9396 - val_accuracy: 0.6455\n",
            "Epoch 33/50\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.7233 - accuracy: 0.7094 - val_loss: 0.9492 - val_accuracy: 0.6437\n",
            "Epoch 34/50\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.7299 - accuracy: 0.7038 - val_loss: 0.9319 - val_accuracy: 0.6194\n",
            "Epoch 35/50\n",
            "56/56 [==============================] - 0s 7ms/step - loss: 0.7068 - accuracy: 0.7032 - val_loss: 0.9414 - val_accuracy: 0.6455\n",
            "Epoch 36/50\n",
            "56/56 [==============================] - 1s 9ms/step - loss: 0.7070 - accuracy: 0.7122 - val_loss: 0.9376 - val_accuracy: 0.6437\n",
            "Epoch 37/50\n",
            "56/56 [==============================] - 0s 9ms/step - loss: 0.7051 - accuracy: 0.7094 - val_loss: 0.9361 - val_accuracy: 0.6399\n",
            "Epoch 38/50\n",
            "56/56 [==============================] - 1s 10ms/step - loss: 0.7036 - accuracy: 0.7240 - val_loss: 0.9477 - val_accuracy: 0.6455\n",
            "Epoch 39/50\n",
            "56/56 [==============================] - 0s 7ms/step - loss: 0.6872 - accuracy: 0.7245 - val_loss: 0.9597 - val_accuracy: 0.6455\n",
            "Epoch 40/50\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.6982 - accuracy: 0.7200 - val_loss: 0.9545 - val_accuracy: 0.6418\n",
            "Epoch 41/50\n",
            "56/56 [==============================] - 0s 7ms/step - loss: 0.6884 - accuracy: 0.7240 - val_loss: 0.9802 - val_accuracy: 0.6362\n",
            "Epoch 42/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.6807 - accuracy: 0.7161 - val_loss: 0.9696 - val_accuracy: 0.6325\n",
            "Epoch 43/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.6927 - accuracy: 0.7268 - val_loss: 0.9585 - val_accuracy: 0.6287\n",
            "Epoch 44/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.7234 - val_loss: 0.9744 - val_accuracy: 0.6474\n",
            "Epoch 45/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.6820 - accuracy: 0.7206 - val_loss: 0.9946 - val_accuracy: 0.6474\n",
            "Epoch 46/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.6741 - accuracy: 0.7200 - val_loss: 0.9796 - val_accuracy: 0.6325\n",
            "Epoch 47/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.7161 - val_loss: 0.9854 - val_accuracy: 0.6511\n",
            "Epoch 48/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.6814 - accuracy: 0.7212 - val_loss: 0.9909 - val_accuracy: 0.6399\n",
            "Epoch 49/50\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.6847 - accuracy: 0.7161 - val_loss: 0.9899 - val_accuracy: 0.6437\n",
            "Epoch 50/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.6848 - accuracy: 0.7139 - val_loss: 0.9969 - val_accuracy: 0.6474\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9539 - accuracy: 0.6435\n",
            "Loss: 0.953904390335083, Accuracy: 0.643478274345398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.activations import relu, tanh\n",
        "\n",
        "# Definir el modelo con hiperparámetros ajustables\n",
        "def create_model(learning_rate=0.001, activation='relu', dropout_rate=0.5):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=X_train.shape[1], activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(32, activation=activation))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear el modelo con hiperparámetros ajustados\n",
        "model = create_model(learning_rate=0.0005, activation='tanh', dropout_rate=0.3)\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkHsUUqkm-b6",
        "outputId": "edab8a2e-7caf-4543-943f-db7fc54f6dbf"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "28/28 [==============================] - 2s 14ms/step - loss: 1.3689 - accuracy: 0.4882 - val_loss: 1.1677 - val_accuracy: 0.5541\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 1.1059 - accuracy: 0.6092 - val_loss: 1.0652 - val_accuracy: 0.6231\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 1.0172 - accuracy: 0.6333 - val_loss: 1.0182 - val_accuracy: 0.6325\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.9718 - accuracy: 0.6445 - val_loss: 0.9784 - val_accuracy: 0.6362\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.9328 - accuracy: 0.6585 - val_loss: 0.9619 - val_accuracy: 0.6455\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.9122 - accuracy: 0.6601 - val_loss: 0.9529 - val_accuracy: 0.6399\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.8889 - accuracy: 0.6657 - val_loss: 0.9451 - val_accuracy: 0.6269\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.8840 - accuracy: 0.6523 - val_loss: 0.9473 - val_accuracy: 0.6362\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.8649 - accuracy: 0.6708 - val_loss: 0.9410 - val_accuracy: 0.6399\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.8747 - accuracy: 0.6629 - val_loss: 0.9393 - val_accuracy: 0.6399\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.8564 - accuracy: 0.6663 - val_loss: 0.9380 - val_accuracy: 0.6437\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 0.8515 - accuracy: 0.6702 - val_loss: 0.9320 - val_accuracy: 0.6175\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.8408 - accuracy: 0.6753 - val_loss: 0.9380 - val_accuracy: 0.6138\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.8377 - accuracy: 0.6803 - val_loss: 0.9324 - val_accuracy: 0.6231\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.8351 - accuracy: 0.6853 - val_loss: 0.9286 - val_accuracy: 0.6213\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.8207 - accuracy: 0.6775 - val_loss: 0.9329 - val_accuracy: 0.6362\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8207 - accuracy: 0.6786 - val_loss: 0.9299 - val_accuracy: 0.6213\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8253 - accuracy: 0.6685 - val_loss: 0.9339 - val_accuracy: 0.6362\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8155 - accuracy: 0.6825 - val_loss: 0.9337 - val_accuracy: 0.6250\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.8199 - accuracy: 0.6820 - val_loss: 0.9329 - val_accuracy: 0.6250\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.8079 - accuracy: 0.6892 - val_loss: 0.9397 - val_accuracy: 0.6269\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.8056 - accuracy: 0.6831 - val_loss: 0.9423 - val_accuracy: 0.6287\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7960 - accuracy: 0.6898 - val_loss: 0.9437 - val_accuracy: 0.6455\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7938 - accuracy: 0.6825 - val_loss: 0.9426 - val_accuracy: 0.6287\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7956 - accuracy: 0.6904 - val_loss: 0.9452 - val_accuracy: 0.6157\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.7931 - accuracy: 0.6853 - val_loss: 0.9418 - val_accuracy: 0.6213\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.7835 - accuracy: 0.6842 - val_loss: 0.9502 - val_accuracy: 0.6343\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.7797 - accuracy: 0.6909 - val_loss: 0.9490 - val_accuracy: 0.6138\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7799 - accuracy: 0.6971 - val_loss: 0.9552 - val_accuracy: 0.6157\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7792 - accuracy: 0.6803 - val_loss: 0.9530 - val_accuracy: 0.6250\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7744 - accuracy: 0.6948 - val_loss: 0.9535 - val_accuracy: 0.6082\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.7823 - accuracy: 0.6915 - val_loss: 0.9601 - val_accuracy: 0.6250\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.7710 - accuracy: 0.6865 - val_loss: 0.9548 - val_accuracy: 0.6250\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7745 - accuracy: 0.6932 - val_loss: 0.9577 - val_accuracy: 0.6269\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7763 - accuracy: 0.6915 - val_loss: 0.9565 - val_accuracy: 0.6063\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7713 - accuracy: 0.6926 - val_loss: 0.9626 - val_accuracy: 0.6213\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.7612 - accuracy: 0.6926 - val_loss: 0.9610 - val_accuracy: 0.6119\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.7729 - accuracy: 0.6865 - val_loss: 0.9581 - val_accuracy: 0.6306\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7694 - accuracy: 0.6876 - val_loss: 0.9637 - val_accuracy: 0.6175\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7634 - accuracy: 0.6848 - val_loss: 0.9617 - val_accuracy: 0.6306\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7541 - accuracy: 0.6988 - val_loss: 0.9602 - val_accuracy: 0.6138\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7678 - accuracy: 0.6988 - val_loss: 0.9634 - val_accuracy: 0.6250\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7613 - accuracy: 0.6920 - val_loss: 0.9639 - val_accuracy: 0.6250\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7615 - accuracy: 0.7010 - val_loss: 0.9717 - val_accuracy: 0.6157\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7514 - accuracy: 0.6999 - val_loss: 0.9660 - val_accuracy: 0.6194\n",
            "Epoch 46/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7625 - accuracy: 0.6960 - val_loss: 0.9639 - val_accuracy: 0.6213\n",
            "Epoch 47/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7594 - accuracy: 0.6915 - val_loss: 0.9661 - val_accuracy: 0.6157\n",
            "Epoch 48/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7475 - accuracy: 0.6965 - val_loss: 0.9688 - val_accuracy: 0.6213\n",
            "Epoch 49/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.7465 - accuracy: 0.6948 - val_loss: 0.9673 - val_accuracy: 0.6269\n",
            "Epoch 50/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.7645 - accuracy: 0.6965 - val_loss: 0.9684 - val_accuracy: 0.6287\n",
            "Epoch 51/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.7630 - accuracy: 0.6887 - val_loss: 0.9660 - val_accuracy: 0.6157\n",
            "Epoch 52/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7533 - accuracy: 0.6915 - val_loss: 0.9643 - val_accuracy: 0.6250\n",
            "Epoch 53/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.7442 - accuracy: 0.7016 - val_loss: 0.9668 - val_accuracy: 0.6269\n",
            "Epoch 54/100\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.7487 - accuracy: 0.6993 - val_loss: 0.9680 - val_accuracy: 0.6250\n",
            "Epoch 55/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.7495 - accuracy: 0.6881 - val_loss: 0.9761 - val_accuracy: 0.6399\n",
            "Epoch 56/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7403 - accuracy: 0.6999 - val_loss: 0.9721 - val_accuracy: 0.6343\n",
            "Epoch 57/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7408 - accuracy: 0.7066 - val_loss: 0.9757 - val_accuracy: 0.6399\n",
            "Epoch 58/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7537 - accuracy: 0.6915 - val_loss: 0.9695 - val_accuracy: 0.6287\n",
            "Epoch 59/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7328 - accuracy: 0.7038 - val_loss: 0.9699 - val_accuracy: 0.6269\n",
            "Epoch 60/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7352 - accuracy: 0.6988 - val_loss: 0.9741 - val_accuracy: 0.6381\n",
            "Epoch 61/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7453 - accuracy: 0.7016 - val_loss: 0.9690 - val_accuracy: 0.6269\n",
            "Epoch 62/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7393 - accuracy: 0.6982 - val_loss: 0.9705 - val_accuracy: 0.6306\n",
            "Epoch 63/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7434 - accuracy: 0.6965 - val_loss: 0.9686 - val_accuracy: 0.6325\n",
            "Epoch 64/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7400 - accuracy: 0.6915 - val_loss: 0.9715 - val_accuracy: 0.6325\n",
            "Epoch 65/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7387 - accuracy: 0.6937 - val_loss: 0.9704 - val_accuracy: 0.6381\n",
            "Epoch 66/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7352 - accuracy: 0.7010 - val_loss: 0.9694 - val_accuracy: 0.6418\n",
            "Epoch 67/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7375 - accuracy: 0.6988 - val_loss: 0.9690 - val_accuracy: 0.6455\n",
            "Epoch 68/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7381 - accuracy: 0.6993 - val_loss: 0.9723 - val_accuracy: 0.6362\n",
            "Epoch 69/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7355 - accuracy: 0.6988 - val_loss: 0.9714 - val_accuracy: 0.6269\n",
            "Epoch 70/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.7352 - accuracy: 0.7049 - val_loss: 0.9750 - val_accuracy: 0.6381\n",
            "Epoch 71/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.7336 - accuracy: 0.7077 - val_loss: 0.9705 - val_accuracy: 0.6343\n",
            "Epoch 72/100\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 0.7332 - accuracy: 0.6926 - val_loss: 0.9729 - val_accuracy: 0.6306\n",
            "Epoch 73/100\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.7283 - accuracy: 0.6976 - val_loss: 0.9713 - val_accuracy: 0.6287\n",
            "Epoch 74/100\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.7182 - accuracy: 0.7077 - val_loss: 0.9692 - val_accuracy: 0.6362\n",
            "Epoch 75/100\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.7289 - accuracy: 0.7027 - val_loss: 0.9732 - val_accuracy: 0.6493\n",
            "Epoch 76/100\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.7335 - accuracy: 0.7083 - val_loss: 0.9706 - val_accuracy: 0.6437\n",
            "Epoch 77/100\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.7242 - accuracy: 0.7027 - val_loss: 0.9712 - val_accuracy: 0.6362\n",
            "Epoch 78/100\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 0.7391 - accuracy: 0.6965 - val_loss: 0.9699 - val_accuracy: 0.6362\n",
            "Epoch 79/100\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.7214 - accuracy: 0.7027 - val_loss: 0.9729 - val_accuracy: 0.6455\n",
            "Epoch 80/100\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.7259 - accuracy: 0.7077 - val_loss: 0.9696 - val_accuracy: 0.6455\n",
            "Epoch 81/100\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.7247 - accuracy: 0.6982 - val_loss: 0.9705 - val_accuracy: 0.6455\n",
            "Epoch 82/100\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.7215 - accuracy: 0.7133 - val_loss: 0.9744 - val_accuracy: 0.6474\n",
            "Epoch 83/100\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.7243 - accuracy: 0.7156 - val_loss: 0.9758 - val_accuracy: 0.6362\n",
            "Epoch 84/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7274 - accuracy: 0.7066 - val_loss: 0.9790 - val_accuracy: 0.6381\n",
            "Epoch 85/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7233 - accuracy: 0.7027 - val_loss: 0.9755 - val_accuracy: 0.6418\n",
            "Epoch 86/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7323 - accuracy: 0.7038 - val_loss: 0.9741 - val_accuracy: 0.6474\n",
            "Epoch 87/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7194 - accuracy: 0.7027 - val_loss: 0.9742 - val_accuracy: 0.6511\n",
            "Epoch 88/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7184 - accuracy: 0.7049 - val_loss: 0.9793 - val_accuracy: 0.6437\n",
            "Epoch 89/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7258 - accuracy: 0.7049 - val_loss: 0.9801 - val_accuracy: 0.6418\n",
            "Epoch 90/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7159 - accuracy: 0.7094 - val_loss: 0.9786 - val_accuracy: 0.6455\n",
            "Epoch 91/100\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.7071 - accuracy: 0.7060 - val_loss: 0.9774 - val_accuracy: 0.6493\n",
            "Epoch 92/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7122 - accuracy: 0.7105 - val_loss: 0.9832 - val_accuracy: 0.6418\n",
            "Epoch 93/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7248 - accuracy: 0.6909 - val_loss: 0.9777 - val_accuracy: 0.6493\n",
            "Epoch 94/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7191 - accuracy: 0.7066 - val_loss: 0.9795 - val_accuracy: 0.6474\n",
            "Epoch 95/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7181 - accuracy: 0.7066 - val_loss: 0.9846 - val_accuracy: 0.6493\n",
            "Epoch 96/100\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7105 - accuracy: 0.7088 - val_loss: 0.9833 - val_accuracy: 0.6511\n",
            "Epoch 97/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7150 - accuracy: 0.7010 - val_loss: 0.9838 - val_accuracy: 0.6530\n",
            "Epoch 98/100\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.7176 - accuracy: 0.7111 - val_loss: 0.9821 - val_accuracy: 0.6455\n",
            "Epoch 99/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7028 - accuracy: 0.7128 - val_loss: 0.9858 - val_accuracy: 0.6493\n",
            "Epoch 100/100\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7123 - accuracy: 0.7049 - val_loss: 0.9797 - val_accuracy: 0.6493\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8885 - accuracy: 0.6435\n",
            "Loss: 0.8884846568107605, Accuracy: 0.643478274345398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Definir el modelo con hiperparámetros ajustables\n",
        "def create_simple_model(learning_rate=0.001, dropout_rate=0.3):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear el modelo con hiperparámetros ajustados\n",
        "model = create_simple_model(learning_rate=0.001, dropout_rate=0.3)\n",
        "\n",
        "# Añadir EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiP0_eMYnx0v",
        "outputId": "b2a0732d-e037-4c02-f1db-fe94c27361f4"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "56/56 [==============================] - 2s 11ms/step - loss: 1.3841 - accuracy: 0.5050 - val_loss: 1.1728 - val_accuracy: 0.5466\n",
            "Epoch 2/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.1172 - accuracy: 0.5795 - val_loss: 1.0901 - val_accuracy: 0.5466\n",
            "Epoch 3/50\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0536 - accuracy: 0.5941 - val_loss: 1.0338 - val_accuracy: 0.6157\n",
            "Epoch 4/50\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.9935 - accuracy: 0.6237 - val_loss: 0.9955 - val_accuracy: 0.6474\n",
            "Epoch 5/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.9580 - accuracy: 0.6405 - val_loss: 0.9709 - val_accuracy: 0.6549\n",
            "Epoch 6/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.9312 - accuracy: 0.6411 - val_loss: 0.9499 - val_accuracy: 0.6418\n",
            "Epoch 7/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.9407 - accuracy: 0.6456 - val_loss: 0.9432 - val_accuracy: 0.6437\n",
            "Epoch 8/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.8894 - accuracy: 0.6585 - val_loss: 0.9343 - val_accuracy: 0.6455\n",
            "Epoch 9/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.8838 - accuracy: 0.6534 - val_loss: 0.9207 - val_accuracy: 0.6530\n",
            "Epoch 10/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.8543 - accuracy: 0.6579 - val_loss: 0.9084 - val_accuracy: 0.6549\n",
            "Epoch 11/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.8361 - accuracy: 0.6618 - val_loss: 0.9014 - val_accuracy: 0.6567\n",
            "Epoch 12/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.8321 - accuracy: 0.6708 - val_loss: 0.9020 - val_accuracy: 0.6567\n",
            "Epoch 13/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.8439 - accuracy: 0.6618 - val_loss: 0.9028 - val_accuracy: 0.6493\n",
            "Epoch 14/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.8024 - accuracy: 0.6680 - val_loss: 0.9088 - val_accuracy: 0.6437\n",
            "Epoch 15/50\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.8044 - accuracy: 0.6674 - val_loss: 0.9095 - val_accuracy: 0.6511\n",
            "Epoch 16/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.8000 - accuracy: 0.6781 - val_loss: 0.9136 - val_accuracy: 0.6511\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8308 - accuracy: 0.6826\n",
            "Loss: 0.8308410048484802, Accuracy: 0.6826087236404419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Modelo XGBoost"
      ],
      "metadata": {
        "id": "hMkBHClJvw5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Codificar las etiquetas usando LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y.idxmax(axis=1))  # Convertir de one-hot encoding a etiquetas enteras\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo XGBoost\n",
        "xgb_model = xgb.XGBClassifier(objective='multi:softprob', num_class=len(label_encoder.classes_))\n",
        "xgb_model.fit(X_train_xgb, y_train_xgb)\n",
        "\n",
        "# Obtener las predicciones de probabilidad del conjunto de prueba\n",
        "X_train_nn = xgb_model.predict_proba(X_train_xgb)\n",
        "X_test_nn = xgb_model.predict_proba(X_test_xgb)\n",
        "\n",
        "# Convertir las etiquetas del conjunto de prueba a one-hot encoding\n",
        "y_train_nn = to_categorical(y_train_xgb, num_classes=len(label_encoder.classes_))\n",
        "y_test_nn = to_categorical(y_test_xgb, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "# Definir el modelo de red neuronal\n",
        "def create_nn_model(input_dim, learning_rate=0.001, dropout_rate=0.3):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(y_train_nn.shape[1], activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear el modelo de red neuronal\n",
        "nn_model = create_nn_model(input_dim=X_train_nn.shape[1])\n",
        "\n",
        "# Añadir EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Entrenar el modelo de red neuronal\n",
        "history = nn_model.fit(X_train_nn, y_train_nn, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = nn_model.evaluate(X_test_nn, y_test_nn)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "LmD4u_WFv0Bb",
        "outputId": "b1442ef6-44ae-4fe7-8e61-6edd23d83c1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 14ms/step - loss: 1.4170 - accuracy: 0.5420 - val_loss: 1.1813 - val_accuracy: 0.5642\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0717 - accuracy: 0.5917 - val_loss: 0.9531 - val_accuracy: 0.6508\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9300 - accuracy: 0.6821 - val_loss: 0.8578 - val_accuracy: 0.7039\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8603 - accuracy: 0.7017 - val_loss: 0.8187 - val_accuracy: 0.7095\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8244 - accuracy: 0.7024 - val_loss: 0.8009 - val_accuracy: 0.7123\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8132 - accuracy: 0.7059 - val_loss: 0.7898 - val_accuracy: 0.7179\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7962 - accuracy: 0.7129 - val_loss: 0.7823 - val_accuracy: 0.7235\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7856 - accuracy: 0.7213 - val_loss: 0.7723 - val_accuracy: 0.7067\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7836 - accuracy: 0.7150 - val_loss: 0.7622 - val_accuracy: 0.7123\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7733 - accuracy: 0.7164 - val_loss: 0.7583 - val_accuracy: 0.7095\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7627 - accuracy: 0.7206 - val_loss: 0.7602 - val_accuracy: 0.6983\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7663 - accuracy: 0.7066 - val_loss: 0.7628 - val_accuracy: 0.6899\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7567 - accuracy: 0.7164 - val_loss: 0.7675 - val_accuracy: 0.6899\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7642 - accuracy: 0.7192 - val_loss: 0.7515 - val_accuracy: 0.7011\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7583 - accuracy: 0.7171 - val_loss: 0.7552 - val_accuracy: 0.7123\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7543 - accuracy: 0.7136 - val_loss: 0.7532 - val_accuracy: 0.6983\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7463 - accuracy: 0.7129 - val_loss: 0.7497 - val_accuracy: 0.7011\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7483 - accuracy: 0.7143 - val_loss: 0.7477 - val_accuracy: 0.7039\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7528 - accuracy: 0.7080 - val_loss: 0.7519 - val_accuracy: 0.7011\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7575 - accuracy: 0.7171 - val_loss: 0.7486 - val_accuracy: 0.7039\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7380 - accuracy: 0.7199 - val_loss: 0.7499 - val_accuracy: 0.7095\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7380 - accuracy: 0.7108 - val_loss: 0.7491 - val_accuracy: 0.7039\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7379 - accuracy: 0.7157 - val_loss: 0.7463 - val_accuracy: 0.6983\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7426 - accuracy: 0.7129 - val_loss: 0.7481 - val_accuracy: 0.7011\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7366 - accuracy: 0.7255 - val_loss: 0.7571 - val_accuracy: 0.6816\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7404 - accuracy: 0.7192 - val_loss: 0.7512 - val_accuracy: 0.6983\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7298 - accuracy: 0.7164 - val_loss: 0.7435 - val_accuracy: 0.7095\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7301 - accuracy: 0.7164 - val_loss: 0.7455 - val_accuracy: 0.7067\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7400 - accuracy: 0.7171 - val_loss: 0.7500 - val_accuracy: 0.7039\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7259 - accuracy: 0.7276 - val_loss: 0.7447 - val_accuracy: 0.6844\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7257 - accuracy: 0.7150 - val_loss: 0.7448 - val_accuracy: 0.6872\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7337 - accuracy: 0.7150 - val_loss: 0.7420 - val_accuracy: 0.6844\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7198 - accuracy: 0.7206 - val_loss: 0.7487 - val_accuracy: 0.6899\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7213 - accuracy: 0.7136 - val_loss: 0.7521 - val_accuracy: 0.6872\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7162 - accuracy: 0.7136 - val_loss: 0.7473 - val_accuracy: 0.6872\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7105 - accuracy: 0.7157 - val_loss: 0.7427 - val_accuracy: 0.6899\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7171 - accuracy: 0.7262 - val_loss: 0.7439 - val_accuracy: 0.6844\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7211 - accuracy: 0.7129 - val_loss: 0.7415 - val_accuracy: 0.6816\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7144 - accuracy: 0.7234 - val_loss: 0.7455 - val_accuracy: 0.7039\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7081 - accuracy: 0.7248 - val_loss: 0.7418 - val_accuracy: 0.6844\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7146 - accuracy: 0.7192 - val_loss: 0.7465 - val_accuracy: 0.6788\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7221 - accuracy: 0.7206 - val_loss: 0.7487 - val_accuracy: 0.6872\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7183 - accuracy: 0.7192 - val_loss: 0.7495 - val_accuracy: 0.6816\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7087 - accuracy: 0.7199 - val_loss: 0.7436 - val_accuracy: 0.6816\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7154 - accuracy: 0.7150 - val_loss: 0.7409 - val_accuracy: 0.6788\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7115 - accuracy: 0.7164 - val_loss: 0.7421 - val_accuracy: 0.6760\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7063 - accuracy: 0.7164 - val_loss: 0.7465 - val_accuracy: 0.7039\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7065 - accuracy: 0.7206 - val_loss: 0.7451 - val_accuracy: 0.6816\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7065 - accuracy: 0.7262 - val_loss: 0.7456 - val_accuracy: 0.6760\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7084 - accuracy: 0.7227 - val_loss: 0.7411 - val_accuracy: 0.6844\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7089 - accuracy: 0.7192 - val_loss: 0.7414 - val_accuracy: 0.6816\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.7043 - accuracy: 0.7304 - val_loss: 0.7472 - val_accuracy: 0.6788\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7080 - accuracy: 0.7164 - val_loss: 0.7417 - val_accuracy: 0.6872\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7047 - accuracy: 0.7164 - val_loss: 0.7477 - val_accuracy: 0.6788\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7107 - accuracy: 0.7150 - val_loss: 0.7460 - val_accuracy: 0.6760\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.9266 - accuracy: 0.6462\n",
            "Loss: 0.9266080260276794, Accuracy: 0.6462141275405884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de un registro individual (preprocesado) con el conjunto de prueba de XGBoost\n",
        "new_record_xgb = X_test_xgb.iloc[3]\n",
        "\n",
        "# Convertir el nuevo registro a un DataFrame\n",
        "new_record_xgb_df = pd.DataFrame([new_record_xgb])\n",
        "\n",
        "# Obtener las predicciones de probabilidad del modelo XGBoost\n",
        "new_record_nn_input = xgb_model.predict_proba(new_record_xgb_df)\n",
        "\n",
        "# Predecir usando el modelo de red neuronal entrenado\n",
        "predictions = nn_model.predict(new_record_nn_input)\n",
        "\n",
        "# Obtener las probabilidades para cada tipo de servicio\n",
        "service_probabilities = predictions[0]\n",
        "\n",
        "# Obtener el servicio objetivo original\n",
        "original_service = y_test_xgb[3]  # Indexar directamente el array de NumPy\n",
        "\n",
        "# Convertir el servicio objetivo original a etiqueta de texto\n",
        "original_service_label = label_encoder.inverse_transform([original_service])[0]\n",
        "\n",
        "# Imprimir el servicio objetivo original y las probabilidades\n",
        "service_labels = label_encoder.classes_  # Obtener las etiquetas originales\n",
        "print(f\"Original Servicio: {original_service_label}\")\n",
        "for label, prob in zip(service_labels, service_probabilities):\n",
        "    print(f\"Servicio: {label}, Probabilidad: {prob:.4f}\")"
      ],
      "metadata": {
        "id": "-NU3X_Ygw6RM",
        "outputId": "81f85dec-8ddf-435a-b702-cef16c4e334d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "Original Servicio: SO\n",
            "Servicio: AT, Probabilidad: 0.0001\n",
            "Servicio: EM, Probabilidad: 0.0058\n",
            "Servicio: LOG, Probabilidad: 0.0036\n",
            "Servicio: SAAF, Probabilidad: 0.0221\n",
            "Servicio: SO, Probabilidad: 0.9684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ejemplo de un registro individual (preprocesado) con el conjunto de prueba de XGBoost\n",
        "new_record_xgb = X_test_xgb.iloc[22]\n",
        "\n",
        "# Convertir el nuevo registro a un DataFrame\n",
        "new_record_xgb_df = pd.DataFrame([new_record_xgb])\n",
        "\n",
        "# Obtener las predicciones de probabilidad del modelo XGBoost\n",
        "new_record_nn_input = xgb_model.predict_proba(new_record_xgb_df)\n",
        "\n",
        "# Predecir usando el modelo de red neuronal entrenado\n",
        "predictions = nn_model.predict(new_record_nn_input)\n",
        "\n",
        "# Obtener las probabilidades para cada tipo de servicio\n",
        "service_probabilities = predictions[0]\n",
        "\n",
        "# Obtener el servicio objetivo original\n",
        "original_service = y_test_xgb[22]  # Indexar directamente el array de NumPy\n",
        "\n",
        "# Convertir el servicio objetivo original a etiqueta de texto\n",
        "original_service_label = label_encoder.inverse_transform([original_service])[0]\n",
        "\n",
        "# Imprimir el servicio objetivo original y las probabilidades\n",
        "service_labels = label_encoder.classes_  # Obtener las etiquetas originales\n",
        "print(f\"Original Servicio: {original_service_label}\")\n",
        "for label, prob in zip(service_labels, service_probabilities):\n",
        "    print(f\"Servicio: {label}, Probabilidad: {prob:.4f}\")"
      ],
      "metadata": {
        "id": "EIANTAKBxIMN",
        "outputId": "ba341c8a-d2a8-4f7e-e465-0d34119cd622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "Original Servicio: EM\n",
            "Servicio: AT, Probabilidad: 0.3682\n",
            "Servicio: EM, Probabilidad: 0.5760\n",
            "Servicio: LOG, Probabilidad: 0.0043\n",
            "Servicio: SAAF, Probabilidad: 0.0198\n",
            "Servicio: SO, Probabilidad: 0.0317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de un registro individual (preprocesado) con el conjunto de prueba de XGBoost\n",
        "new_record_xgb = X_test_xgb.iloc[70]\n",
        "\n",
        "# Convertir el nuevo registro a un DataFrame\n",
        "new_record_xgb_df = pd.DataFrame([new_record_xgb])\n",
        "\n",
        "# Obtener las predicciones de probabilidad del modelo XGBoost\n",
        "new_record_nn_input = xgb_model.predict_proba(new_record_xgb_df)\n",
        "\n",
        "# Predecir usando el modelo de red neuronal entrenado\n",
        "predictions = nn_model.predict(new_record_nn_input)\n",
        "\n",
        "# Obtener las probabilidades para cada tipo de servicio\n",
        "service_probabilities = predictions[0]\n",
        "\n",
        "# Obtener el servicio objetivo original\n",
        "original_service = y_test_xgb[70]  # Indexar directamente el array de NumPy\n",
        "\n",
        "# Convertir el servicio objetivo original a etiqueta de texto\n",
        "original_service_label = label_encoder.inverse_transform([original_service])[0]\n",
        "\n",
        "# Imprimir el servicio objetivo original y las probabilidades\n",
        "service_labels = label_encoder.classes_  # Obtener las etiquetas originales\n",
        "print(f\"Original Servicio: {original_service_label}\")\n",
        "for label, prob in zip(service_labels, service_probabilities):\n",
        "    print(f\"Servicio: {label}, Probabilidad: {prob:.4f}\")"
      ],
      "metadata": {
        "id": "T4xTHLwVxJUd",
        "outputId": "c5b3149e-cdda-48d5-a324-b3c813dfb292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "Original Servicio: AT\n",
            "Servicio: AT, Probabilidad: 0.1020\n",
            "Servicio: EM, Probabilidad: 0.0166\n",
            "Servicio: LOG, Probabilidad: 0.2469\n",
            "Servicio: SAAF, Probabilidad: 0.1943\n",
            "Servicio: SO, Probabilidad: 0.4403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RNA predictiva con datos generados\n",
        "Red Neuronal con 8000 registros más que han sido creados teniendo en cuenta las estadísticas reales de los datos, es decir, contemplando cómo se distribuyen por edad, género y localidad y, obviamente, el municipio y la provincia correctamente computados.\n",
        "\n",
        "Esto se hace para intentar aumentar el porcentaje de precisión obtenido."
      ],
      "metadata": {
        "id": "eomz_QLmjN6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the frequency of each element in the 'SERVICIO' column\n",
        "service_frequency = df['SERVICIO'].value_counts()\n",
        "\n",
        "# Group by 'PROVINCIA' and 'SERVICIO' and count the occurrences\n",
        "service_province_freq = shuffled_combined_df.groupby(['PROVINCIA', 'SERVICIO']).size().reset_index(name='COUNT')\n",
        "\n",
        "# Function to assign services based on frequency\n",
        "def assign_service(row, freq_df):\n",
        "    province = row['PROVINCIA']\n",
        "    possible_services = freq_df[freq_df['PROVINCIA'] == province]\n",
        "    if possible_services.empty:\n",
        "        return np.nan\n",
        "    else:\n",
        "        return np.random.choice(possible_services['SERVICIO'].values, p=possible_services['COUNT'].values / possible_services['COUNT'].sum())\n",
        "\n",
        "# Apply the function to assign services\n",
        "df_8000rows['SERVICIO'] = df_8000rows.apply(assign_service, axis=1, args=(service_province_freq,))\n",
        "\n",
        "# Ensure balanced classes by sampling\n",
        "min_class_size = service_frequency.min()\n",
        "balanced_df = df_8000rows.groupby('SERVICIO').apply(lambda x: x.sample(n=min_class_size, replace=True)).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "1uB0r6aSmkZd"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the frequency of each service\n",
        "service_frequency = shuffled_combined_df['SERVICIO'].value_counts()\n",
        "\n",
        "# Set the target number of records per service\n",
        "target_size = 1457\n",
        "\n",
        "# Create a balanced dataframe starting with the initial shuffled data\n",
        "to_use_df = shuffled_combined_df.copy()\n",
        "\n",
        "# Loop through each service to balance the dataframe\n",
        "for service, count in service_frequency.items():\n",
        "    if count < target_size:\n",
        "        # Get the rows for the current service\n",
        "        service_df = balanced_df[balanced_df['SERVICIO'] == service]\n",
        "        # Sample additional rows with replacement to reach the target size\n",
        "        additional_samples = service_df.sample(n=target_size - count, replace=True)\n",
        "        to_use_df = pd.concat([to_use_df, additional_samples])\n",
        "\n",
        "# Shuffle the final balanced dataframe\n",
        "to_use_df = to_use_df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "NriTgA3RnJXD"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the rows of the dataframe ready to use\n",
        "to_use_df = to_use_df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "pTr3ars6w5BF"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the min and max year in the 'YEAR NACIMIENTO' column\n",
        "min_year = int(to_use_df['YEAR NACIMIENTO'].min())\n",
        "max_year = int(to_use_df['YEAR NACIMIENTO'].max())\n",
        "\n",
        "# Function to generate random years with the specified distribution\n",
        "def generate_random_years(size):\n",
        "    return np.random.randint(min_year, max_year + 1, size=int(size))\n",
        "\n",
        "# Function to insert random years into the 'YEAR NACIMIENTO' column where it is empty\n",
        "def insert_random_years(df):\n",
        "    # Find the indices where 'YEAR NACIMIENTO' is empty\n",
        "    empty_indices = df[df['YEAR NACIMIENTO'].isna()].index\n",
        "\n",
        "    # Generate random years based on the specified distribution\n",
        "    random_years = generate_random_years(len(empty_indices))\n",
        "\n",
        "    # Assign these random years to the empty 'YEAR NACIMIENTO' rows\n",
        "    df.loc[empty_indices, 'YEAR NACIMIENTO'] = random_years\n",
        "    return df\n",
        "\n",
        "# Apply the function to the dataframe\n",
        "to_use_df = insert_random_years(to_use_df)"
      ],
      "metadata": {
        "id": "syZ8IdqFxPc5"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una función para categorizar por grupos de edad\n",
        "def categorize_age(year):\n",
        "    if year < 1940:\n",
        "        return 'Antes de 1940'\n",
        "    elif year < 1960:\n",
        "        return '1940-1959'\n",
        "    elif year < 1980:\n",
        "        return '1960-1979'\n",
        "    elif year < 2000:\n",
        "        return '1980-1999'\n",
        "    else:\n",
        "        return '2000 en adelante'\n",
        "\n",
        "# Aplicar la función a la columna 'YEAR NACIMIENTO'\n",
        "to_use_df['YEAR NACIMIENTO'] = to_use_df['YEAR NACIMIENTO'].apply(categorize_age)\n",
        "\n",
        "# Ver el resultado\n",
        "print(to_use_df.head())"
      ],
      "metadata": {
        "id": "XU2JPoSa4vau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c7cd31-ba68-4081-e886-2dc397978796"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                LOCALIDAD  GENERO   YEAR NACIMIENTO    PROVINCIA SERVICIO\n",
            "0   VILLANUEVA DE LA JARA   MUJER         1980-1999       CUENCA      LOG\n",
            "1               VALDEMECA   MUJER         1960-1979       CUENCA      LOG\n",
            "2  VILLAMAYOR DE SANTIAGO   MUJER  2000 en adelante       CUENCA      LOG\n",
            "3      CIRUELOS DEL PINAR   MUJER         1980-1999  GUADALAJARA      LOG\n",
            "4          LA PUEBLANUEVA  HOMBRE         1960-1979       TOLEDO       AT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determina la cantidad de servicios únicos\n",
        "unique_services = to_use_df['SERVICIO'].unique()\n",
        "num_services = len(unique_services)\n",
        "\n",
        "# Determina cuántos registros por servicio necesitas para el conjunto de prueba\n",
        "test_size_per_service = 85 // num_services\n",
        "\n",
        "# Si hay más de 85 registros, ajusta la muestra para que esté balanceada\n",
        "if test_size_per_service * num_services < 85:\n",
        "    additional_samples = 85 - (test_size_per_service * num_services)\n",
        "else:\n",
        "    additional_samples = 0\n",
        "\n",
        "# Crear el conjunto de prueba balanceado\n",
        "test_df = pd.DataFrame()\n",
        "\n",
        "for service in unique_services:\n",
        "    service_df = to_use_df[to_use_df['SERVICIO'] == service]\n",
        "    test_samples = service_df.sample(n=test_size_per_service, replace=False)\n",
        "    test_df = pd.concat([test_df, test_samples])\n",
        "\n",
        "# Añadir muestras adicionales si es necesario\n",
        "if additional_samples > 0:\n",
        "    additional_df = to_use_df[~to_use_df.index.isin(test_df.index)]\n",
        "    additional_samples_df = additional_df.sample(n=additional_samples, replace=False)\n",
        "    test_df = pd.concat([test_df, additional_samples_df])\n",
        "\n",
        "# Eliminar las filas seleccionadas del dataframe original para crear el conjunto de entrenamiento/validación\n",
        "to_use_df = to_use_df.drop(test_df.index)\n",
        "\n",
        "# Verifica el conjunto de prueba\n",
        "print(test_df['SERVICIO'].value_counts())\n",
        "print(test_df.shape)\n",
        "\n",
        "# Verifica el conjunto de entrenamiento/validación\n",
        "print(to_use_df.shape)"
      ],
      "metadata": {
        "id": "3QdShOyt2c_6",
        "outputId": "c1a12e81-d66a-46e0-808c-0e3fa79da8e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SERVICIO\n",
            "LOG     17\n",
            "AT      17\n",
            "SAAF    17\n",
            "EM      17\n",
            "SO      17\n",
            "Name: count, dtype: int64\n",
            "(85, 5)\n",
            "(7200, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Red Neuronal Predictiva\n",
        "\n",
        "Creación de una red neuronal predictiva que sea capaz de clasificar nuevos usuarios con buena precisión en servicio y provincia."
      ],
      "metadata": {
        "id": "2dYYkD8OoRlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir las variables categóricas en variables dummy\n",
        "df = pd.get_dummies(to_use_df, columns=['LOCALIDAD', 'GENERO', 'PROVINCIA', 'YEAR NACIMIENTO'])\n",
        "\n",
        "# Separar las características (X) y la etiqueta (y)\n",
        "X = df.drop('SERVICIO', axis=1)\n",
        "y = df['SERVICIO']\n",
        "\n",
        "# Convertir la etiqueta en variables dummy\n",
        "y = pd.get_dummies(y)"
      ],
      "metadata": {
        "id": "HdSgywBv2mHU"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=42)\n",
        "\n",
        "# Verificar las formas de los conjuntos de datos\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", X_train.shape)\n",
        "print(\"Tamaño del conjunto de validación:\", X_val.shape)\n",
        "print(\"Tamaño del conjunto de prueba:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M9z1jBprDBF",
        "outputId": "9594b1e5-2ffd-4ae7-ec85-4e9787febcf1"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: (5040, 504)\n",
            "Tamaño del conjunto de validación: (1512, 504)\n",
            "Tamaño del conjunto de prueba: (648, 504)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAF_-B59qr0_",
        "outputId": "dc07ff98-fa6f-4466-c6b9-042b88481ce6"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "158/158 [==============================] - 2s 9ms/step - loss: 1.5199 - accuracy: 0.3200 - val_loss: 1.3087 - val_accuracy: 0.4597\n",
            "Epoch 2/50\n",
            "158/158 [==============================] - 1s 7ms/step - loss: 1.2506 - accuracy: 0.4843 - val_loss: 1.0200 - val_accuracy: 0.6620\n",
            "Epoch 3/50\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 1.0001 - accuracy: 0.6266 - val_loss: 0.7826 - val_accuracy: 0.7110\n",
            "Epoch 4/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.8100 - accuracy: 0.7127 - val_loss: 0.6498 - val_accuracy: 0.7679\n",
            "Epoch 5/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.6941 - accuracy: 0.7565 - val_loss: 0.5996 - val_accuracy: 0.7831\n",
            "Epoch 6/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.6266 - accuracy: 0.7760 - val_loss: 0.5440 - val_accuracy: 0.8056\n",
            "Epoch 7/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.5906 - accuracy: 0.7905 - val_loss: 0.5291 - val_accuracy: 0.8122\n",
            "Epoch 8/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.5457 - accuracy: 0.8038 - val_loss: 0.5053 - val_accuracy: 0.8148\n",
            "Epoch 9/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.5230 - accuracy: 0.8131 - val_loss: 0.4970 - val_accuracy: 0.8082\n",
            "Epoch 10/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.5042 - accuracy: 0.8181 - val_loss: 0.4985 - val_accuracy: 0.8148\n",
            "Epoch 11/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.4859 - accuracy: 0.8274 - val_loss: 0.4878 - val_accuracy: 0.8142\n",
            "Epoch 12/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.4638 - accuracy: 0.8306 - val_loss: 0.4853 - val_accuracy: 0.8142\n",
            "Epoch 13/50\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 0.4461 - accuracy: 0.8349 - val_loss: 0.4931 - val_accuracy: 0.8155\n",
            "Epoch 14/50\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 0.4386 - accuracy: 0.8421 - val_loss: 0.4808 - val_accuracy: 0.8214\n",
            "Epoch 15/50\n",
            "158/158 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8373 - val_loss: 0.4917 - val_accuracy: 0.8115\n",
            "Epoch 16/50\n",
            "158/158 [==============================] - 1s 9ms/step - loss: 0.4189 - accuracy: 0.8413 - val_loss: 0.4908 - val_accuracy: 0.8142\n",
            "Epoch 17/50\n",
            "158/158 [==============================] - 1s 8ms/step - loss: 0.4195 - accuracy: 0.8423 - val_loss: 0.4922 - val_accuracy: 0.8161\n",
            "Epoch 18/50\n",
            "158/158 [==============================] - 1s 9ms/step - loss: 0.4005 - accuracy: 0.8466 - val_loss: 0.5071 - val_accuracy: 0.8128\n",
            "Epoch 19/50\n",
            "158/158 [==============================] - 1s 7ms/step - loss: 0.3934 - accuracy: 0.8435 - val_loss: 0.5116 - val_accuracy: 0.8115\n",
            "Epoch 20/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3935 - accuracy: 0.8480 - val_loss: 0.4994 - val_accuracy: 0.8155\n",
            "Epoch 21/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3928 - accuracy: 0.8470 - val_loss: 0.4955 - val_accuracy: 0.8214\n",
            "Epoch 22/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3894 - accuracy: 0.8462 - val_loss: 0.5073 - val_accuracy: 0.8214\n",
            "Epoch 23/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.3879 - accuracy: 0.8456 - val_loss: 0.5082 - val_accuracy: 0.8201\n",
            "Epoch 24/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3757 - accuracy: 0.8524 - val_loss: 0.5077 - val_accuracy: 0.8214\n",
            "Epoch 25/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3726 - accuracy: 0.8494 - val_loss: 0.5049 - val_accuracy: 0.8175\n",
            "Epoch 26/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3795 - accuracy: 0.8498 - val_loss: 0.5183 - val_accuracy: 0.8201\n",
            "Epoch 27/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3734 - accuracy: 0.8520 - val_loss: 0.5098 - val_accuracy: 0.8188\n",
            "Epoch 28/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.3595 - accuracy: 0.8579 - val_loss: 0.5300 - val_accuracy: 0.8161\n",
            "Epoch 29/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3650 - accuracy: 0.8558 - val_loss: 0.5275 - val_accuracy: 0.8261\n",
            "Epoch 30/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3633 - accuracy: 0.8510 - val_loss: 0.5292 - val_accuracy: 0.8241\n",
            "Epoch 31/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3618 - accuracy: 0.8544 - val_loss: 0.5271 - val_accuracy: 0.8261\n",
            "Epoch 32/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.3630 - accuracy: 0.8544 - val_loss: 0.5365 - val_accuracy: 0.8194\n",
            "Epoch 33/50\n",
            "158/158 [==============================] - 1s 7ms/step - loss: 0.3478 - accuracy: 0.8621 - val_loss: 0.5308 - val_accuracy: 0.8261\n",
            "Epoch 34/50\n",
            "158/158 [==============================] - 1s 7ms/step - loss: 0.3493 - accuracy: 0.8558 - val_loss: 0.5543 - val_accuracy: 0.8241\n",
            "Epoch 35/50\n",
            "158/158 [==============================] - 1s 7ms/step - loss: 0.3452 - accuracy: 0.8595 - val_loss: 0.5517 - val_accuracy: 0.8228\n",
            "Epoch 36/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3486 - accuracy: 0.8609 - val_loss: 0.5489 - val_accuracy: 0.8228\n",
            "Epoch 37/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3578 - accuracy: 0.8565 - val_loss: 0.5388 - val_accuracy: 0.8214\n",
            "Epoch 38/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3452 - accuracy: 0.8595 - val_loss: 0.5606 - val_accuracy: 0.8221\n",
            "Epoch 39/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.3476 - accuracy: 0.8571 - val_loss: 0.5522 - val_accuracy: 0.8267\n",
            "Epoch 40/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.3413 - accuracy: 0.8605 - val_loss: 0.5709 - val_accuracy: 0.8241\n",
            "Epoch 41/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3402 - accuracy: 0.8601 - val_loss: 0.5690 - val_accuracy: 0.8214\n",
            "Epoch 42/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8635 - val_loss: 0.5767 - val_accuracy: 0.8181\n",
            "Epoch 43/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.3415 - accuracy: 0.8589 - val_loss: 0.5747 - val_accuracy: 0.8247\n",
            "Epoch 44/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.3304 - accuracy: 0.8645 - val_loss: 0.5912 - val_accuracy: 0.8188\n",
            "Epoch 45/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3371 - accuracy: 0.8581 - val_loss: 0.5925 - val_accuracy: 0.8228\n",
            "Epoch 46/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3457 - accuracy: 0.8569 - val_loss: 0.5832 - val_accuracy: 0.8208\n",
            "Epoch 47/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.3306 - accuracy: 0.8647 - val_loss: 0.5897 - val_accuracy: 0.8234\n",
            "Epoch 48/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3305 - accuracy: 0.8633 - val_loss: 0.6050 - val_accuracy: 0.8234\n",
            "Epoch 49/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.3372 - accuracy: 0.8589 - val_loss: 0.6009 - val_accuracy: 0.8221\n",
            "Epoch 50/50\n",
            "158/158 [==============================] - 1s 8ms/step - loss: 0.3300 - accuracy: 0.8597 - val_loss: 0.6136 - val_accuracy: 0.8188\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.8148\n",
            "Loss: 0.5936059951782227, Accuracy: 0.8148148059844971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el modelo con hiperparámetros ajustables\n",
        "def create_model(learning_rate=0.001, activation='relu', dropout_rate=0.5):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=X_train.shape[1], activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(32, activation=activation))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear el modelo con hiperparámetros ajustados\n",
        "model = create_model(learning_rate=0.0005, activation='tanh', dropout_rate=0.3)\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIzu839YqxHC",
        "outputId": "401fb3e0-c496-4e6a-e926-24e26c0cec6d"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 2s 9ms/step - loss: 1.4881 - accuracy: 0.3671 - val_loss: 1.3354 - val_accuracy: 0.4821\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 1.2109 - accuracy: 0.5437 - val_loss: 1.0629 - val_accuracy: 0.6243\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.9678 - accuracy: 0.6528 - val_loss: 0.8487 - val_accuracy: 0.6984\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.7920 - accuracy: 0.7107 - val_loss: 0.7383 - val_accuracy: 0.7209\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.7037 - accuracy: 0.7435 - val_loss: 0.6984 - val_accuracy: 0.7295\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.6521 - accuracy: 0.7520 - val_loss: 0.6680 - val_accuracy: 0.7368\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.6243 - accuracy: 0.7554 - val_loss: 0.6573 - val_accuracy: 0.7427\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6171 - accuracy: 0.7530 - val_loss: 0.6436 - val_accuracy: 0.7507\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.7647 - val_loss: 0.6455 - val_accuracy: 0.7507\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5852 - accuracy: 0.7669 - val_loss: 0.6443 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.7653 - val_loss: 0.6435 - val_accuracy: 0.7447\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5745 - accuracy: 0.7655 - val_loss: 0.6391 - val_accuracy: 0.7507\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5638 - accuracy: 0.7633 - val_loss: 0.6336 - val_accuracy: 0.7540\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.5556 - accuracy: 0.7748 - val_loss: 0.6317 - val_accuracy: 0.7460\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.5586 - accuracy: 0.7671 - val_loss: 0.6312 - val_accuracy: 0.7540\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.5471 - accuracy: 0.7796 - val_loss: 0.6358 - val_accuracy: 0.7493\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.5498 - accuracy: 0.7726 - val_loss: 0.6342 - val_accuracy: 0.7520\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.5428 - accuracy: 0.7770 - val_loss: 0.6395 - val_accuracy: 0.7533\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.5416 - accuracy: 0.7718 - val_loss: 0.6369 - val_accuracy: 0.7560\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.5420 - accuracy: 0.7706 - val_loss: 0.6336 - val_accuracy: 0.7507\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.5400 - accuracy: 0.7756 - val_loss: 0.6335 - val_accuracy: 0.7493\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7782 - val_loss: 0.6275 - val_accuracy: 0.7606\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.7784 - val_loss: 0.6399 - val_accuracy: 0.7560\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5279 - accuracy: 0.7780 - val_loss: 0.6301 - val_accuracy: 0.7632\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5250 - accuracy: 0.7861 - val_loss: 0.6278 - val_accuracy: 0.7665\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7851 - val_loss: 0.6250 - val_accuracy: 0.7639\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.5193 - accuracy: 0.7760 - val_loss: 0.6281 - val_accuracy: 0.7599\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5182 - accuracy: 0.7871 - val_loss: 0.6229 - val_accuracy: 0.7612\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7786 - val_loss: 0.6299 - val_accuracy: 0.7619\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.5081 - accuracy: 0.7875 - val_loss: 0.6236 - val_accuracy: 0.7646\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.5056 - accuracy: 0.7871 - val_loss: 0.6161 - val_accuracy: 0.7725\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7883 - val_loss: 0.6249 - val_accuracy: 0.7725\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.7944 - val_loss: 0.6233 - val_accuracy: 0.7632\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.7891 - val_loss: 0.6117 - val_accuracy: 0.7738\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7938 - val_loss: 0.6206 - val_accuracy: 0.7652\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.4911 - accuracy: 0.7980 - val_loss: 0.6089 - val_accuracy: 0.7784\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7923 - val_loss: 0.6141 - val_accuracy: 0.7712\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4897 - accuracy: 0.7942 - val_loss: 0.6038 - val_accuracy: 0.7791\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7966 - val_loss: 0.6091 - val_accuracy: 0.7659\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.8036 - val_loss: 0.6047 - val_accuracy: 0.7791\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.4810 - accuracy: 0.7998 - val_loss: 0.6071 - val_accuracy: 0.7738\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.4829 - accuracy: 0.8004 - val_loss: 0.6012 - val_accuracy: 0.7817\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.4808 - accuracy: 0.8012 - val_loss: 0.6041 - val_accuracy: 0.7718\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 1s 10ms/step - loss: 0.4801 - accuracy: 0.8028 - val_loss: 0.6043 - val_accuracy: 0.7758\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.4791 - accuracy: 0.8006 - val_loss: 0.6039 - val_accuracy: 0.7738\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.8014 - val_loss: 0.6002 - val_accuracy: 0.7824\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.8018 - val_loss: 0.5936 - val_accuracy: 0.7824\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.8063 - val_loss: 0.5980 - val_accuracy: 0.7831\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.8063 - val_loss: 0.6025 - val_accuracy: 0.7844\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.4716 - accuracy: 0.8071 - val_loss: 0.5970 - val_accuracy: 0.7857\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.8073 - val_loss: 0.5888 - val_accuracy: 0.7910\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.8155 - val_loss: 0.5847 - val_accuracy: 0.7917\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.8123 - val_loss: 0.5917 - val_accuracy: 0.7903\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.4573 - accuracy: 0.8141 - val_loss: 0.5990 - val_accuracy: 0.7864\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.8103 - val_loss: 0.5883 - val_accuracy: 0.7903\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.4610 - accuracy: 0.8097 - val_loss: 0.5887 - val_accuracy: 0.7890\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.8141 - val_loss: 0.5849 - val_accuracy: 0.7950\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.8157 - val_loss: 0.5830 - val_accuracy: 0.7943\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.8194 - val_loss: 0.5879 - val_accuracy: 0.7956\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.8244 - val_loss: 0.5866 - val_accuracy: 0.7996\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.8224 - val_loss: 0.5777 - val_accuracy: 0.7976\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.8187 - val_loss: 0.5843 - val_accuracy: 0.8009\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.4444 - accuracy: 0.8149 - val_loss: 0.5749 - val_accuracy: 0.8016\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.8224 - val_loss: 0.5793 - val_accuracy: 0.8042\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.8214 - val_loss: 0.5771 - val_accuracy: 0.8056\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.8212 - val_loss: 0.5713 - val_accuracy: 0.8095\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.4362 - accuracy: 0.8246 - val_loss: 0.5776 - val_accuracy: 0.7996\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 1s 10ms/step - loss: 0.4278 - accuracy: 0.8272 - val_loss: 0.5721 - val_accuracy: 0.8049\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.4326 - accuracy: 0.8230 - val_loss: 0.5728 - val_accuracy: 0.8069\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.4299 - accuracy: 0.8250 - val_loss: 0.5747 - val_accuracy: 0.8036\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.4304 - accuracy: 0.8302 - val_loss: 0.5693 - val_accuracy: 0.8056\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.8276 - val_loss: 0.5659 - val_accuracy: 0.8036\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8260 - val_loss: 0.5664 - val_accuracy: 0.8049\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.8310 - val_loss: 0.5688 - val_accuracy: 0.8029\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.8278 - val_loss: 0.5640 - val_accuracy: 0.8042\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8282 - val_loss: 0.5638 - val_accuracy: 0.8056\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.4201 - accuracy: 0.8347 - val_loss: 0.5646 - val_accuracy: 0.8075\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.4279 - accuracy: 0.8282 - val_loss: 0.5611 - val_accuracy: 0.8095\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8397 - val_loss: 0.5662 - val_accuracy: 0.8009\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8337 - val_loss: 0.5617 - val_accuracy: 0.8089\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.4183 - accuracy: 0.8319 - val_loss: 0.5622 - val_accuracy: 0.8062\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.4076 - accuracy: 0.8440 - val_loss: 0.5664 - val_accuracy: 0.8042\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8371 - val_loss: 0.5644 - val_accuracy: 0.8049\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8377 - val_loss: 0.5702 - val_accuracy: 0.8062\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.4094 - accuracy: 0.8405 - val_loss: 0.5600 - val_accuracy: 0.8069\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8435 - val_loss: 0.5572 - val_accuracy: 0.8069\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8379 - val_loss: 0.5589 - val_accuracy: 0.8069\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8421 - val_loss: 0.5603 - val_accuracy: 0.8022\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8369 - val_loss: 0.5617 - val_accuracy: 0.8016\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8383 - val_loss: 0.5573 - val_accuracy: 0.8082\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8379 - val_loss: 0.5529 - val_accuracy: 0.8095\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.3910 - accuracy: 0.8492 - val_loss: 0.5551 - val_accuracy: 0.8062\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.3943 - accuracy: 0.8452 - val_loss: 0.5564 - val_accuracy: 0.8049\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.3953 - accuracy: 0.8472 - val_loss: 0.5564 - val_accuracy: 0.8082\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.3960 - accuracy: 0.8397 - val_loss: 0.5538 - val_accuracy: 0.8075\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.3958 - accuracy: 0.8393 - val_loss: 0.5545 - val_accuracy: 0.8075\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.3992 - accuracy: 0.8438 - val_loss: 0.5588 - val_accuracy: 0.8016\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.3912 - accuracy: 0.8437 - val_loss: 0.5560 - val_accuracy: 0.8075\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8429 - val_loss: 0.5493 - val_accuracy: 0.8122\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8395 - val_loss: 0.5527 - val_accuracy: 0.8095\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.8009\n",
            "Loss: 0.56069016456604, Accuracy: 0.8009259104728699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el modelo con hiperparámetros ajustables\n",
        "def create_simple_model(learning_rate=0.001, dropout_rate=0.3):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear el modelo con hiperparámetros ajustados\n",
        "model = create_simple_model(learning_rate=0.001, dropout_rate=0.3)\n",
        "\n",
        "# Añadir EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WltsCZRMq1OI",
        "outputId": "3c82ead5-50c6-4531-836f-8340ad297deb"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "158/158 [==============================] - 2s 5ms/step - loss: 1.5501 - accuracy: 0.3018 - val_loss: 1.3675 - val_accuracy: 0.4630\n",
            "Epoch 2/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 1.2482 - accuracy: 0.4877 - val_loss: 1.0258 - val_accuracy: 0.6085\n",
            "Epoch 3/50\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.9827 - accuracy: 0.6276 - val_loss: 0.7957 - val_accuracy: 0.7235\n",
            "Epoch 4/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.8101 - accuracy: 0.7141 - val_loss: 0.6723 - val_accuracy: 0.7705\n",
            "Epoch 5/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.6938 - accuracy: 0.7486 - val_loss: 0.6155 - val_accuracy: 0.7784\n",
            "Epoch 6/50\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 0.6266 - accuracy: 0.7752 - val_loss: 0.5665 - val_accuracy: 0.7956\n",
            "Epoch 7/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.5858 - accuracy: 0.7893 - val_loss: 0.5564 - val_accuracy: 0.7989\n",
            "Epoch 8/50\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.5544 - accuracy: 0.7970 - val_loss: 0.5246 - val_accuracy: 0.8042\n",
            "Epoch 9/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.5108 - accuracy: 0.8125 - val_loss: 0.5314 - val_accuracy: 0.8075\n",
            "Epoch 10/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.4852 - accuracy: 0.8171 - val_loss: 0.5168 - val_accuracy: 0.8128\n",
            "Epoch 11/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.4774 - accuracy: 0.8306 - val_loss: 0.5148 - val_accuracy: 0.8102\n",
            "Epoch 12/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.4607 - accuracy: 0.8300 - val_loss: 0.5064 - val_accuracy: 0.8108\n",
            "Epoch 13/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.4497 - accuracy: 0.8228 - val_loss: 0.5139 - val_accuracy: 0.8135\n",
            "Epoch 14/50\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.4497 - accuracy: 0.8317 - val_loss: 0.5011 - val_accuracy: 0.8122\n",
            "Epoch 15/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.4329 - accuracy: 0.8361 - val_loss: 0.5018 - val_accuracy: 0.8122\n",
            "Epoch 16/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.4227 - accuracy: 0.8403 - val_loss: 0.4910 - val_accuracy: 0.8161\n",
            "Epoch 17/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.4105 - accuracy: 0.8415 - val_loss: 0.5031 - val_accuracy: 0.8161\n",
            "Epoch 18/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.4110 - accuracy: 0.8466 - val_loss: 0.4975 - val_accuracy: 0.8168\n",
            "Epoch 19/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.4015 - accuracy: 0.8464 - val_loss: 0.5037 - val_accuracy: 0.8168\n",
            "Epoch 20/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.3958 - accuracy: 0.8442 - val_loss: 0.5093 - val_accuracy: 0.8168\n",
            "Epoch 21/50\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.3946 - accuracy: 0.8468 - val_loss: 0.4950 - val_accuracy: 0.8287\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8117\n",
            "Loss: 0.5132601261138916, Accuracy: 0.8117284178733826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo de prueba para ver qué tan bien predice."
      ],
      "metadata": {
        "id": "nqBOdYGgtMVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ejemplo de un registro individual (preprocesado)\n",
        "# Asegúrate de que el registro individual tenga las mismas características que los datos de entrenamiento y prueba\n",
        "new_record = X_test.iloc[3]\n",
        "\n",
        "# Obtener el servicio objetivo original\n",
        "original_service = y_test.iloc[3].idxmax()\n",
        "\n",
        " # Convertir el nuevo registro a un DataFrame\n",
        "new_record_df = pd.DataFrame([new_record])\n",
        "\n",
        "# Asegurarse de que tenga las mismas columnas que el DataFrame de entrenamiento\n",
        "missing_cols = set(X.columns) - set(new_record_df.columns)\n",
        "for col in missing_cols:\n",
        "    new_record_df[col] = 0\n",
        "new_record_df = new_record_df[X.columns]\n",
        "\n",
        "# Convertir a numpy array\n",
        "new_record_array = new_record_df.values\n",
        "\n",
        "# Predecir usando el modelo entrenado\n",
        "predictions = model.predict(new_record_array)\n",
        "\n",
        "# Obtener las probabilidades para cada tipo de servicio\n",
        "service_probabilities = predictions[0]\n",
        "\n",
        "# Imprimir el servicio objetivo original y las probabilidades\n",
        "print(f\"Original Servicio: {original_service}\")\n",
        "# Imprimir las probabilidades\n",
        "service_labels = y.columns  # Asegúrate de que 'y' tiene las columnas de las categorías de servicio\n",
        "for label, prob in zip(service_labels, service_probabilities):\n",
        "    print(f\"Servicio: {label}, Probabilidad: {prob:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2IGBwvEtME1",
        "outputId": "002f3d45-0074-4afb-e23b-ed4b6cfd838a"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ce29cb3b0a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n",
            "Original Servicio: LOG\n",
            "Servicio: AT, Probabilidad: 0.3234\n",
            "Servicio: EM, Probabilidad: 0.0106\n",
            "Servicio: LOG, Probabilidad: 0.6517\n",
            "Servicio: SAAF, Probabilidad: 0.0122\n",
            "Servicio: SO, Probabilidad: 0.0021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ejemplo de un registro individual (preprocesado)\n",
        "# Asegúrate de que el registro individual tenga las mismas características que los datos de entrenamiento y prueba\n",
        "new_record = X_test.iloc[22]\n",
        "\n",
        "# Obtener el servicio objetivo original\n",
        "original_service = y_test.iloc[22].idxmax()\n",
        "\n",
        " # Convertir el nuevo registro a un DataFrame\n",
        "new_record_df = pd.DataFrame([new_record])\n",
        "\n",
        "# Asegurarse de que tenga las mismas columnas que el DataFrame de entrenamiento\n",
        "missing_cols = set(X.columns) - set(new_record_df.columns)\n",
        "for col in missing_cols:\n",
        "    new_record_df[col] = 0\n",
        "new_record_df = new_record_df[X.columns]\n",
        "\n",
        "# Convertir a numpy array\n",
        "new_record_array = new_record_df.values\n",
        "\n",
        "# Predecir usando el modelo entrenado\n",
        "predictions = model.predict(new_record_array)\n",
        "\n",
        "# Obtener las probabilidades para cada tipo de servicio\n",
        "service_probabilities = predictions[0]\n",
        "\n",
        "# Imprimir el servicio objetivo original y las probabilidades\n",
        "print(f\"Original Servicio: {original_service}\")\n",
        "# Imprimir las probabilidades\n",
        "service_labels = y.columns  # Asegúrate de que 'y' tiene las columnas de las categorías de servicio\n",
        "for label, prob in zip(service_labels, service_probabilities):\n",
        "    print(f\"Servicio: {label}, Probabilidad: {prob:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hV24oFNuwiy",
        "outputId": "84b395fc-660c-4b4e-a3a6-1161e8b5e9eb"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "Original Servicio: LOG\n",
            "Servicio: AT, Probabilidad: 0.0235\n",
            "Servicio: EM, Probabilidad: 0.0163\n",
            "Servicio: LOG, Probabilidad: 0.9197\n",
            "Servicio: SAAF, Probabilidad: 0.0141\n",
            "Servicio: SO, Probabilidad: 0.0263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ejemplo de un registro individual (preprocesado)\n",
        "# Asegúrate de que el registro individual tenga las mismas características que los datos de entrenamiento y prueba\n",
        "new_record = X_test.iloc[70]\n",
        "\n",
        "# Obtener el servicio objetivo original\n",
        "original_service = y_test.iloc[70].idxmax()\n",
        "\n",
        " # Convertir el nuevo registro a un DataFrame\n",
        "new_record_df = pd.DataFrame([new_record])\n",
        "\n",
        "# Asegurarse de que tenga las mismas columnas que el DataFrame de entrenamiento\n",
        "missing_cols = set(X.columns) - set(new_record_df.columns)\n",
        "for col in missing_cols:\n",
        "    new_record_df[col] = 0\n",
        "new_record_df = new_record_df[X.columns]\n",
        "\n",
        "# Convertir a numpy array\n",
        "new_record_array = new_record_df.values\n",
        "\n",
        "# Predecir usando el modelo entrenado\n",
        "predictions = model.predict(new_record_array)\n",
        "\n",
        "# Obtener las probabilidades para cada tipo de servicio\n",
        "service_probabilities = predictions[0]\n",
        "\n",
        "# Imprimir el servicio objetivo original y las probabilidades\n",
        "print(f\"Original Servicio: {original_service}\")\n",
        "# Imprimir las probabilidades\n",
        "service_labels = y.columns  # Asegúrate de que 'y' tiene las columnas de las categorías de servicio\n",
        "for label, prob in zip(service_labels, service_probabilities):\n",
        "    print(f\"Servicio: {label}, Probabilidad: {prob:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuV-HDlsuySK",
        "outputId": "6a64f581-ad66-4cec-e551-fb716e6b7fa8"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "Original Servicio: LOG\n",
            "Servicio: AT, Probabilidad: 0.0000\n",
            "Servicio: EM, Probabilidad: 0.0000\n",
            "Servicio: LOG, Probabilidad: 0.9999\n",
            "Servicio: SAAF, Probabilidad: 0.0001\n",
            "Servicio: SO, Probabilidad: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "id": "etse9KBVCF5d",
        "outputId": "3bdadb2f-3dae-4fc3-f517-3e124ecac4b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting keras>=3.2.0 (from scikeras)\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.4.2 (from scikeras)\n",
            "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
            "Collecting namex (from keras>=3.2.0->scikeras)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.9.0)\n",
            "Collecting optree (from keras>=3.2.0->scikeras)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Installing collected packages: namex, optree, scikit-learn, keras, scikeras\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.3.3 namex-0.0.8 optree-0.11.0 scikeras-0.13.0 scikit-learn-1.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              },
              "id": "2ee2685661fa4e0c932cc9fda08321ef"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Definir el modelo con hiperparámetros ajustables\n",
        "def create_nn_model(learning_rate=0.001, dropout_rate=0.3):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear el KerasClassifier con SciKeras\n",
        "nn_model = KerasClassifier(model=create_nn_model, verbose=0)\n",
        "\n",
        "# Definir los hiperparámetros para la búsqueda aleatoria\n",
        "param_dist_nn = {\n",
        "    'model__learning_rate': uniform(0.0001, 0.001),\n",
        "    'model__dropout_rate': uniform(0.1, 0.5),\n",
        "    'epochs': [50, 100, 200],\n",
        "    'batch_size': [16, 32, 64]\n",
        "}\n",
        "\n",
        "# Realizar la búsqueda aleatoria\n",
        "random_search_nn = RandomizedSearchCV(estimator=nn_model, param_distributions=param_dist_nn, scoring='accuracy', cv=3, n_iter=20, verbose=1, random_state=42)\n",
        "random_search_nn.fit(X_train, y_train)\n",
        "\n",
        "# Obtener el mejor modelo\n",
        "best_nn_model = random_search_nn.best_estimator_\n",
        "\n",
        "# Evaluar el mejor modelo de red neuronal\n",
        "loss, accuracy = best_nn_model.score(X_test, y_test)\n",
        "print(f'Best Neural Network Model Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "gZnNu4i6BkXu",
        "outputId": "ead7f96f-b1a0-49ea-b2cd-53221bebc7d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow.keras.wrappers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-1c710bcdf77f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Definir el modelo con hiperparámetros ajustables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_nn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo XGBoost con datos generados"
      ],
      "metadata": {
        "id": "B4ZOQ2aZxfwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificar las etiquetas usando LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y.idxmax(axis=1))  # Convertir de one-hot encoding a etiquetas enteras\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo XGBoost\n",
        "xgb_model = xgb.XGBClassifier(objective='multi:softprob', num_class=len(label_encoder.classes_))\n",
        "xgb_model.fit(X_train_xgb, y_train_xgb)\n",
        "\n",
        "# Obtener las predicciones de probabilidad del conjunto de prueba\n",
        "X_train_nn = xgb_model.predict_proba(X_train_xgb)\n",
        "X_test_nn = xgb_model.predict_proba(X_test_xgb)\n",
        "\n",
        "# Convertir las etiquetas del conjunto de prueba a one-hot encoding\n",
        "y_train_nn = to_categorical(y_train_xgb, num_classes=len(label_encoder.classes_))\n",
        "y_test_nn = to_categorical(y_test_xgb, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "# Definir el modelo de red neuronal\n",
        "def create_nn_model(input_dim, learning_rate=0.001, dropout_rate=0.3):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(y_train_nn.shape[1], activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear el modelo de red neuronal\n",
        "nn_model = create_nn_model(input_dim=X_train_nn.shape[1])\n",
        "\n",
        "# Añadir EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Entrenar el modelo de red neuronal\n",
        "history = nn_model.fit(X_train_nn, y_train_nn, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = nn_model.evaluate(X_test_nn, y_test_nn)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "HtwD6fucxfhR",
        "outputId": "391169bd-b0f0-47ab-bb80-bafb24d7b1fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 1.2614 - accuracy: 0.5637 - val_loss: 0.7179 - val_accuracy: 0.8065\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.8043 - val_loss: 0.5719 - val_accuracy: 0.8016\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.8038 - val_loss: 0.5516 - val_accuracy: 0.8075\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.8051 - val_loss: 0.5444 - val_accuracy: 0.8095\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.8033 - val_loss: 0.5357 - val_accuracy: 0.8075\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.8098 - val_loss: 0.5356 - val_accuracy: 0.8125\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.8083 - val_loss: 0.5324 - val_accuracy: 0.8135\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5609 - accuracy: 0.8100 - val_loss: 0.5268 - val_accuracy: 0.8135\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5535 - accuracy: 0.8051 - val_loss: 0.5384 - val_accuracy: 0.8155\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.8078 - val_loss: 0.5292 - val_accuracy: 0.8085\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.8065 - val_loss: 0.5259 - val_accuracy: 0.8145\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.8083 - val_loss: 0.5368 - val_accuracy: 0.8095\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.8105 - val_loss: 0.5268 - val_accuracy: 0.8155\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.8065 - val_loss: 0.5228 - val_accuracy: 0.8115\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.5462 - accuracy: 0.8113 - val_loss: 0.5195 - val_accuracy: 0.8135\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.5395 - accuracy: 0.8095 - val_loss: 0.5196 - val_accuracy: 0.8115\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.5331 - accuracy: 0.8120 - val_loss: 0.5123 - val_accuracy: 0.8115\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.5347 - accuracy: 0.8100 - val_loss: 0.5255 - val_accuracy: 0.8135\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5390 - accuracy: 0.8095 - val_loss: 0.5205 - val_accuracy: 0.8115\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.5324 - accuracy: 0.8105 - val_loss: 0.5169 - val_accuracy: 0.8115\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.8103 - val_loss: 0.5144 - val_accuracy: 0.8135\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.8085 - val_loss: 0.5142 - val_accuracy: 0.8135\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.8127 - val_loss: 0.5060 - val_accuracy: 0.8145\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5200 - accuracy: 0.8135 - val_loss: 0.5108 - val_accuracy: 0.8155\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.8100 - val_loss: 0.5161 - val_accuracy: 0.8135\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.8093 - val_loss: 0.5110 - val_accuracy: 0.8135\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.8080 - val_loss: 0.5080 - val_accuracy: 0.8115\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.8118 - val_loss: 0.5086 - val_accuracy: 0.8105\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.8108 - val_loss: 0.5059 - val_accuracy: 0.8194\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.8177 - val_loss: 0.5044 - val_accuracy: 0.8135\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.8108 - val_loss: 0.5041 - val_accuracy: 0.8125\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.8108 - val_loss: 0.4989 - val_accuracy: 0.8165\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.8108 - val_loss: 0.5042 - val_accuracy: 0.8115\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.8180 - val_loss: 0.5003 - val_accuracy: 0.8095\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.8152 - val_loss: 0.5077 - val_accuracy: 0.8095\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.8132 - val_loss: 0.5051 - val_accuracy: 0.8125\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.8070 - val_loss: 0.5070 - val_accuracy: 0.8125\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.8130 - val_loss: 0.4978 - val_accuracy: 0.8115\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8135 - val_loss: 0.5034 - val_accuracy: 0.8155\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5060 - accuracy: 0.8147 - val_loss: 0.4995 - val_accuracy: 0.8145\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.8180 - val_loss: 0.5000 - val_accuracy: 0.8135\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.8103 - val_loss: 0.4949 - val_accuracy: 0.8165\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.8145 - val_loss: 0.4987 - val_accuracy: 0.8115\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.8095 - val_loss: 0.4974 - val_accuracy: 0.8204\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.8127 - val_loss: 0.4967 - val_accuracy: 0.8194\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.8123 - val_loss: 0.5038 - val_accuracy: 0.8135\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.8152 - val_loss: 0.4919 - val_accuracy: 0.8175\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.8118 - val_loss: 0.4964 - val_accuracy: 0.8244\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.8095 - val_loss: 0.5008 - val_accuracy: 0.8155\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.8115 - val_loss: 0.4988 - val_accuracy: 0.8095\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.8083 - val_loss: 0.4971 - val_accuracy: 0.8125\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.8147 - val_loss: 0.4922 - val_accuracy: 0.8234\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.8090 - val_loss: 0.4950 - val_accuracy: 0.8175\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.8125 - val_loss: 0.4930 - val_accuracy: 0.8165\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.8135 - val_loss: 0.4926 - val_accuracy: 0.8175\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.8098 - val_loss: 0.4952 - val_accuracy: 0.8234\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.8137 - val_loss: 0.4980 - val_accuracy: 0.8165\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.7597\n",
            "Loss: 0.6326981782913208, Accuracy: 0.7597222328186035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de un registro individual (preprocesado) con el conjunto de prueba de XGBoost\n",
        "new_record_xgb = X_test_xgb.iloc[3]\n",
        "\n",
        "# Convertir el nuevo registro a un DataFrame\n",
        "new_record_xgb_df = pd.DataFrame([new_record_xgb])\n",
        "\n",
        "# Obtener las predicciones de probabilidad del modelo XGBoost\n",
        "new_record_nn_input = xgb_model.predict_proba(new_record_xgb_df)\n",
        "\n",
        "# Predecir usando el modelo de red neuronal entrenado\n",
        "predictions = nn_model.predict(new_record_nn_input)\n",
        "\n",
        "# Obtener las probabilidades para cada tipo de servicio\n",
        "service_probabilities = predictions[0]\n",
        "\n",
        "# Obtener el servicio objetivo original\n",
        "original_service = y_test_xgb[3]  # Indexar directamente el array de NumPy\n",
        "\n",
        "# Convertir el servicio objetivo original a etiqueta de texto\n",
        "original_service_label = label_encoder.inverse_transform([original_service])[0]\n",
        "\n",
        "# Imprimir el servicio objetivo original y las probabilidades\n",
        "service_labels = label_encoder.classes_  # Obtener las etiquetas originales\n",
        "print(f\"Original Servicio: {original_service_label}\")\n",
        "for label, prob in zip(service_labels, service_probabilities):\n",
        "    print(f\"Servicio: {label}, Probabilidad: {prob:.4f}\")\n"
      ],
      "metadata": {
        "id": "BrlPk7IhxbX0",
        "outputId": "fbdafe70-0c95-485c-a95f-489ff9a7ee49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ce29c9177f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n",
            "Original Servicio: EM\n",
            "Servicio: AT, Probabilidad: 0.8002\n",
            "Servicio: EM, Probabilidad: 0.0716\n",
            "Servicio: LOG, Probabilidad: 0.0007\n",
            "Servicio: SAAF, Probabilidad: 0.0745\n",
            "Servicio: SO, Probabilidad: 0.0530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de un registro individual (preprocesado) con el conjunto de prueba de XGBoost\n",
        "new_record_xgb = X_test_xgb.iloc[3]\n",
        "\n",
        "# Convertir el nuevo registro a un DataFrame\n",
        "new_record_xgb_df = pd.DataFrame([new_record_xgb])\n",
        "\n",
        "# Obtener las predicciones de probabilidad del modelo XGBoost\n",
        "new_record_nn_input = xgb_model.predict_proba(new_record_xgb_df)\n",
        "\n",
        "# Predecir usando el modelo de red neuronal entrenado\n",
        "predictions = nn_model.predict(new_record_nn_input)\n",
        "\n",
        "# Obtener las probabilidades para cada tipo de servicio\n",
        "service_probabilities = predictions[0]\n",
        "\n",
        "# Obtener el servicio objetivo original\n",
        "original_service = y_test_xgb[3]  # Indexar directamente el array de NumPy\n",
        "\n",
        "# Convertir el servicio objetivo original a etiqueta de texto\n",
        "original_service_label = label_encoder.inverse_transform([original_service])[0]\n",
        "\n",
        "# Imprimir el servicio objetivo original y las probabilidades\n",
        "service_labels = label_encoder.classes_  # Obtener las etiquetas originales\n",
        "print(f\"Original Servicio: {original_service_label}\")\n",
        "for label, prob in zip(service_labels, service_probabilities):\n",
        "    print(f\"Servicio: {label}, Probabilidad: {prob:.4f}\")\n"
      ],
      "metadata": {
        "id": "hhW2b0J1xa1b",
        "outputId": "ca027eda-414f-4370-9332-7ec226929560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "Original Servicio: EM\n",
            "Servicio: AT, Probabilidad: 0.8002\n",
            "Servicio: EM, Probabilidad: 0.0716\n",
            "Servicio: LOG, Probabilidad: 0.0007\n",
            "Servicio: SAAF, Probabilidad: 0.0745\n",
            "Servicio: SO, Probabilidad: 0.0530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de un registro individual (preprocesado) con el conjunto de prueba de XGBoost\n",
        "new_record_xgb = X_test_xgb.iloc[3]\n",
        "\n",
        "# Convertir el nuevo registro a un DataFrame\n",
        "new_record_xgb_df = pd.DataFrame([new_record_xgb])\n",
        "\n",
        "# Obtener las predicciones de probabilidad del modelo XGBoost\n",
        "new_record_nn_input = xgb_model.predict_proba(new_record_xgb_df)\n",
        "\n",
        "# Predecir usando el modelo de red neuronal entrenado\n",
        "predictions = nn_model.predict(new_record_nn_input)\n",
        "\n",
        "# Obtener las probabilidades para cada tipo de servicio\n",
        "service_probabilities = predictions[0]\n",
        "\n",
        "# Obtener el servicio objetivo original\n",
        "original_service = y_test_xgb[3]  # Indexar directamente el array de NumPy\n",
        "\n",
        "# Convertir el servicio objetivo original a etiqueta de texto\n",
        "original_service_label = label_encoder.inverse_transform([original_service])[0]\n",
        "\n",
        "# Imprimir el servicio objetivo original y las probabilidades\n",
        "service_labels = label_encoder.classes_  # Obtener las etiquetas originales\n",
        "print(f\"Original Servicio: {original_service_label}\")\n",
        "for label, prob in zip(service_labels, service_probabilities):\n",
        "    print(f\"Servicio: {label}, Probabilidad: {prob:.4f}\")\n"
      ],
      "metadata": {
        "id": "ZkNNAJsZxZ7M",
        "outputId": "2a930f91-ec2c-4c75-a87a-a9104281c052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "Original Servicio: EM\n",
            "Servicio: AT, Probabilidad: 0.8002\n",
            "Servicio: EM, Probabilidad: 0.0716\n",
            "Servicio: LOG, Probabilidad: 0.0007\n",
            "Servicio: SAAF, Probabilidad: 0.0745\n",
            "Servicio: SO, Probabilidad: 0.0530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definir el modelo XGBoost\n",
        "xgb_model = xgb.XGBClassifier(objective='multi:softprob', num_class=len(label_encoder.classes_))\n",
        "\n",
        "# Definir los hiperparámetros para la búsqueda en cuadrícula\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Realizar la búsqueda en cuadrícula\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1)\n",
        "grid_search.fit(X_train_xgb, y_train_xgb)\n",
        "\n",
        "# Obtener el mejor modelo\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Obtener las predicciones de probabilidad del conjunto de prueba\n",
        "X_train_nn = best_xgb_model.predict_proba(X_train_xgb)\n",
        "X_test_nn = best_xgb_model.predict_proba(X_test_xgb)\n",
        "\n",
        "# Convertir las etiquetas del conjunto de prueba a one-hot encoding\n",
        "y_train_nn = to_categorical(y_train_xgb, num_classes=len(label_encoder.classes_))\n",
        "y_test_nn = to_categorical(y_test_xgb, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "# Evaluar el mejor modelo XGBoost\n",
        "best_xgb_accuracy = grid_search.best_score_\n",
        "print(f'Best XGBoost Model Accuracy: {best_xgb_accuracy}')"
      ],
      "metadata": {
        "id": "YCRbag6v7emX",
        "outputId": "8dfc9304-d1f6-4df8-d138-f82680bbcbc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
            "Best XGBoost Model Accuracy: 0.7236111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Definir el modelo XGBoost\n",
        "xgb_model = xgb.XGBClassifier(objective='multi:softprob', num_class=len(label_encoder.classes_))\n",
        "\n",
        "# Definir los hiperparámetros para la búsqueda aleatoria\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 300),\n",
        "    'max_depth': randint(3, 10),\n",
        "    'learning_rate': uniform(0.01, 0.3),\n",
        "    'subsample': uniform(0.7, 0.3),\n",
        "    'colsample_bytree': uniform(0.7, 0.3)\n",
        "}\n",
        "\n",
        "# Realizar la búsqueda aleatoria\n",
        "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, scoring='accuracy', cv=3, n_iter=50, verbose=1, random_state=42)\n",
        "random_search.fit(X_train_xgb, y_train_xgb)\n",
        "\n",
        "# Obtener el mejor modelo\n",
        "best_xgb_model = random_search.best_estimator_\n",
        "\n",
        "# Obtener las predicciones de probabilidad del conjunto de prueba\n",
        "X_train_nn = best_xgb_model.predict_proba(X_train_xgb)\n",
        "X_test_nn = best_xgb_model.predict_proba(X_test_xgb)\n",
        "\n",
        "# Convertir las etiquetas del conjunto de prueba a one-hot encoding\n",
        "y_train_nn = to_categorical(y_train_xgb, num_classes=len(label_encoder.classes_))\n",
        "y_test_nn = to_categorical(y_test_xgb, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "# Evaluar el mejor modelo XGBoost\n",
        "best_xgb_accuracy = random_search.best_score_\n",
        "print(f'Best XGBoost Model Accuracy: {best_xgb_accuracy}')"
      ],
      "metadata": {
        "id": "9P2KL2RzCVKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2i\n",
        "\n",
        "# Definir el modelo de red neuronal con regularización y Dropout\n",
        "def create_nn_model(input_dim, learning_rate=0.001, dropout_rate=0.3, regularization=0.01):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=input_dim, activation='relu', kernel_regularizer=l2(regularization)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(regularization)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(regularization)))\n",
        "    model.add(Dense(y_train_nn.shape[1], activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear el modelo de red neuronal\n",
        "nn_model = create_nn_model(input_dim=X_train_nn.shape[1], learning_rate=0.001, dropout_rate=0.4, regularization=0.01)\n",
        "\n",
        "# Añadir EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Entrenar el modelo de red neuronal\n",
        "history = nn_model.fit(X_train_nn, y_train_nn, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = nn_model.evaluate(X_test_nn, y_test_nn)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "faSiGPIV7loL",
        "outputId": "215cc2bc-6bf0-4e64-cd19-768a79a24ec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 1s 6ms/step - loss: 2.3895 - accuracy: 0.5166 - val_loss: 1.7545 - val_accuracy: 0.8125\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.4217 - accuracy: 0.7946 - val_loss: 1.0949 - val_accuracy: 0.8274\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 1.0868 - accuracy: 0.8108 - val_loss: 0.9436 - val_accuracy: 0.8284\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.9774 - accuracy: 0.8123 - val_loss: 0.8735 - val_accuracy: 0.8214\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9170 - accuracy: 0.8115 - val_loss: 0.8390 - val_accuracy: 0.8185\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.8740 - accuracy: 0.8224 - val_loss: 0.8020 - val_accuracy: 0.8264\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8652 - accuracy: 0.8140 - val_loss: 0.7863 - val_accuracy: 0.8254\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.8347 - accuracy: 0.8194 - val_loss: 0.7785 - val_accuracy: 0.8274\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8272 - accuracy: 0.8162 - val_loss: 0.7691 - val_accuracy: 0.8224\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.8169 - accuracy: 0.8207 - val_loss: 0.7514 - val_accuracy: 0.8244\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8060 - accuracy: 0.8207 - val_loss: 0.7497 - val_accuracy: 0.8274\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7915 - accuracy: 0.8177 - val_loss: 0.7396 - val_accuracy: 0.8214\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7841 - accuracy: 0.8162 - val_loss: 0.7389 - val_accuracy: 0.8284\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.7880 - accuracy: 0.8199 - val_loss: 0.7320 - val_accuracy: 0.8204\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7861 - accuracy: 0.8147 - val_loss: 0.7247 - val_accuracy: 0.8264\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7771 - accuracy: 0.8192 - val_loss: 0.7211 - val_accuracy: 0.8254\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7680 - accuracy: 0.8202 - val_loss: 0.7138 - val_accuracy: 0.8234\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7724 - accuracy: 0.8204 - val_loss: 0.7113 - val_accuracy: 0.8244\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.7645 - accuracy: 0.8209 - val_loss: 0.7144 - val_accuracy: 0.8204\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7594 - accuracy: 0.8172 - val_loss: 0.7088 - val_accuracy: 0.8254\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7590 - accuracy: 0.8170 - val_loss: 0.7056 - val_accuracy: 0.8274\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.7532 - accuracy: 0.8170 - val_loss: 0.6977 - val_accuracy: 0.8264\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.7497 - accuracy: 0.8167 - val_loss: 0.6949 - val_accuracy: 0.8254\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.7614 - accuracy: 0.8120 - val_loss: 0.7026 - val_accuracy: 0.8274\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.7452 - accuracy: 0.8127 - val_loss: 0.6950 - val_accuracy: 0.8244\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.7444 - accuracy: 0.8224 - val_loss: 0.6929 - val_accuracy: 0.8234\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.7485 - accuracy: 0.8172 - val_loss: 0.6852 - val_accuracy: 0.8254\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.7476 - accuracy: 0.8170 - val_loss: 0.6844 - val_accuracy: 0.8254\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.7416 - accuracy: 0.8170 - val_loss: 0.6822 - val_accuracy: 0.8244\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.7313 - accuracy: 0.8187 - val_loss: 0.6871 - val_accuracy: 0.8214\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.7333 - accuracy: 0.8212 - val_loss: 0.6881 - val_accuracy: 0.8264\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.7327 - accuracy: 0.8165 - val_loss: 0.6790 - val_accuracy: 0.8254\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.8197 - val_loss: 0.6808 - val_accuracy: 0.8254\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.7288 - accuracy: 0.8197 - val_loss: 0.6755 - val_accuracy: 0.8214\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.7210 - accuracy: 0.8189 - val_loss: 0.6784 - val_accuracy: 0.8224\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.7211 - accuracy: 0.8160 - val_loss: 0.6827 - val_accuracy: 0.8244\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.7304 - accuracy: 0.8167 - val_loss: 0.6753 - val_accuracy: 0.8264\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.7217 - accuracy: 0.8175 - val_loss: 0.6777 - val_accuracy: 0.8294\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.7222 - accuracy: 0.8189 - val_loss: 0.6782 - val_accuracy: 0.8214\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.7157 - accuracy: 0.8212 - val_loss: 0.6663 - val_accuracy: 0.8284\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.7213 - accuracy: 0.8185 - val_loss: 0.6738 - val_accuracy: 0.8194\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.7138 - accuracy: 0.8224 - val_loss: 0.6923 - val_accuracy: 0.8274\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.7178 - accuracy: 0.8189 - val_loss: 0.6647 - val_accuracy: 0.8294\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.7159 - accuracy: 0.8185 - val_loss: 0.6676 - val_accuracy: 0.8244\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.7164 - accuracy: 0.8192 - val_loss: 0.6718 - val_accuracy: 0.8214\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7162 - accuracy: 0.8177 - val_loss: 0.6606 - val_accuracy: 0.8254\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.7097 - accuracy: 0.8194 - val_loss: 0.6601 - val_accuracy: 0.8254\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.8227 - val_loss: 0.6595 - val_accuracy: 0.8185\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.7039 - accuracy: 0.8202 - val_loss: 0.6640 - val_accuracy: 0.8234\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.7029 - accuracy: 0.8217 - val_loss: 0.6661 - val_accuracy: 0.8254\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7092 - accuracy: 0.8192 - val_loss: 0.6666 - val_accuracy: 0.8214\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7054 - accuracy: 0.8180 - val_loss: 0.6618 - val_accuracy: 0.8234\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.7053 - accuracy: 0.8199 - val_loss: 0.6609 - val_accuracy: 0.8254\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7085 - accuracy: 0.8189 - val_loss: 0.6598 - val_accuracy: 0.8234\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6987 - accuracy: 0.8167 - val_loss: 0.6560 - val_accuracy: 0.8214\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7017 - accuracy: 0.8172 - val_loss: 0.6498 - val_accuracy: 0.8313\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.8212 - val_loss: 0.6716 - val_accuracy: 0.8185\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6996 - accuracy: 0.8177 - val_loss: 0.6550 - val_accuracy: 0.8185\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.8180 - val_loss: 0.6510 - val_accuracy: 0.8234\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.7024 - accuracy: 0.8239 - val_loss: 0.6506 - val_accuracy: 0.8244\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.6867 - accuracy: 0.8202 - val_loss: 0.6473 - val_accuracy: 0.8254\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6952 - accuracy: 0.8212 - val_loss: 0.6492 - val_accuracy: 0.8274\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.8165 - val_loss: 0.6473 - val_accuracy: 0.8254\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.7026 - accuracy: 0.8204 - val_loss: 0.6595 - val_accuracy: 0.8234\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.8222 - val_loss: 0.6532 - val_accuracy: 0.8194\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6952 - accuracy: 0.8204 - val_loss: 0.6542 - val_accuracy: 0.8234\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6915 - accuracy: 0.8202 - val_loss: 0.6527 - val_accuracy: 0.8234\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6921 - accuracy: 0.8264 - val_loss: 0.6453 - val_accuracy: 0.8224\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6999 - accuracy: 0.8162 - val_loss: 0.6402 - val_accuracy: 0.8264\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6872 - accuracy: 0.8185 - val_loss: 0.6452 - val_accuracy: 0.8254\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6958 - accuracy: 0.8217 - val_loss: 0.6499 - val_accuracy: 0.8214\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6962 - accuracy: 0.8192 - val_loss: 0.6469 - val_accuracy: 0.8204\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.8222 - val_loss: 0.6499 - val_accuracy: 0.8254\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.8204 - val_loss: 0.6374 - val_accuracy: 0.8323\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.8237 - val_loss: 0.6576 - val_accuracy: 0.8214\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.8214 - val_loss: 0.6462 - val_accuracy: 0.8254\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6980 - accuracy: 0.8167 - val_loss: 0.6569 - val_accuracy: 0.8165\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.8229 - val_loss: 0.6426 - val_accuracy: 0.8224\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.8222 - val_loss: 0.6539 - val_accuracy: 0.8214\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.8199 - val_loss: 0.6380 - val_accuracy: 0.8244\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.8212 - val_loss: 0.6382 - val_accuracy: 0.8284\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.8192 - val_loss: 0.6439 - val_accuracy: 0.8274\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.8182 - val_loss: 0.6357 - val_accuracy: 0.8204\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.8207 - val_loss: 0.6384 - val_accuracy: 0.8254\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.8219 - val_loss: 0.6391 - val_accuracy: 0.8284\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.8217 - val_loss: 0.6404 - val_accuracy: 0.8284\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.8212 - val_loss: 0.6348 - val_accuracy: 0.8274\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.8187 - val_loss: 0.6417 - val_accuracy: 0.8194\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.8202 - val_loss: 0.6534 - val_accuracy: 0.8155\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.8212 - val_loss: 0.6350 - val_accuracy: 0.8234\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.8222 - val_loss: 0.6443 - val_accuracy: 0.8204\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.8214 - val_loss: 0.6359 - val_accuracy: 0.8294\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.8242 - val_loss: 0.6495 - val_accuracy: 0.8274\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.8219 - val_loss: 0.6529 - val_accuracy: 0.8155\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.8217 - val_loss: 0.6339 - val_accuracy: 0.8234\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.8167 - val_loss: 0.6439 - val_accuracy: 0.8254\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.8222 - val_loss: 0.6463 - val_accuracy: 0.8234\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6805 - accuracy: 0.8197 - val_loss: 0.6311 - val_accuracy: 0.8254\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.8217 - val_loss: 0.6338 - val_accuracy: 0.8264\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.8162 - val_loss: 0.6333 - val_accuracy: 0.8274\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.7736 - accuracy: 0.7801\n",
            "Loss: 0.7736042141914368, Accuracy: 0.7800925970077515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de un registro individual (preprocesado) con el conjunto de prueba de XGBoost\n",
        "new_record_xgb = X_test_xgb.iloc[3]\n",
        "\n",
        "# Convertir el nuevo registro a un DataFrame\n",
        "new_record_xgb_df = pd.DataFrame([new_record_xgb])\n",
        "\n",
        "# Obtener las predicciones de probabilidad del modelo XGBoost\n",
        "new_record_nn_input = best_xgb_model.predict_proba(new_record_xgb_df)\n",
        "\n",
        "# Predecir usando el modelo de red neuronal entrenado\n",
        "predictions = nn_model.predict(new_record_nn_input)\n",
        "\n",
        "# Obtener las probabilidades para cada tipo de servicio\n",
        "service_probabilities = predictions[0]\n",
        "\n",
        "# Obtener el servicio objetivo original\n",
        "original_service = y_test_xgb[3]  # Indexar directamente el array de NumPy\n",
        "\n",
        "# Convertir el servicio objetivo original a etiqueta de texto\n",
        "original_service_label = label_encoder.inverse_transform([original_service])[0]\n",
        "\n",
        "# Imprimir el servicio objetivo original y las probabilidades\n",
        "service_labels = label_encoder.classes_  # Obtener las etiquetas originales\n",
        "print(f\"Original Servicio: {original_service_label}\")\n",
        "for label, prob in zip(service_labels, service_probabilities):\n",
        "    print(f\"Servicio: {label}, Probabilidad: {prob:.4f}\")"
      ],
      "metadata": {
        "id": "erRlM4R27tHI",
        "outputId": "8fa5c906-70d8-4c1e-b5b5-d258567d5cd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n",
            "Original Servicio: EM\n",
            "Servicio: AT, Probabilidad: 0.8878\n",
            "Servicio: EM, Probabilidad: 0.0211\n",
            "Servicio: LOG, Probabilidad: 0.0067\n",
            "Servicio: SAAF, Probabilidad: 0.0446\n",
            "Servicio: SO, Probabilidad: 0.0398\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}