{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ana-AlonsoCanizares/AA_GRUPO3/blob/main/INFORME_CR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Informe Provincial Ciudad Real\n",
        "##Descarga y limpeza de datos"
      ],
      "metadata": {
        "id": "cncOKnCG9KT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzamos cargando los datos de la carpeta de Google Drive en la que estén guardados (será necesario cambiar esta ruta en función de la ruta del ordenador).\n",
        "\n",
        "Es necesario aceptar la conexión con la cuenta de Google Drive.\n",
        "\n",
        "Importante y esencial, antes de tirar el código es necesario que la carpeta de Drive a la que se va a llamar tenga los archivos en formato xlsx así nombrados: 'CR_SAAF.xlsx', 'CR_AT.xlsx', 'CR_EM.xlsx', 'CR_LOG.xlsx' y 'CR_SO.xlsx' para que no haya errores a la hora de ejecutar este código.\n"
      ],
      "metadata": {
        "id": "SHATfRyI9VF6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhwbvGlQ9JVW",
        "outputId": "ad9a69e4-1050-444a-cc27-16c173be65ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importan las librerías necesarias para la parte de carga de datos y su limpieza."
      ],
      "metadata": {
        "id": "T6gtnbKM-e5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cdv4QrHLrle",
        "outputId": "4baef274-0aa6-4ca5-de9a-a08d77738ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unidecode import unidecode\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "e4n3PNFZ-oIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegúrarse de cambiar la ruta por el nombre real de la carpeta en Google Drive\n",
        "folder_path = '/content/drive/My Drive/PFG_FASPAS/CR'\n",
        "docs_xlsx = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
        "print(docs_xlsx)\n",
        "\n",
        "# Asegúrarse de cambiar la ruta por el nombre real de la carpeta en Google Drive\n",
        "folder_path_csv = '/content/drive/My Drive/PFG_FASPAS/Zonas_Prioritarias'\n",
        "doc_zonas = [f for f in os.listdir(folder_path_csv) if f.endswith('limpio.xlsx')]\n",
        "print(doc_zonas)\n",
        "\n",
        "# Asegúrarse de cambiar la ruta por el nombre real de la carpeta en Google Drive\n",
        "folder_path_mun = '/content/drive/My Drive/PFG_FASPAS/Municipios_Despoblacion'\n",
        "doc_mun = [f for f in os.listdir(folder_path_mun) if f.endswith('limpio.xlsx')]\n",
        "print(doc_mun)\n",
        "\n",
        "# Asegúrarse de cambiar la ruta por el nombre real de la carpeta en Google Drive\n",
        "folder_path_areas = '/content/drive/My Drive/PFG_FASPAS/Areas_Salud'\n",
        "doc_areas = [f for f in os.listdir(folder_path_areas) if f.endswith('limpio.xlsx')]\n",
        "print(doc_areas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMug4vBB9ozZ",
        "outputId": "11db8ac8-74ee-4b88-c1e0-2f053be6556a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CR_SAAF_limpio.xlsx', 'CR_AT_limpio.xlsx', 'CR_LOG_limpio.xlsx', 'CR_EM_limpio.xlsx', 'CR_SO_limpio.xlsx', 'zp_SAAF.xlsx', 'zp_AT.xlsx', 'zp_EM.xlsx', 'zp_LOG.xlsx', 'zp_SO.xlsx', 'md_AT.xlsx', 'md_SO.xlsx', 'md_SAAF.xlsx', 'md_LOG.xlsx', 'md_EM.xlsx']\n",
            "['mun_pri_clm_limpio.xlsx']\n",
            "['Municipios_Despoblacion_CLM_limpio.xlsx']\n",
            "['areas_salud_clm_limpio.xlsx']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creación de un diccionario que almacene los dataframes (.xlsx) contenidos en la carpeta de Ciudad Real.\n",
        "\n",
        "Se irán cargando todos los archivos en un dataframe que se añade al diccionario con el nombre de dicho archivo como clave."
      ],
      "metadata": {
        "id": "hxl_Z9P1-wXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic_dataframes = {}\n",
        "dic_zonas = {}\n",
        "dic_mun = {}\n",
        "dic_areas = {}\n",
        "\n",
        "for doc in docs_xlsx:\n",
        "    entire_path = os.path.join(folder_path, doc)\n",
        "    df = pd.read_excel(entire_path)\n",
        "    # Uso el nombre del archivo como clave\n",
        "    dic_dataframes[doc] = df\n",
        "\n",
        "for doc in doc_zonas:\n",
        "  entire_path = os.path.join(folder_path_csv, doc)\n",
        "  df = pd.read_excel(entire_path)\n",
        "  # Uso el nombre del archivo como clave\n",
        "  dic_zonas[doc] = df\n",
        "\n",
        "for doc in doc_mun:\n",
        "  entire_path = os.path.join(folder_path_mun, doc)\n",
        "  df = pd.read_excel(entire_path)\n",
        "  # Uso el nombre del archivo como clave\n",
        "  dic_mun[doc] = df\n",
        "\n",
        "for doc in doc_areas:\n",
        "  entire_path = os.path.join(folder_path_areas, doc)\n",
        "  df = pd.read_excel(entire_path)\n",
        "  # Uso el nombre del archivo como clave\n",
        "  dic_areas[doc] = df"
      ],
      "metadata": {
        "id": "wpsYAD2X-c4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se debe observar que el dataframe cuente con al menos las columnas: 'AÑOS ATENCIÓN', 'FECHA NACIMIENTO' **en formato fecha**, 'LOCALIDAD', 'GÉNERO' y 'CP'"
      ],
      "metadata": {
        "id": "swAIR8SeSRpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que sabemos cuáles son las claves, guardamos cada dataframe por separado para trabajar con todos ellos de manera individual, por el momento."
      ],
      "metadata": {
        "id": "j7NG1ZuiB2pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir todas las claves\n",
        "for clave in dic_dataframes.keys():\n",
        "    print(clave)\n",
        "for clave in dic_zonas.keys():\n",
        "  print(clave)\n",
        "for clave in dic_mun.keys():\n",
        "  print(clave)\n",
        "for clave in dic_areas.keys():\n",
        "  print(clave)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bSrp6NdAwQZ",
        "outputId": "647229b6-7bc1-4816-cde7-12aa94ac0a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CR_SAAF_limpio.xlsx\n",
            "CR_AT_limpio.xlsx\n",
            "CR_LOG_limpio.xlsx\n",
            "CR_EM_limpio.xlsx\n",
            "CR_SO_limpio.xlsx\n",
            "zp_SAAF.xlsx\n",
            "zp_AT.xlsx\n",
            "zp_EM.xlsx\n",
            "zp_LOG.xlsx\n",
            "zp_SO.xlsx\n",
            "md_AT.xlsx\n",
            "md_SO.xlsx\n",
            "md_SAAF.xlsx\n",
            "md_LOG.xlsx\n",
            "md_EM.xlsx\n",
            "mun_pri_clm_limpio.xlsx\n",
            "Municipios_Despoblacion_CLM_limpio.xlsx\n",
            "areas_salud_clm_limpio.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CR_SAAF = dic_dataframes.get(\"CR_SAAF_limpio.xlsx\")\n",
        "CR_AT = dic_dataframes.get(\"CR_AT_limpio.xlsx\")\n",
        "CR_EM = dic_dataframes.get(\"CR_EM_limpio.xlsx\")\n",
        "CR_LOG = dic_dataframes.get(\"CR_LOG_limpio.xlsx\")\n",
        "CR_SO = dic_dataframes.get(\"CR_SO_limpio.xlsx\")\n",
        "mun_pri_clm = dic_zonas.get(\"mun_pri_clm_limpio.xlsx\")\n",
        "mun_desp_clm = dic_mun.get(\"Municipios_Despoblacion_CLM_limpio.xlsx\")\n",
        "areas_clm = dic_areas.get(\"areas_salud_clm_limpio.xlsx\")"
      ],
      "metadata": {
        "id": "tgagsBVtCDkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CÓDIGO SOLO PARA EL CURRO (PQ NO PUEDO ACCEDER AL DRIVE)\n",
        "CR_SAAF = pd.read_excel('/content/CR_SAAF_limpio.xlsx')\n",
        "CR_AT = pd.read_excel('/content/CR_AT_limpio.xlsx')\n",
        "CR_EM = pd.read_excel('/content/CR_EM_limpio.xlsx')\n",
        "CR_LOG = pd.read_excel('/content/CR_LOG_limpio.xlsx')\n",
        "CR_SO = pd.read_excel('/content/CR_SO_limpio.xlsx')\n",
        "mun_pri_clm = pd.read_excel('/content/mun_pri_clm_limpio.xlsx')\n",
        "mun_desp_clm = pd.read_excel('/content/Municipios_Despoblacion_CLM_limpio.xlsx')\n",
        "areas_clm = pd.read_excel('/content/areas_salud_clm_limpio.xlsx')"
      ],
      "metadata": {
        "id": "FzS8Balj4ozG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Funciones para medir el impacto\n",
        "1. impact_analysis_per_service(df, key, nombre). Analiza el impacto por servicio basado en la columna 'LOCALIDAD' del DataFrame.\n",
        "\n",
        "*   Calcula el conteo de registros para cada localidad.\n",
        "*   Imprime un mensaje indicando el impacto de cada localidad según el número de registros:\n",
        "  *   Fuerte impacto: más de 10 registros.\n",
        "  *   Medio impacto: entre 5 y 10 registros.\n",
        "  *   Leve impacto: 5 o menos registros.\n",
        "\n",
        "2. impact_analysis_depopulation(df, key, nombre). Analiza el impacto de la despoblación basado en la columna 'CLASIFICACION DE ZONA' del DataFrame.\n",
        "\n",
        "*   Calcula el conteo de registros para cada clasificación de zona.\n",
        "*   Imprime un mensaje indicando el impacto de cada localidad según el número de registros:\n",
        "  *   Fuerte impacto: más de 10 registros.\n",
        "  *   Medio impacto: entre 5 y 10 registros.\n",
        "  *   Leve impacto: 5 o menos registros.\n",
        "\n",
        "3. impact_analysis(df). Analiza el impacto general basado en la columna 'LOCALIDAD' del DataFrame para todos los servicios en una provincia específica.\n",
        "\n",
        "\n",
        "\n",
        "*   Calcula el conteo de registros para cada localidad.\n",
        "*   Imprime un mensaje indicando el impacto de cada localidad según el número de registros:\n",
        "  *   Fuerte impacto: más de 10 registros.\n",
        "  *   Medio impacto: entre 5 y 10 registros.\n",
        "  *   Leve impacto: 5 o menos registros.\n",
        "4. combine_and_filter_common_columns(df_dict, common_columns). Combina múltiples DataFrames en un solo DataFrame basado en columnas comunes y elimina las filas duplicadas donde los valores de estas columnas sean iguales.\n",
        "\n",
        "\n",
        "*   Extrae las columnas comunes de cada DataFrame en el diccionario df_dict.\n",
        "*   Combina todos los DataFrames extraídos en uno solo.\n",
        "*   Elimina las filas duplicadas basadas en los valores de las columnas comunes.\n",
        "\n",
        "Estas funciones están diseñadas para analizar y combinar datos de distintas maneras, facilitando la identificación de impactos por localidad, clasificación de zona, y la limpieza de datos duplicados en múltiples DataFrames."
      ],
      "metadata": {
        "id": "-EuaDsx5tPWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def impact_analysis_per_service(df, key, nombre):\n",
        "    # Calcular el conteo de registros para cada categoría\n",
        "    cat_count = df['LOCALIDAD'].value_counts()\n",
        "    # Imprimir los resultados\n",
        "    print(f\"\\n\\nEn el caso del servicio de {key}, las localidades con impacto dentro de las que se incluyen en las {nombre} son:\\n\")\n",
        "\n",
        "    # Iterar sobre la serie y mostrar el impacto\n",
        "    for localidad, valor in cat_count.items():\n",
        "        if valor > 10:\n",
        "            print(f\"La localidad de {localidad} que tiene un impacto fuerte, ya que cuenta con {valor} registros.\\n\")\n",
        "        elif valor > 5:\n",
        "            print(f\"La localidad de {localidad} que tiene un impacto medio, ya que cuenta con {valor} registros.\\n\")\n",
        "        else:\n",
        "            if valor > 1:\n",
        "                print(f\"La localidad de {localidad} que tiene un impacto leve, ya que cuenta con {valor} registros.\\n\")\n",
        "            else:\n",
        "                print(f\"La localidad de {localidad} que tiene un impacto leve, ya que cuenta con {valor} registro.\\n\")\n",
        "\n",
        "def impact_analysis_depopulation(df, key, nombre):\n",
        "    # Calcular el conteo de registros para cada categoría\n",
        "    cat_count = df['CLASIFICACION DE ZONA'].value_counts()\n",
        "    # Imprimir los resultados\n",
        "    print(f\"\\n\\nEn el caso del servicio de {key}, los números sobre el impacto para el tipo de {nombre} son:\\n\")\n",
        "\n",
        "    # Iterar sobre la serie y mostrar el impacto\n",
        "    for zona, valor in cat_count.items():\n",
        "        if valor > 10:\n",
        "            print(f\"El tipo de zona de {zona} que tiene un impacto fuerte, ya que cuenta con {valor} registros.\\n\")\n",
        "        elif valor > 5:\n",
        "            print(f\"El tipo de zona de {zona} que tiene un impacto medio, ya que cuenta con {valor} registros.\\n\")\n",
        "        else:\n",
        "            if valor > 1:\n",
        "                print(f\"El tipo de zona de {zona} que tiene un impacto leve, ya que cuenta con {valor} registros.\\n\")\n",
        "            else:\n",
        "                print(f\"El tipo de zona de {zona} que tiene un impacto leve, ya que cuenta con {valor} registro.\\n\")\n",
        "\n",
        "def impact_analysis(df):\n",
        "    # Calcular el conteo de registros para cada categoría\n",
        "    cat_count = df['LOCALIDAD'].value_counts()\n",
        "    # Imprimir los resultados\n",
        "    print(f\"\\nPara todos los servicios de la provincia de Ciudad Real, las localidades con impacto dentro de las que se incluyen en las zonas prioritarias son:\\n\")\n",
        "\n",
        "    # Iterar sobre la serie y mostrar el impacto\n",
        "    for localidad, valor in cat_count.items():\n",
        "        if valor > 10:\n",
        "            print(f\"La localidad de {localidad} que tiene un impacto fuerte, ya que cuenta con {valor} registros.\\n\")\n",
        "        elif valor > 5:\n",
        "            print(f\"La localidad de {localidad} que tiene un impacto medio, ya que cuenta con {valor} registros.\\n\")\n",
        "        else:\n",
        "            if valor > 1:\n",
        "                print(f\"La localidad de {localidad} que tiene un impacto leve, ya que cuenta con {valor} registros.\\n\")\n",
        "            else:\n",
        "                print(f\"La localidad de {localidad} que tiene un impacto leve, ya que cuenta con {valor} registro.\\n\")\n",
        "\n",
        "def combine_and_filter_common_columns(df_dict, common_columns):\n",
        "    \"\"\"\n",
        "    Combina los DataFrames en el diccionario según las columnas comunes y elimina las filas\n",
        "    donde los valores de las columnas comunes sean iguales.\n",
        "\n",
        "    :param df_dict: Diccionario de DataFrames\n",
        "    :param common_columns: Lista de columnas comunes a considerar\n",
        "    :return: DataFrame combinado y filtrado\n",
        "    \"\"\"\n",
        "    # Crear una lista para almacenar los DataFrames con las tres columnas comunes\n",
        "    df_list = []\n",
        "\n",
        "    # Extraer las columnas comunes de cada DataFrame y añadirlas a la lista\n",
        "    for key, df in df_dict.items():\n",
        "        df_common = df[common_columns]\n",
        "        df_list.append(df_common)\n",
        "\n",
        "    # Concatenar todos los DataFrames de la lista en uno solo\n",
        "    combined_df = pd.concat(df_list)\n",
        "\n",
        "    # Eliminar las filas donde los valores de las tres columnas sean iguales\n",
        "    combined_df = combined_df.drop_duplicates(subset=common_columns, keep=False)\n",
        "\n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "Ytfhidh0bzXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Merge df1 and df2 on 'birthdate'\n",
        "merged_df = pd.merge(CR_LOG, CR_SAAF[['FECHA NACIMIENTO', 'LOCALIDAD']], on='FECHA NACIMIENTO', how='left')\n",
        "\n",
        "# Step 2: Copy the 'LOCALIDAD' column to df2 if you want to retain all original df2 rows\n",
        "CR_LOG['LOCALIDAD'] = merged_df['LOCALIDAD']"
      ],
      "metadata": {
        "id": "5iphYWg8NKwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Número total de usuarios y socios\n",
        "Vamos a sacar el número total de usuarios y socios por servicio y cuáles son únicos, independientemente del servicio al que pertenezcan."
      ],
      "metadata": {
        "id": "UQon77Gkix7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict = {\n",
        "    'zp_SAAF': CR_SAAF,\n",
        "    'zp_AT': CR_AT,\n",
        "    'zp_EM':CR_EM,\n",
        "    'zp_LOG':CR_LOG,\n",
        "    'zp_SO': CR_SO\n",
        "}"
      ],
      "metadata": {
        "id": "OANPBSJcixcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando sobre el diccionario para crear gráficos y analizar impacto\n",
        "for key, df in df_dict.items():\n",
        "  valor = len(df)\n",
        "  print(f'Para el servicio de {key} hay un total de {valor} usuarios.\\n')\n",
        "\n",
        "# Assuming 'df_dict' is your dictionary of DataFrames\n",
        "column_sets = []\n",
        "\n",
        "# Iterate over each DataFrame in the dictionary to collect column sets\n",
        "for key, df in df_dict.items():\n",
        "    column_sets.append(set(df.columns))\n",
        "\n",
        "# Find the intersection of all column sets to get the common columns\n",
        "common_columns = list(set.intersection(*column_sets))\n",
        "\n",
        "# print(\"Common columns across all DataFrames:\", common_columns)\n",
        "\n",
        "# Collect DataFrames with only the common columns\n",
        "dfs_common_cols = [df[common_columns] for df in df_dict.values()]\n",
        "\n",
        "# Use pd.concat to combine all the DataFrames in the list\n",
        "result_df = pd.concat(dfs_common_cols, ignore_index=True)\n",
        "\n",
        "total = len(result_df)\n",
        "print(f'\\nLa provincia de Ciudad Real cuenta con un total de {total} usuarios y socios distintos.')\n"
      ],
      "metadata": {
        "id": "QZ3Wct82jUDr",
        "outputId": "3a05b482-b7b0-4ab0-8f90-916cc593a75e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para el servicio de zp_SAAF hay un total de 226 usuarios.\n",
            "\n",
            "Para el servicio de zp_AT hay un total de 38 usuarios.\n",
            "\n",
            "Para el servicio de zp_EM hay un total de 166 usuarios.\n",
            "\n",
            "Para el servicio de zp_LOG hay un total de 241 usuarios.\n",
            "\n",
            "Para el servicio de zp_SO hay un total de 118 usuarios.\n",
            "\n",
            "\n",
            "La provincia de Ciudad Real cuenta con un total de 789 usuarios y socios distintos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "226+38+166+241"
      ],
      "metadata": {
        "id": "xvExYwAFbGAI",
        "outputId": "31302140-ed04-401c-8a9c-86b26cce2f6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "671"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataframes cruzados con zonas prioritarias\n",
        "\n",
        "Cruzamos todos los dfs con el df de municipios prioritarios para sacar el impacto de cada servicio en estas zonas."
      ],
      "metadata": {
        "id": "iCE0swqIWWZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_prio = {\n",
        "    'zp_SAAF': pd.merge(CR_SAAF, mun_pri_clm, left_on='LOCALIDAD', right_on='ZONA PRIORITARIA'),\n",
        "    'zp_AT': pd.merge(CR_AT, mun_pri_clm, left_on='LOCALIDAD', right_on='ZONA PRIORITARIA'),\n",
        "    'zp_EM': pd.merge(CR_EM, mun_pri_clm, left_on='LOCALIDAD', right_on='ZONA PRIORITARIA'),\n",
        "    'zp_LOG': pd.merge(CR_LOG, mun_pri_clm, left_on='LOCALIDAD', right_on='ZONA PRIORITARIA'),\n",
        "    'zp_SO': pd.merge(CR_SO, mun_pri_clm, left_on='LOCALIDAD', right_on='ZONA PRIORITARIA')\n",
        "}"
      ],
      "metadata": {
        "id": "i4n9cHTXcCqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of DataFrames\n",
        "dfs = [dict_prio['zp_SAAF'], dict_prio['zp_AT'], dict_prio['zp_EM'], dict_prio['zp_LOG'], dict_prio['zp_SO']]\n",
        "\n",
        "# Corresponding folder paths on Google Drive\n",
        "folder_paths = [\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CR',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CR',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CR',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CR',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CR'\n",
        "]\n",
        "\n",
        "# Corresponding file names\n",
        "file_names = ['zp_SAAF.xlsx', 'zp_AT.xlsx', 'zp_EM.xlsx', 'zp_LOG.xlsx', 'zp_SO.xlsx']"
      ],
      "metadata": {
        "id": "jjMp_unIxhdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the DataFrames, folder paths, and file names\n",
        "for df, folder_path, file_name in zip(dfs, folder_paths, file_names):\n",
        "    # Define the complete file path\n",
        "    file_path = f\"{folder_path}/{file_name}\"\n",
        "\n",
        "    # Save the DataFrame as an Excel file\n",
        "    df.to_excel(file_path, index=False)\n",
        "\n",
        "print(\"All DataFrames have been exported successfully.\")"
      ],
      "metadata": {
        "id": "p79pTiXeyADK",
        "outputId": "e14ef0c6-cafb-4413-e63a-db61c933976d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: '/content/drive/My Drive/PFG_FASPAS/CR'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-29ff4f7079fc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Save the DataFrame as an Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All DataFrames have been exported successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options)\u001b[0m\n\u001b[1;32m   2250\u001b[0m             \u001b[0minf_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf_rep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m         )\n\u001b[0;32m-> 2252\u001b[0;31m         formatter.write(\n\u001b[0m\u001b[1;32m   2253\u001b[0m             \u001b[0mexcel_writer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0;31m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;31m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m             writer = ExcelWriter(  # type: ignore[abstract]\n\u001b[0m\u001b[1;32m    935\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mengine_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[1;32m   1217\u001b[0m         )\n\u001b[1;32m   1218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m             self._handles = get_handle(\n\u001b[0m\u001b[1;32m   1220\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/content/drive/My Drive/PFG_FASPAS/CR'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'dict_prio' is your dictionary of DataFrames\n",
        "for key, df in dict_prio.items():\n",
        "    if not df.empty and 'LOCALIDAD' in df.columns and not df['LOCALIDAD'].isnull().all():\n",
        "        cat_count = df['LOCALIDAD'].value_counts()\n",
        "        if not cat_count.empty:\n",
        "            # Create a bar graph\n",
        "            plt.figure(figsize=(15, 6))  # Adjust the figure size to be wider\n",
        "            ax = cat_count.sort_index().plot(kind='bar')\n",
        "\n",
        "            # Additional customization\n",
        "            plt.title(f'{key}: Impacto en Zonas por Zonas Prioritarias')\n",
        "            plt.xlabel('ZONA PRIORITARIA')\n",
        "            plt.ylabel('Número de Registros')\n",
        "            plt.xticks(rotation=45, ha='right')  # Rotate the x-axis labels for better reading\n",
        "\n",
        "            # Add the count numbers on top of each bar\n",
        "            for i in ax.containers:\n",
        "                ax.bar_label(i, label_type='edge')\n",
        "\n",
        "            # Display the graph\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"No hay datos para graficar en {key}.\")\n",
        "    else:\n",
        "        print(f\"No hay datos para graficar en {key}.\")\n"
      ],
      "metadata": {
        "id": "yA6sWBBaeR-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando sobre el diccionario para crear gráficos y analizar impacto\n",
        "nombre = ('zonas prioritarias')\n",
        "for key, df in dict_prio.items():\n",
        "    impact_analysis_per_service(df, key, nombre)"
      ],
      "metadata": {
        "id": "_jZTIFrahZzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando sobre el diccionario para crear gráficos y analizar impacto\n",
        "for key, df in dict_prio.items():\n",
        "  valor = len(df)\n",
        "  print(f'Para el servicio de {key} hay un total de {valor} usuarios en zonas prioritarias.\\n')"
      ],
      "metadata": {
        "id": "7H-Nh6GeljPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el informe de impacto real de la provincia de Ciudad Real, tendremos en cuenta la localidad, la fecha de nacimiento y el género de los registros para no duplicar usuarios."
      ],
      "metadata": {
        "id": "FccobOQhdtwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Llamar a la función\n",
        "result = pd.merge(result_df, mun_pri_clm, left_on='LOCALIDAD', right_on='ZONA PRIORITARIA')\n",
        "\n",
        "impact_analysis(result)"
      ],
      "metadata": {
        "id": "3FAElvWcdtQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Zonas de Despoblación\n"
      ],
      "metadata": {
        "id": "uXOMcSMt31St"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. impact_analysis(df). Analiza el impacto general basado en la columna 'LOCALIDAD' del DataFrame para todos los servicios en la provincia de Ciudad Real, incluyendo la clasificación de zona.\n",
        "\n",
        "*   Calcula el conteo de registros para cada localidad.\n",
        "*   Itera sobre cada localidad y determina su clasificación de zona.\n",
        "*   Imprime un mensaje indicando el impacto de cada localidad según el número de registros y su clasificación de zona:\n",
        "  *   Fuerte impacto: más de 10 registros.\n",
        "  *   Medio impacto: entre 5 y 10 registros.\n",
        "Leve impacto: 5 o menos registros.\n",
        "2. impact_analysis_per_service(df, key, nombre). Analiza el impacto de un servicio específico basado en la columna 'LOCALIDAD' del DataFrame, incluyendo la clasificación de zona.\n",
        "\n",
        "\n",
        "*   Calcula el conteo de registros para cada localidad.\n",
        "*   Itera sobre cada localidad y determina su clasificación de zona.\n",
        "*   Imprime un mensaje indicando el impacto de cada localidad según el número de registros y su clasificación de zona para un servicio específico:\n",
        "  *   Fuerte impacto: más de 10 registros.\n",
        "  *   Medio impacto: entre 5 y 10 registros.\n",
        "  *   Leve impacto: 5 o menos registros.\n",
        "\n",
        "Estas funciones están diseñadas para proporcionar una visión del impacto de los servicios en distintas localidades, tomando en cuenta la clasificación de zona y la cantidad de registros asociados a cada localidad."
      ],
      "metadata": {
        "id": "0xqfGOIHuVrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def impact_analysis(df):\n",
        "    # Calcular el conteo de registros para cada categoría\n",
        "    cat_count = df['LOCALIDAD'].value_counts()\n",
        "    # Imprimir los resultados\n",
        "    print(f\"\\nPara todos los servicios de la provincia de Ciudad Real, las localidades con impacto dentro de las que se incluyen en los municipios de despoblación son:\\n\")\n",
        "\n",
        "    # Iterar sobre la serie y mostrar el impacto\n",
        "    for localidad, valor in cat_count.items():\n",
        "        zona = df[df['LOCALIDAD'] == localidad]['CLASIFICACION DE ZONA'].iloc[0]\n",
        "        if valor > 10:\n",
        "            print(f\"La localidad de {localidad} que pertenece a una zona {zona} tiene un impacto fuerte, ya que cuenta con {valor} registros.\\n\")\n",
        "        elif valor > 5:\n",
        "            print(f\"La localidad de {localidad} que pertenece a una zona {zona} tiene un impacto medio, ya que cuenta con {valor} registros.\\n\")\n",
        "        else:\n",
        "            if valor > 1:\n",
        "                print(f\"La localidad de {localidad} que pertenece a una zona {zona} tiene un impacto leve, ya que cuenta con {valor} registros.\\n\")\n",
        "            else:\n",
        "                print(f\"La localidad de {localidad} que pertenece a una zona {zona} tiene un impacto leve, ya que cuenta con {valor} registro.\\n\")\n",
        "\n",
        "def impact_analysis_per_service(df, key, nombre):\n",
        "    # Calcular el conteo de registros para cada categoría\n",
        "    cat_count = df['LOCALIDAD'].value_counts()\n",
        "    # Imprimir los resultados\n",
        "    print(f\"\\n\\nEn el caso del servicio de {key}, las localidades con impacto dentro de las que se incluyen en las {nombre} son:\\n\")\n",
        "\n",
        "    # Iterar sobre la serie y mostrar el impacto\n",
        "    for localidad, valor in cat_count.items():\n",
        "        zona = df[df['LOCALIDAD'] == localidad]['CLASIFICACION DE ZONA'].iloc[0]\n",
        "        if valor > 10:\n",
        "            print(f\"La localidad de {localidad} que pertenece a una zona {zona} tiene un impacto fuerte, ya que cuenta con {valor} registros.\\n\")\n",
        "        elif valor > 5:\n",
        "            print(f\"La localidad de {localidad} que pertenece a una zona {zona} tiene un impacto medio, ya que cuenta con {valor} registros.\\n\")\n",
        "        else:\n",
        "            if valor > 1:\n",
        "                print(f\"La localidad de {localidad} que pertenece a una zona {zona} tiene un impacto leve, ya que cuenta con {valor} registros.\\n\")\n",
        "            else:\n",
        "                print(f\"La localidad de {localidad} que pertenece a una zona {zona} tiene un impacto leve, ya que cuenta con {valor} registro.\\n\")"
      ],
      "metadata": {
        "id": "A2hN5JWjv0uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_mun_desp = {\n",
        "    'md_SAAF': pd.merge(CR_SAAF, mun_desp_clm, left_on='LOCALIDAD', right_on='MUNICIPIO'),\n",
        "    'md_AT': pd.merge(CR_AT, mun_desp_clm, left_on='LOCALIDAD', right_on='MUNICIPIO'),\n",
        "    'md_EM': pd.merge(CR_EM, mun_desp_clm, left_on='LOCALIDAD', right_on='MUNICIPIO'),\n",
        "    'md_LOG': pd.merge(CR_LOG, mun_desp_clm, left_on='LOCALIDAD', right_on='MUNICIPIO'),\n",
        "    'md_SO': pd.merge(CR_SO, mun_desp_clm, left_on='LOCALIDAD', right_on='MUNICIPIO')\n",
        "}"
      ],
      "metadata": {
        "id": "jT8ioqM3_tmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of DataFrames\n",
        "dfs = [dict_mun_desp['md_SAAF'], dict_mun_desp['md_AT'], dict_mun_desp['md_EM'], dict_mun_desp['md_LOG'], dict_mun_desp['md_SO']]\n",
        "\n",
        "# Corresponding folder paths on Google Drive\n",
        "folder_paths = [\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CR',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CR',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CR',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CR',\n",
        "    '/content/drive/My Drive/PFG_FASPAS/CR'\n",
        "]\n",
        "\n",
        "# Corresponding file names\n",
        "file_names = ['md_SAAF.xlsx', 'md_AT.xlsx', 'md_EM.xlsx', 'md_LOG.xlsx', 'md_SO.xlsx']\n",
        "\n",
        "# Iterate over the DataFrames, folder paths, and file names\n",
        "for df, folder_path, file_name in zip(dfs, folder_paths, file_names):\n",
        "    # Define the complete file path\n",
        "    file_path = f\"{folder_path}/{file_name}\"\n",
        "\n",
        "    # Save the DataFrame as an Excel file\n",
        "    df.to_excel(file_path, index=False)\n",
        "\n",
        "print(\"All DataFrames have been exported successfully.\")"
      ],
      "metadata": {
        "id": "YQYLxl1Y7ABD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpiamos los datos para coger solo las zonas que dan un porcentaje de deducción, que se corresponden a las zonas de EXTREMA DESPOBLACIÓN, INTENSA DESPOBLACION, INTERMEDIA AGRICOLA y EN RIESGO."
      ],
      "metadata": {
        "id": "Fd1O-hwhO6m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filtrar_porcentaje_mayor_cero(dict_mun_desp):\n",
        "    dict_filtrado = {}\n",
        "    for key, df in dict_mun_desp.items():\n",
        "        if 'PORCENTAJE DEDUCCION' in df.columns:\n",
        "            df_filtrado = df[df['PORCENTAJE DEDUCCION'] > 0]\n",
        "            dict_filtrado[key] = df_filtrado\n",
        "    return dict_filtrado\n",
        "\n",
        "# Filtrar los DataFrames\n",
        "dict_mun_desp = filtrar_porcentaje_mayor_cero(dict_mun_desp)\n",
        "mun_desp_clm = mun_desp_clm[mun_desp_clm['PORCENTAJE DEDUCCION'] > 0]"
      ],
      "metadata": {
        "id": "k4aZxsInO9GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando sobre el diccionario para crear gráficos\n",
        "for key, df in dict_mun_desp.items():\n",
        "    # Calcular el conteo de registros para cada categoría\n",
        "    cat_count = df['LOCALIDAD'].value_counts()\n",
        "\n",
        "    plt.figure(figsize=(12, 5))  # Width=12 inches and Height=5 inches\n",
        "    # Crear un gráfico de barras\n",
        "    ax = cat_count.sort_index().plot(kind='bar')\n",
        "\n",
        "    # Personalización adicional\n",
        "    plt.title(f'{key}: Impacto en Zonas por Zonas Despobladas')\n",
        "    plt.xlabel('ZONA DESPOBLADA')\n",
        "    plt.ylabel('Número de Registros')\n",
        "    plt.xticks(rotation=45, ha = 'right')  # Rota las etiquetas del eje X para mejor lectura\n",
        "    plt.xticks(fontsize=10)\n",
        "\n",
        "    # Añadir el número de conteos en la parte superior de cada barra\n",
        "    for i in ax.containers:\n",
        "        ax.bar_label(i, label_type='edge')\n",
        "\n",
        "    # Mostrar el gráfico\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "18AxZxXz34e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando sobre el diccionario para crear gráficos\n",
        "for key, df in dict_mun_desp.items():\n",
        "    # Calcular el conteo de registros para cada categoría\n",
        "    cat_count = df['CLASIFICACION DE ZONA'].value_counts()\n",
        "\n",
        "    plt.figure(figsize=(12, 5))  # Width=12 inches and Height=5 inches\n",
        "    # Crear un gráfico de barras\n",
        "    ax = cat_count.sort_index().plot(kind='bar')\n",
        "\n",
        "    # Personalización adicional\n",
        "    plt.title(f'{key}: Impacto en Zonas por Tipo de Zonas Despobladas')\n",
        "    plt.xlabel('TIPO DE DESPOBLACIÓN')\n",
        "    plt.ylabel('Número de Registros')\n",
        "    plt.xticks(rotation=45, ha = 'right')  # Rota las etiquetas del eje X para mejor lectura\n",
        "    plt.xticks(fontsize=10)\n",
        "\n",
        "    # Añadir el número de conteos en la parte superior de cada barra\n",
        "    for i in ax.containers:\n",
        "        ax.bar_label(i, label_type='edge')\n",
        "\n",
        "    # Mostrar el gráfico\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8CbxAiG66TIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando sobre el diccionario para crear gráficos y analizar impacto\n",
        "nombre = ('zonas despobladas')\n",
        "for key, df in dict_mun_desp.items():\n",
        "    impact_analysis_per_service(df, key, nombre)"
      ],
      "metadata": {
        "id": "EUmwQJNAwdoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando sobre el diccionario para crear gráficos y analizar impacto\n",
        "nombre = ('zonas despobladas')\n",
        "for key, df in dict_mun_desp.items():\n",
        "    impact_analysis_depopulation(df, key, nombre)"
      ],
      "metadata": {
        "id": "78NhiEgPyOMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Llamar a la función\n",
        "result = pd.merge(result_df, mun_desp_clm, left_on='LOCALIDAD', right_on='MUNICIPIO')\n",
        "\n",
        "impact_analysis(result)"
      ],
      "metadata": {
        "id": "ymooLx7PxL3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Áreas de Salud"
      ],
      "metadata": {
        "id": "pI0mJwQWuAVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código de Áreas de Salud no contemplado para el PFG, dejar para FASPAS."
      ],
      "metadata": {
        "id": "wLJ4xzkWuYdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_name(name):\n",
        "    name = name.strip()  # Remove leading/trailing whitespace\n",
        "    articles = ['EL ', 'LA ', 'LOS ', 'LAS ', 'UN ', 'UNA ', 'UNOS ', 'UNAS ']\n",
        "    for article in articles:\n",
        "        if name.upper().startswith(article):\n",
        "            name = name[len(article):]\n",
        "            break\n",
        "    return name.upper()\n",
        "\n",
        "# Clean the areas_clm DataFrame\n",
        "areas_clm['ENTIDAD SINGULAR'] = areas_clm['ENTIDAD SINGULAR'].apply(clean_name)\n",
        "\n",
        "# List of CR DataFrames\n",
        "cr_dfs = [CR_SAAF, CR_AT, CR_EM, CR_LOG, CR_SO]\n",
        "\n",
        "# Clean the 'LOCALIDAD' column in each CR DataFrame\n",
        "for df in cr_dfs:\n",
        "  df['LOCALIDAD'] = df['LOCALIDAD'].dropna().apply(clean_name)"
      ],
      "metadata": {
        "id": "kZsK0Q625RXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "areas_clm = areas_clm[~areas_clm['ENTIDAD SINGULAR'].duplicated(keep=False)]\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "areas_clm.reset_index(drop=True, inplace=True)\n",
        "areas_clm.shape"
      ],
      "metadata": {
        "id": "Wz-0PRr2yzcP",
        "outputId": "9d589df6-21e5-4a8e-80d2-cc0c2c37b851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(655, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_areas_salud = {\n",
        "    'as_SAAF': pd.merge(CR_SAAF, areas_clm, left_on='LOCALIDAD', right_on='ENTIDAD SINGULAR'),\n",
        "    'as_AT': pd.merge(CR_AT, areas_clm, left_on='LOCALIDAD', right_on='ENTIDAD SINGULAR'),\n",
        "    'as_EM': pd.merge(CR_EM, areas_clm, left_on='LOCALIDAD', right_on='ENTIDAD SINGULAR'),\n",
        "    'as_LOG': pd.merge(CR_LOG, areas_clm, left_on='LOCALIDAD', right_on='ENTIDAD SINGULAR'),\n",
        "    'as_SO': pd.merge(CR_SO, areas_clm, left_on='LOCALIDAD', right_on='ENTIDAD SINGULAR')\n",
        "}"
      ],
      "metadata": {
        "id": "Usz9XD-buMYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterando sobre el diccionario para crear gráficos\n",
        "for key, df in dict_areas_salud.items():\n",
        "    # Calcular el conteo de registros para cada categoría\n",
        "    cat_count = df['AREA DE SALUD'].value_counts()\n",
        "\n",
        "    plt.figure(figsize=(12, 5))  # Width=12 inches and Height=5 inches\n",
        "    # Crear un gráfico de barras\n",
        "    ax = cat_count.sort_index().plot(kind='bar')\n",
        "\n",
        "    # Personalización adicional\n",
        "    plt.title(f'{key}: Impacto en Áreas por Áreas de Salud')\n",
        "    plt.xlabel('ÁREA DE SALUD')\n",
        "    plt.ylabel('Número de Registros')\n",
        "    plt.xticks(rotation=45, ha = 'right')  # Rota las etiquetas del eje X para mejor lectura\n",
        "    plt.xticks(fontsize=10)\n",
        "\n",
        "    # Añadir el número de conteos en la parte superior de cada barra\n",
        "    for i in ax.containers:\n",
        "        ax.bar_label(i, label_type='edge')\n",
        "\n",
        "    # Mostrar el gráfico\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4UL56g9VwFKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-gD3QRB0PFq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}